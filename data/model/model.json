[
    {
        "modelName": "Claude Haiku 4.5",
        "company": "Anthropic",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-10-15",
        "description": "Claude Haiku 4.5 是 Anthropic 最新的高性价比与低延迟模型，支持 200K 上下文与 64K 输出；在 SWE-bench Verified 达到 73.3%，在众多代理编程评测中接近 Sonnet 4.5 的水平，同时在电脑使用与子代理编排上表现突出；适合实时对话、客服与并行编码子任务。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "视觉理解",
            "代码增强",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 64,
        "relatedLinks": [
            {
                "title": "Claude Haiku 4.5 模型页面",
                "url": "https://www.anthropic.com/claude/haiku"
            },
            {
                "title": "Claude Haiku 4.5 官方发布公告",
                "url": "https://www.anthropic.com/news/claude-haiku-4-5"
            },
            {
                "title": "Claude 文档：模型总览",
                "url": "https://docs.anthropic.com/claude/docs/models-overview"
            }
        ]
    },
    {
        "modelName": "Claude Sonnet 4.5",
        "company": "Anthropic",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-09-29",
        "description": "Claude Sonnet 4.5 是 Anthropic 当前最强的通用编码与智能体模型，支持 200K 上下文与最高 64K 输出；在 SWE-bench Verified 达到 77.2%，在 OSWorld 计算机使用基准达到 61.4%，显著提升长时任务的稳定性、并行工具调用与检索/浏览器操作能力；适用于端到端软件开发、长运行智能体与企业知识处理。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "视觉理解",
            "代码增强",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 64,
        "relatedLinks": [
            {
                "title": "Claude Sonnet 4.5 模型页面",
                "url": "https://www.anthropic.com/claude/sonnet"
            },
            {
                "title": "Claude Sonnet 4.5 官方发布公告",
                "url": "https://www.anthropic.com/news/claude-sonnet-4-5"
            },
            {
                "title": "Claude 文档：模型总览",
                "url": "https://docs.anthropic.com/claude/docs/models-overview"
            }
        ]
    },
    {
        "modelName": "Claude Opus 4.1",
        "company": "Anthropic",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-08-05",
        "description": "Claude Opus 4.1 是 Anthropic 的混合推理旗舰模型，采用 Transformer 架构并强化长程推理与工具调用，支持 200K 上下文与 32K 输出；在 SWE-bench Verified 达到 74.5%，提升多文件重构与代码精确性，同时具备视觉理解与深入研究能力，适用于企业级编码自动化、检索分析与内容创作。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "视觉理解",
            "代码增强",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 32,
        "relatedLinks": [
            {
                "title": "Claude Opus 4.1 官方发布公告",
                "url": " https://www.anthropic.com/news/claude-opus-4-1 "
            },
            {
                "title": "Claude Opus 4.1 模型页面",
                "url": " https://www.anthropic.com/claude/opus "
            }
        ]
    },
    {
        "modelName": "Claude Sonnet 4",
        "company": "Anthropic",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-05-22",
        "description": "Claude Sonnet 4 是 4 系列的主力模型，支持 200K 上下文与 64K 输出，并在 Beta 模式下支持 1M 上下文；在 OSWorld 早期版本取得 42.2% 领先成绩，面向高并发与用户交互场景的实用前沿性能，适用于编码、工具调用和长上下文的信息处理。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "视觉理解",
            "代码增强",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 64,
        "relatedLinks": [
            {
                "title": "Claude Sonnet 4 模型页面",
                "url": "https://www.anthropic.com/claude/sonnet"
            },
            {
                "title": "Claude 4 系列发布公告",
                "url": "https://www.anthropic.com/news/claude-4"
            },
            {
                "title": "Claude 文档：模型总览（Legacy）",
                "url": "https://docs.anthropic.com/claude/docs/models-overview"
            }
        ]
    },
    {
        "modelName": "Claude Opus 4",
        "company": "Anthropic",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-05-22",
        "description": "Claude Opus 4 是 4 代的旗舰推理模型，支持 200K 上下文与 32K 输出，强调复杂问题的分解与深层思考，适合研究类任务、跨文件重构和长程规划；后续由 Opus 4.1 接替并在大多数评测上取得更高分。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "视觉理解",
            "代码增强",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 32,
        "relatedLinks": [
            {
                "title": "Claude Opus 模型页面",
                "url": "https://www.anthropic.com/claude/opus"
            },
            {
                "title": "Claude 4 系列发布公告",
                "url": "https://www.anthropic.com/news/claude-4"
            },
            {
                "title": "Claude 文档：模型总览（Legacy）",
                "url": "https://docs.anthropic.com/claude/docs/models-overview"
            }
        ]
    },
    {
        "modelName": "Claude Sonnet 3.7",
        "company": "Anthropic",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-02-24",
        "description": "Claude Sonnet 3.7 是首个混合推理模型，支持 200K 上下文与 64K 输出（Beta 可到 128K），在编码与工具使用任务上显著提升；SWE-bench Verified 从 33.4% 提升到 49.0%，并引入公开 Beta 的“计算机使用”能力。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "视觉理解",
            "代码增强",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 64,
        "relatedLinks": [
            {
                "title": "Claude Sonnet 模型页面（含 3.7）",
                "url": "https://www.anthropic.com/claude/sonnet"
            },
            {
                "title": "Claude 3.7 系列发布公告",
                "url": "https://www.anthropic.com/news/claude-3-7-sonnet"
            },
            {
                "title": "Claude 文档：模型总览（Legacy）",
                "url": "https://docs.anthropic.com/claude/docs/models-overview"
            }
        ]
    },
    {
        "modelName": "Claude Haiku 3.5",
        "company": "Anthropic",
        "openSourceStatus": "闭源",
        "releaseDate": "2024-10-22",
        "description": "Claude Haiku 3.5 是 3.5 系列的最快模型，支持 200K 上下文与 8K 输出，低时延与更强的指令遵循与工具使用，适合用户界面、子代理与大规模个性化数据处理；在 SWE-bench Verified 达到 40.6%。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "视觉理解",
            "代码增强",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 8,
        "relatedLinks": [
            {
                "title": "Claude 3.5 Haiku 发布",
                "url": "https://www.anthropic.com/news/3-5-models-and-computer-use"
            },
            {
                "title": "Claude 文档：模型总览（Legacy）",
                "url": "https://docs.anthropic.com/claude/docs/models-overview"
            }
        ]
    },
    {
        "modelName": "Claude Sonnet 3.5",
        "company": "Anthropic",
        "openSourceStatus": "闭源",
        "releaseDate": "2024-06-21",
        "description": "Claude Sonnet 3.5 是 3.5 系列的主力中位模型，支持 200K 上下文；在推理、编码与视觉上显著超过 Claude 3 Opus，内部代理编码评测解决率 64%；引入 Claude.ai 的 Artifacts 交互以便实时生成与编辑内容；价格为 $3/MTok 输入、$15/MTok 输出，已在 Claude.ai、iOS、Anthropic API、Amazon Bedrock 与 Vertex AI 上线。",
        "modelTags": [
            "文本生成",
            "视觉理解",
            "代码增强",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 64,
        "relatedLinks": [
            {
                "title": "Claude 3.5 Sonnet 官方发布公告",
                "url": "https://www.anthropic.com/news/claude-3-5-sonnet"
            },
            {
                "title": "Claude Sonnet 模型页面",
                "url": "https://www.anthropic.com/claude/sonnet"
            },
            {
                "title": "Claude 文档：模型总览（Legacy）",
                "url": "https://docs.anthropic.com/claude/docs/models-overview"
            }
        ]
    },
    {
        "modelName": "DeepSeek-R1",
        "company": "DeepSeek",
        "openSourceStatus": "开源",
        "releaseDate": "2025-01-20",
        "description": "DeepSeek-R1 为首代推理模型，通过多阶段冷启动与强化学习显著提升链式思考与复杂推理能力，在数学、代码与自然语言推理任务上达到接近 OpenAI-o1-1217 的水平，并开放 R1 及多个密集蒸馏模型以便研究与部署，适用于高难度问题求解与评测。",
        "modelTags": [
            "文本生成",
            "深度思考"
        ],
        "contextWindow": 64,
        "maxGenerationTokenLength": 16,
        "relatedLinks": [
            {
                "title": "DeepSeek-R1 技术报告（arXiv）",
                "url": "https://arxiv.org/abs/2501.12948"
            },
            {
                "title": "DeepSeek-R1 GitHub 仓库",
                "url": "https://github.com/deepseek-ai/DeepSeek-R1"
            },
            {
                "title": "DeepSeek API 文档（新闻）",
                "url": "https://api-docs.deepseek.com/zh-cn/quick_start/pricing"
            }
        ]
    },
    {
        "modelName": "DeepSeek-V3",
        "company": "DeepSeek",
        "openSourceStatus": "开源",
        "releaseDate": "2024-12-26",
        "description": "DeepSeek-V3 为 671B 总参、每 token 激活 37B 的强力 MoE 大模型，采用 MLA 与 DeepSeekMoE 架构，并创新无辅助损失负载均衡与多 token 预测目标；在 14.8T 语料上预训练并经 SFT 与强化学习优化，生成能力接近闭源前沿模型，适合企业级内容生成与智能体场景。",
        "modelTags": [
            "文本生成",
            "工具调用"
        ],
        "contextWindow": 64,
        "maxGenerationTokenLength": 16,
        "relatedLinks": [
            {
                "title": "DeepSeek-V3 技术报告（arXiv）",
                "url": "https://arxiv.org/abs/2412.19437"
            },
            {
                "title": "DeepSeek-V3 GitHub 仓库",
                "url": "https://github.com/deepseek-ai/DeepSeek-V3"
            },
            {
                "title": "DeepSeek API 文档（模型与价格，含新闻）",
                "url": "https://api-docs.deepseek.com/zh-cn/quick_start/pricing"
            }
        ]
    },
    {
        "modelName": "DeepSeek LLM",
        "company": "DeepSeek",
        "openSourceStatus": "开源",
        "releaseDate": "2024-01-05",
        "description": "DeepSeek LLM ，基于自研长周期 scaling 规律与高质量数据集构建，覆盖 7B/67B 配置，采用 SFT 与 DPO 完成对齐，兼顾中文与英文，并在代码、数学与推理任务上优于同规模开源模型，适用于通用文本生成、检索问答与企业应用部署。",
        "modelTags": [
            "文本生成"
        ],
        "contextWindow": 0,
        "maxGenerationTokenLength": 0,
        "relatedLinks": [
            {
                "title": "DeepSeek LLM 技术报告（arXiv）",
                "url": "https://arxiv.org/abs/2401.02954"
            },
            {
                "title": "DeepSeek LLM GitHub 仓库",
                "url": "https://github.com/deepseek-ai/DeepSeek-LLM"
            }
        ]
    },
    {
        "modelName": "DeepSeek-V2",
        "company": "DeepSeek",
        "openSourceStatus": "开源",
        "releaseDate": "2024-05-07",
        "description": "DeepSeek-V2 为 236B 总参、每 token 激活 21B 的 MoE 大模型，引入 Multi-head Latent Attention 压缩 KV 缓存与 DeepSeekMoE 稀疏计算，支持 128K 长上下文，8.1T 语料预训练并经 SFT+RL 后优化生成质量，适用于长文本处理、对话生成与工具集成。",
        "modelTags": [
            "文本生成"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 8,
        "relatedLinks": [
            {
                "title": "DeepSeek-V2 技术报告（arXiv）",
                "url": "https://arxiv.org/abs/2405.04434"
            },
            {
                "title": "DeepSeek-V2 GitHub 仓库",
                "url": "https://github.com/deepseek-ai/DeepSeek-V2"
            }
        ]
    },
    {
        "modelName": "DeepSeek-V3.2-Exp",
        "company": "DeepSeek",
        "openSourceStatus": "开源",
        "releaseDate": "2025-09-29",
        "description": "DeepSeek-V3.2-Exp 基于 V3.1-Terminus，支持思考/非思考双模式；引入 DeepSeek Sparse Attention（DSA）以提升长上下文训练与推理效率，并在保持输出质量的同时显著降低计算与 API 成本（官方称降价 50%+）；模型在公开评测上与 V3.1-Terminus 表现相当，已在 Web、App 与 API 同步上线，并提供开源权重与技术报告。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "工具调用"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 64,
        "relatedLinks": [
            {
                "title": "DeepSeek-V3.2-Exp 官方发布（API Docs）",
                "url": "https://api-docs.deepseek.com/news/news250929"
            },
            {
                "title": "DeepSeek-V3.2-Exp Hugging Face",
                "url": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp"
            },
            {
                "title": "DeepSeek-V3.2-Exp 技术报告（GitHub PDF）",
                "url": "https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf"
            },
            {
                "title": "DeepSeek API 变更日志",
                "url": "https://api-docs.deepseek.com/updates"
            }
        ],
        "parent": "DeepSeek-V3"
    },
    {
        "modelName": "moonshot-v1-8k",
        "company": "Moonshot AI",
        "openSourceStatus": "闭源",
        "releaseDate": "2024-01-31",
        "description": "moonshot-v1-8k 是 Kimi 的通用文本生成模型，支持 8K 上下文，兼容 Chat Completions 接口，具备稳健指令遵循与长文本处理能力，支持工具调用、JSON Mode 与 Partial Mode，适用于对话问答、摘要整理、内容创作及轻量代码生成等场景。",
        "modelTags": [
            "文本生成",
            "工具调用"
        ],
        "contextWindow": 8,
        "maxGenerationTokenLength": 0,
        "relatedLinks": [
            {
                "title": "主要概念：模型列表（moonshot-v1 系列）",
                "url": "https://platform.moonshot.cn/docs/introduction"
            },
            {
                "title": "为什么要推出 Kimi Latest（提及 moonshot-v1 系列与 128k）",
                "url": "https://platform.moonshot.cn/blog/posts/kimi-latest"
            }
        ]
    },
    {
        "modelName": "moonshot-v1-32k",
        "company": "Moonshot AI",
        "openSourceStatus": "闭源",
        "releaseDate": "2024-01-31",
        "description": "moonshot-v1-32k 面向长文本生成与理解，提供 32K 上下文窗口，兼容 OpenAI 风格 API，支持工具调用、JSON Mode 与 Partial Mode，适合多文档综合、长段落写作、结构化抽取和业务分析等企业级场景。",
        "modelTags": [
            "文本生成",
            "工具调用"
        ],
        "contextWindow": 32,
        "maxGenerationTokenLength": 0,
        "relatedLinks": [
            {
                "title": "主要概念：模型列表（moonshot-v1 系列）",
                "url": "https://platform.moonshot.cn/docs/introduction"
            },
            {
                "title": "开始使用 Kimi API（Chat Completions）",
                "url": "https://platform.moonshot.cn/docs/guide/start-using-kimi-api"
            }
        ]
    },
    {
        "modelName": "moonshot-v1-128k",
        "company": "Moonshot AI",
        "openSourceStatus": "闭源",
        "releaseDate": "2024-01-31",
        "description": "moonshot-v1-128k 提供 128K 超长上下文窗口，适合长文档问答、合同与技术规范解析、跨章节创作与复杂指令任务，支持工具调用、JSON Mode 与 Partial Mode，便于搭建稳定的企业级长文本处理与自动化工作流。",
        "modelTags": [
            "文本生成",
            "工具调用"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 0,
        "relatedLinks": [
            {
                "title": "主要概念：模型列表（moonshot-v1 系列）",
                "url": "https://platform.moonshot.cn/docs/introduction"
            },
            {
                "title": "为什么要推出 Kimi Latest（提及 128k 与 moonshot-v1）",
                "url": "https://platform.moonshot.cn/blog/posts/kimi-latest"
            }
        ]
    },
    {
        "modelName": "moonshot-v1-8k-vision-preview",
        "company": "Moonshot AI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-01-13",
        "description": "moonshot-v1-8k-vision-preview 为图片理解模型，支持 8K 上下文与每张图片固定 1024 Token 计费，具备 OCR、颜色与形状识别等能力，支持多轮对话、流式输出、工具调用与 JSON Mode，适用于票据/表单识别、图表解析、界面截图理解等场景。",
        "modelTags": [
            "视觉理解",
            "文本生成",
            "工具调用"
        ],
        "contextWindow": 8,
        "maxGenerationTokenLength": 0,
        "relatedLinks": [
            {
                "title": "使用 Kimi 视觉模型（Vision）官方指南",
                "url": "https://platform.moonshot.cn/docs/guide/use-kimi-vision-model"
            },
            {
                "title": "开放平台 Changelog：vision 模型上线（2025-01-13）",
                "url": "https://platform.moonshot.cn/blog/posts/changelog"
            }
        ]
    },
    {
        "modelName": "moonshot-v1-32k-vision-preview",
        "company": "Moonshot AI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-01-13",
        "description": "moonshot-v1-32k-vision-preview 在 32K 上下文下提供更稳定的多图理解能力，支持多轮对话、流式输出、工具调用与 JSON Mode；在图像与文本混合输入场景中可进行结构化信息抽取，适用于复杂文档截图解析与业务图像问答。",
        "modelTags": [
            "视觉理解",
            "文本生成",
            "工具调用"
        ],
        "contextWindow": 32,
        "maxGenerationTokenLength": 0,
        "relatedLinks": [
            {
                "title": "使用 Kimi 视觉模型（Vision）官方指南",
                "url": "https://platform.moonshot.cn/docs/guide/use-kimi-vision-model"
            },
            {
                "title": "开放平台 Changelog：vision 模型上线（2025-01-13）",
                "url": "https://platform.moonshot.cn/blog/posts/changelog"
            }
        ]
    },
    {
        "modelName": "moonshot-v1-128k-vision-preview",
        "company": "Moonshot AI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-01-13",
        "description": "moonshot-v1-128k-vision-preview 提供 128K 上下文的图片理解与文本生成能力，支持工具调用、JSON Mode 与 Partial Mode；适合超长任务链与多图融合的视觉问答、复杂图表/界面截图解析与跨页面关联信息抽取等场景。",
        "modelTags": [
            "视觉理解",
            "文本生成",
            "工具调用"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 0,
        "relatedLinks": [
            {
                "title": "使用 Kimi 视觉模型（Vision）官方指南",
                "url": "https://platform.moonshot.cn/docs/guide/use-kimi-vision-model"
            },
            {
                "title": "开放平台 Changelog：vision 模型上线（2025-01-13）",
                "url": "https://platform.moonshot.cn/blog/posts/changelog"
            }
        ]
    },
    {
        "modelName": "kimi-k2",
        "company": "Moonshot AI",
        "openSourceStatus": "开源",
        "releaseDate": "2025-07-11",
        "description": "kimi-k2-0711-preview 为 K2 开源基础版本，采用 1T 总参数、32B 激活参数的 MoE 架构，支持 128K 上下文，面向代码生成、调试与智能体搭建；在工具调用与工作流编排方面表现出色，适合编程助手与复杂任务代理。",
        "modelTags": [
            "代码增强",
            "文本生成",
            "工具调用",
            "深度思考"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 32,
        "relatedLinks": [
            {
                "title": "Kimi K2 技术报告",
                "url": "https://arxiv.org/abs/2507.20534"
            },
            {
                "title": "Kimi K2 模型更新 0905 博客（提及最初 7 月 11 日发布）",
                "url": "https://platform.moonshot.cn/blog/posts/kimi-k2-0905"
            },
            {
                "title": "Kimi K2 Github 地址",
                "url": "https://github.com/moonshotai/kimi-K2"
            }
        ],
        "parent": "kimi-k2"
    },
    {
        "modelName": "kimi-k2-0905-preview",
        "company": "Moonshot AI",
        "openSourceStatus": "开源",
        "releaseDate": "2025-09-05",
        "description": "kimi-k2-0905-preview 是 K2 的升级版本，扩展上下文至 256K，并显著提升 Agentic Coding 能力与前端代码质量；兼容 OpenAI 接口，适合企业级代码生成、自动化运维与多工具协同的智能体工作流。",
        "modelTags": [
            "代码增强",
            "文本生成",
            "工具调用",
            "深度思考"
        ],
        "contextWindow": 256,
        "maxGenerationTokenLength": 32,
        "relatedLinks": [
            {
                "title": "Kimi K2 技术报告",
                "url": "https://arxiv.org/abs/2507.20534"
            },
            {
                "title": "Kimi K2 模型更新 0905 博客（提及最初 7 月 11 日发布）",
                "url": "https://platform.moonshot.cn/blog/posts/kimi-k2-0905"
            },
            {
                "title": "Kimi K2 Github 地址",
                "url": "https://github.com/moonshotai/kimi-K2"
            }
        ],
        "parentModel": "kimi-k2"
    },
    {
        "modelName": "kimi-k2-thinking",
        "company": "Moonshot AI",
        "openSourceStatus": "开源",
        "releaseDate": "2025-11-06",
        "description": "kimi-k2-thinking 为 K2 的长思考模型，提供 256K 上下文，支持多步工具调用与复杂推理，擅长分解任务、稳健输出结构化结果；适用于复杂业务流程编排、长链路问题求解与高可靠智能体系统构建。",
        "modelTags": [
            "深度思考",
            "文本生成",
            "工具调用",
            "代码增强"
        ],
        "contextWindow": 256,
        "maxGenerationTokenLength": 32,
        "relatedLinks": [
            {
                "title": "Kimi K2 快速开始（列出 thinking 版本与 256K）",
                "url": "https://platform.moonshot.cn/docs/guide/kimi-k2-quickstart"
            },
            {
                "title": "开放平台 Changelog：K2 Think 模型发布（2025-11-06）",
                "url": "https://platform.moonshot.cn/blog/posts/changelog"
            },
            {
                "title": "Kimi K2 Thinking 模型 Hugging Face 地址",
                "url": "https://huggingface.co/moonshotai/Kimi-K2-Thinking"
            }
        ],
        "parent": "kimi-k2"
    },
    {
        "modelName": "GPT-4",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2023-03-14",
        "description": "GPT‑4 采用改进 Transformer 与 RLHF 对齐，主版本提供 8K 上下文（另有 32K 版本），在推理与指令遵循、专业评测与内容创作上显著提升，适用于对话、文档理解与应用开发。",
        "modelTags": [
            "文本生成",
            "工具调用"
        ],
        "contextWindow": 8,
        "maxGenerationTokenLength": 4,
        "relatedLinks": [
            {
                "title": "官方页面：GPT‑4",
                "url": "https://openai.com/product/gpt-4"
            },
            {
                "title": "GPT‑4 技术报告（arXiv）",
                "url": "https://arxiv.org/abs/2303.08774"
            }
        ]
    },
    {
        "modelName": "GPT-3.5 Turbo",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2023-11-06",
        "description": "GPT‑3.5 Turbo 是 OpenAI 的经济型通用文本模型，延续 GPT 系列架构并优化聊天与补全，提供 16K 上下文与较低价格和延迟。适合对话系统、摘要改写、轻量检索增强生成与基础内容创作，不支持图像/音频输入及高级工具调用。",
        "modelTags": [
            "文本生成",
            "工具调用"
        ],
        "contextWindow": 16,
        "maxGenerationTokenLength": 4,
        "relatedLinks": [
            {
                "title": "平台文档：GPT‑3.5 Turbo",
                "url": " https://platform.openai.com/docs/models/gpt-3-5-turbo "
            },
            {
                "title": "平台文档：GPT‑3.5 系列概览",
                "url": " https://platform.openai.com/docs/models/gpt-3-5 "
            }
        ]
    },
    {
        "modelName": "GPT-4 Turbo",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2023-11-06",
        "description": "GPT‑4 Turbo 是 OpenAI 推出的高智能多模态大模型，基于改进的 Transformer 训练与 RLHF 后处理，提供 128K 上下文、较低延迟与更低价格。支持文本与图像输入、结构化输出与函数/工具调用，适用于长文档理解、企业智能助理、内容创作与复杂业务流程自动化。",
        "modelTags": [
            "文本生成",
            "视觉理解",
            "工具调用"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 4,
        "relatedLinks": [
            {
                "title": "DevDay 发布：GPT‑4 Turbo 等新模型",
                "url": " https://openai.com/blog/new-models-and-developer-products-announced-at-devday "
            },
            {
                "title": "平台文档：GPT‑4 与 GPT‑4 Turbo",
                "url": " https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo "
            }
        ],
        "parentModel": "GPT-4"
    },
    {
        "modelName": "GPT-4o",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2024-05-13",
        "description": "GPT‑4o 是 OpenAI 的“omni”旗舰模型，“o”代表“o​​mni” 它接受文本、音频、图像和视频的任意组合作为输入，并生成文本、音频和图像的任意组合输出。可在文本、图像与音频间端到端推理，具备 128K 上下文与 16K 输出上限，较 GPT‑4 Turbo 更快且更便宜。支持实时对话、视觉理解与工具调用，适用于语音助手、跨语言对话、图像解析与多模态业务工作流。",
        "modelTags": [
            "文本生成",
            "视觉理解",
            "工具调用"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 16,
        "relatedLinks": [
            {
                "title": "官方介绍：你好 GPT‑4o",
                "url": " https://openai.com/index/hello-gpt-4o/ "
            },
            {
                "title": "平台文档：GPT‑4o",
                "url": " https://platform.openai.com/docs/models/gpt-4o "
            }
        ]
    },
    {
        "modelName": "GPT-4o mini",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2024-07-18",
        "description": "GPT‑4o mini 是面向聚焦任务的小型“omni”模型，提供 128K 上下文与 16K 输出，支持文本与图像输入、文本输出，成本与延迟显著降低，适合微调与蒸馏，在分类、信息抽取、翻译、标签生成及图文混合理解等场景表现稳定。",
        "modelTags": [
            "文本生成",
            "视觉理解",
            "工具调用"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 16,
        "relatedLinks": [
            {
                "title": "平台文档：GPT‑4o mini",
                "url": "https://platform.openai.com/docs/models/gpt-4o-mini"
            },
            {
                "title": "平台文档：GPT‑4o",
                "url": "https://platform.openai.com/docs/models/gpt-4o"
            }
        ],
        "parent": "GPT-4o"
    },
    {
        "modelName": "GPT-4.1",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-04-14",
        "description": "GPT‑4.1 是 OpenAI 提供的最高智能非推理 GPT 模型，支持文本与图像输入、文本输出，具备最长 1M 上下文窗口，并显著提升指令遵循、工具调用与长上下文理解能力。适合企业级智能体、海量文档分析、复杂问答与代码协作等高要求场景。",
        "modelTags": [
            "文本生成",
            "视觉理解",
            "工具调用",
            "代码增强"
        ],
        "contextWindow": 1000,
        "maxGenerationTokenLength": 32,
        "relatedLinks": [
            {
                "title": "官方博文：Introducing GPT‑4.1 in the API",
                "url": " https://openai.com/index/gpt-4-1/ "
            },
            {
                "title": "平台文档：GPT‑4.1",
                "url": " https://platform.openai.com/docs/models/gpt-4.1 "
            }
        ]
    },
    {
        "modelName": "GPT-4.1 mini",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-04-14",
        "description": "GPT‑4.1 mini 是 GPT‑4.1 的更小更快版本，提供 1M 上下文与 32K 输出，擅长指令遵循与工具调用，支持文本与图像输入、文本输出，低延迟且无需推理步骤，适合低时延智能体、长文档处理与结构化结果生成。",
        "modelTags": [
            "文本生成",
            "工具调用",
            "视觉理解",
            "代码增强"
        ],
        "contextWindow": 1000,
        "maxGenerationTokenLength": 32,
        "relatedLinks": [
            {
                "title": "平台文档：GPT‑4.1 mini",
                "url": "https://platform.openai.com/docs/models/gpt-4.1-mini"
            },
            {
                "title": "官方博文：Introducing GPT‑4.1 in the API",
                "url": "https://openai.com/index/gpt-4-1/"
            }
        ],
        "parent": "GPT-4.1"
    },
    {
        "modelName": "GPT-4.1 nano",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-04-14",
        "description": "GPT‑4.1 nano 是 GPT‑4.1 系列中速度最快、成本最低的版本，提供 1M 上下文与 32K 最大输出，擅长指令遵循与工具调用，支持文本与图像输入、文本输出，适合大规模路由、批量处理与结构化结果生成。",
        "modelTags": [
            "文本生成",
            "工具调用",
            "视觉理解",
            "代码增强"
        ],
        "contextWindow": 1000,
        "maxGenerationTokenLength": 32,
        "relatedLinks": [
            {
                "title": "平台文档：GPT‑4.1 nano",
                "url": "https://platform.openai.com/docs/models/gpt-4.1-nano"
            },
            {
                "title": "官方博文：Introducing GPT‑4.1 in the API",
                "url": "https://openai.com/index/gpt-4-1/"
            }
        ],
        "parent": "GPT-4.1"
    },
    {
        "modelName": "GPT-5",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-08-07",
        "description": "GPT‑5 是 OpenAI 迄今最强的编码与智能体任务模型，提供 400K 上下文与 128K 最大输出，支持文本与图像输入、文本输出，并引入最小推理（minimal reasoning）与可控详细程度（verbosity）。在前端生成、复杂工具调用链与大型代码库调试上显著提升，适用于企业级智能体、长文档理解与高质量代码生成。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "视觉理解",
            "代码增强",
            "工具调用"
        ],
        "contextWindow": 400,
        "maxGenerationTokenLength": 128,
        "relatedLinks": [
            {
                "title": "平台文档：GPT‑5",
                "url": "https://platform.openai.com/docs/models/gpt-5"
            },
            {
                "title": "隆重推出 GPT‑5（研究/产品介绍）",
                "url": "https://openai.com/index/introducing-gpt-5/"
            }
        ]
    },
    {
        "modelName": "GPT-5 mini",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-08-07",
        "description": "GPT‑5 mini 是 GPT‑5 的更小更快版本，保持 400K 上下文与 128K 最大输出，适合低延迟任务与聚焦型工作流。支持文本与图像输入、文本输出与工具调用，擅长分类、抽取、摘要与结构化输出，成本友好并适合微调与蒸馏。",
        "modelTags": [
            "文本生成",
            "视觉理解",
            "工具调用"
        ],
        "contextWindow": 400,
        "maxGenerationTokenLength": 128,
        "relatedLinks": [
            {
                "title": "平台文档：GPT‑5 mini",
                "url": "https://platform.openai.com/docs/models/gpt-5-mini"
            },
            {
                "title": "面向开发者的 GPT‑5 发布",
                "url": "https://openai.com/index/introducing-gpt-5-for-developers/"
            }
        ],
        "parent": "GPT-5"
    },
    {
        "modelName": "GPT-5 nano",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-08-07",
        "description": "GPT‑5 nano 为该系列的极速与低成本版本，提供 400K 上下文与 128K 最大输出，支持文本与图像输入、文本输出，适用于大规模推理路由、批量处理与轻量智能体。在结构化抽取、分类与短上下文任务上表现稳定。",
        "modelTags": [
            "文本生成",
            "视觉理解",
            "工具调用"
        ],
        "contextWindow": 400,
        "maxGenerationTokenLength": 128,
        "relatedLinks": [
            {
                "title": "平台文档：GPT‑5 nano",
                "url": "https://platform.openai.com/docs/models/gpt-5-nano"
            },
            {
                "title": "面向开发者的 GPT‑5 发布",
                "url": "https://openai.com/index/introducing-gpt-5-for-developers/"
            }
        ],
        "parent": "GPT-5"
    },
    {
        "modelName": "GPT-5 pro",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-10-06",
        "description": "GPT‑5 pro 为扩展推理版本，提供 400K 上下文与 272K 最大输出，强调更强的多步骤推理、引导式工具使用与长上下文理解能力，适用于复杂分析、合规审阅、企业知识问答与端到端智能体工作流。支持文本与图像输入、文本输出与工具调用。",
        "modelTags": [
            "文本生成",
            "深度思考",
            "视觉理解",
            "工具调用",
            "代码增强"
        ],
        "contextWindow": 400,
        "maxGenerationTokenLength": 272,
        "relatedLinks": [
            {
                "title": "平台文档：GPT‑5 pro",
                "url": "https://platform.openai.com/docs/models/gpt-5-pro"
            },
            {
                "title": "GPT‑5 与智能工作新时代（企业应用）",
                "url": "https://openai.com/index/gpt-5-new-era-of-work/"
            }
        ],
        "parent": "GPT-5"
    },
    {
        "modelName": "GPT-5 Codex",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-08-07",
        "description": "GPT‑5 Codex 面向智能体编码与复杂工程任务，提供 400K 上下文与 128K 最大输出，擅长大型代码库分析、端到端修复与前端界面生成，支持工具调用并在实际编码基准（如 SWE‑bench Verified、Aider polyglot）中表现优异，适用于 IDE 助手与自主演进型编码代理。",
        "modelTags": [
            "文本生成",
            "代码增强",
            "工具调用",
            "视觉理解"
        ],
        "contextWindow": 400,
        "maxGenerationTokenLength": 128,
        "relatedLinks": [
            {
                "title": "平台文档：GPT‑5 Codex",
                "url": "https://platform.openai.com/docs/models/gpt-5-codex"
            },
            {
                "title": "面向开发者的 GPT‑5 发布",
                "url": "https://openai.com/index/introducing-gpt-5-for-developers/"
            }
        ],
        "parent": "GPT-5"
    },
    {
        "modelName": "GPT OSS",
        "company": "OpenAI",
        "openSourceStatus": "开源",
        "releaseDate": "2025-08-05",
        "description": "GPT OSS 是 OpenAI 推出的开放权重模型家族（gpt‑oss‑120b 与 gpt‑oss‑20b），采用 Mixture‑of‑Experts（MoE）架构并对专家权重使用 4‑bit MXFP4 量化。纯文本推理，内置链式思维并支持可调推理强度，适配 Transformers、vLLM、llama.cpp、Ollama 等生态；最长相对位置编码支持 128K。Apache 2.0 许可证，适合私有部署与本地推理。",
        "modelTags": [
            "文本生成",
            "工具调用",
            "代码增强",
            "长上下文"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 128,
        "relatedLinks": [
            {
                "title": "Hugging Face 模型卡：gpt‑oss‑120b",
                "url": "https://huggingface.co/openai/gpt-oss-120b"
            },
            {
                "title": "Hugging Face 模型卡：gpt‑oss‑20b",
                "url": "https://huggingface.co/openai/gpt-oss-20b"
            },
            {
                "title": "公告：欢迎 GPT OSS（Hugging Face）",
                "url": "https://huggingface.co/blog/zh/welcome-openai-gpt-oss"
            }
        ]
    },
    {
        "modelName": "o1",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2024-12-17",
        "description": "o1 系列为通过强化学习训练的推理模型，先思考后回答，擅长复杂多步骤推理、数学、科学与代码分析。提供 200K 上下文与 100K 最大输出，支持文本与图像输入、文本输出。",
        "modelTags": [
            "深度思考",
            "视觉理解",
            "工具调用",
            "文本生成"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 100,
        "relatedLinks": [
            {
                "title": "平台文档：o1",
                "url": "https://platform.openai.com/docs/models/o1"
            }
        ]
    },
    {
        "modelName": "o1-pro",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-03-19",
        "description": "o1‑pro 使用更多算力以提供更优、更稳定的答案，仅在 Responses API 提供，支持多轮思考后再响应，适合耗时更长的复杂问题。规格与 o1 保持一致（200K 上下文，100K 输出）。",
        "modelTags": [
            "深度思考",
            "视觉理解",
            "工具调用",
            "文本生成"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 100,
        "relatedLinks": [
            {
                "title": "平台文档：o1‑pro",
                "url": "https://platform.openai.com/docs/models/o1-pro"
            }
        ],
        "parent": "o1"
    },
    {
        "modelName": "o1-mini",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2024-09-12",
        "description": "o1‑mini 是更快、更实惠的推理模型，提供 128K 上下文与 65K 最大输出（文本 I/O），不支持图像。官方建议在相同成本与延迟下优先使用 o3‑mini。",
        "modelTags": [
            "深度思考",
            "工具调用",
            "文本生成"
        ],
        "contextWindow": 128,
        "maxGenerationTokenLength": 65,
        "relatedLinks": [
            {
                "title": "平台文档：o1‑mini",
                "url": "https://platform.openai.com/docs/models/o1-mini"
            }
        ],
        "parent": "o1"
    },
    {
        "modelName": "o3",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-04-16",
        "description": "o3 是跨领域的强推理模型，为数学、科学、编码与视觉推理设立新标准；支持文本与图像输入、文本输出，适合多步骤分析与技术写作。",
        "modelTags": [
            "深度思考",
            "视觉理解",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 100,
        "relatedLinks": [
            {
                "title": "平台文档：o3",
                "url": "https://platform.openai.com/docs/models/o3"
            }
        ]
    },
    {
        "modelName": "o3-pro",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-06-10",
        "description": "o3‑pro 使用更多算力以获得更优答案，仅在 Responses API 提供；因面向较难问题，部分请求可能需数分钟完成，建议使用后台模式避免超时。规格 200K 上下文、100K 输出。",
        "modelTags": [
            "深度思考",
            "视觉理解",
            "工具调用",
            "文本生成"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 100,
        "relatedLinks": [
            {
                "title": "平台文档：o3‑pro",
                "url": "https://platform.openai.com/docs/models/o3-pro"
            }
        ],
        "parent": "o3"
    },
    {
        "modelName": "o3-mini",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-01-31",
        "description": "o3‑mini 是最新的小型推理模型，在与 o1‑mini 相同成本与延迟下提供更高智能；支持结构化输出、函数调用与批量 API；文本 I/O。",
        "modelTags": [
            "深度思考",
            "工具调用",
            "文本生成"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 100,
        "relatedLinks": [
            {
                "title": "平台文档：o3‑mini",
                "url": "https://platform.openai.com/docs/models/o3-mini"
            }
        ],
        "parent": "o3"
    },
    {
        "modelName": "o3-deep-research",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-06-26",
        "description": "o3‑deep‑research 是最强的深度研究模型，可进行互联网搜索与跨数据源综合（支持 MCP 连接器与自有数据），适合复杂多阶段的研究任务。",
        "modelTags": [
            "深度思考",
            "网络搜索",
            "工具调用",
            "文本生成"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 100,
        "relatedLinks": [
            {
                "title": "平台文档：o3‑deep‑research",
                "url": "https://platform.openai.com/docs/models/o3-deep-research"
            }
        ],
        "parent": "o3"
    },
    {
        "modelName": "o4-mini",
        "company": "OpenAI",
        "openSourceStatus": "闭源",
        "releaseDate": "2025-04-16",
        "description": "o4‑mini 是最新的小型 o 系列推理模型，优化编码与视觉任务的效率与效果；提供 200K 上下文与 100K 输出，支持文本与图像输入；官方说明其后续由 GPT‑5 mini 接任。",
        "modelTags": [
            "深度思考",
            "视觉理解",
            "工具调用"
        ],
        "contextWindow": 200,
        "maxGenerationTokenLength": 100,
        "relatedLinks": [
            {
                "title": "平台文档：o4‑mini",
                "url": "https://platform.openai.com/docs/models/o4-mini"
            }
        ]
    }
]