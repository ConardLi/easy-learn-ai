#### **产品与应用落地**  
##### **OpenAI 发布桌面版 Codex App：不再依赖 VSCode 插件**  
OpenAI 推出 macOS 版 Codex 应用，将多代理并行、工作树（每任务单独分支）、/plan 规划模式、可复用 Skills 与定时 Automations 集成在一个“指挥中心”里，定位是给开发者用的代码代理工作台，而不是传统 IDE 插件。  
 > 相关链接：[官方介绍：Codex App](https://openai.com/index/introducing-the-codex-app/)｜[Codex 产品页](https://openai.com/codex)｜[OpenAI X 公告](https://twitter.com/OpenAI/status/2018385565289267236)｜[OpenAIDevs 功能长帖](https://twitter.com/OpenAIDevs/status/2018385865207419124)  

##### **Windsurf 上线 Arena 模式：在 IDE 里打模型擂台赛**  
Windsurf IDE 推出 Wave 14，新增 Arena 模式，可在同一代码任务上并排比较多模型，并把 Battle Groups 模式一周内设为 0 倍积分消耗。结合个人和公共排行榜，让“用真实任务选模型”取代只看基准分。  
 > 相关链接：[Windsurf 下载页（含 Arena 说明）](https://windsurf.com/download/editor)｜[作者介绍推文](https://xcancel.com/swyx/status/2017342647963431363)  

##### **LM Studio 接入 Anthropic 协议：本地模型假扮 Claude Code**  
LM Studio 0.4.1 新增兼容 Anthropic /v1/messages 的本地接口，Claude Code 等工具只需改 base URL 就能把后端换成本地 GGUF/MLX 模型，同时提供 OpenAI 兼容端点和 TypeScript SDK，方便做第三方插件和本地代理工作流。  
 > 相关链接：[LM Studio 博客：Claude Code 集成](https://lmstudio.ai/blog/claudecode)｜[OpenAI 兼容 SDK](https://lmstudio.ai/gdmka/openai-compat-endpoint)  

##### **PerpetualBooster：不用调参的 GBM，兼容 ONNX/XGBoost**  
Rust 实现的 PerpetualBooster 更新到 v1.1.2，用一个“预算”参数取代一堆超参，宣称在单次训练下可比 LightGBM+Optuna 快 100 倍、精度相近，并支持 R、ONNX 导出和“保存成 XGBoost”以便接入现有生态。  
 > 相关链接：[GitHub](https://github.com/perpetual-ml/perpetual)｜[Reddit 讨论](https://www.reddit.com/r/MachineLearning/comments/1qtr62c/p_perpetualbooster_v112_gbm_without/)  

##### **BCG 内部上线 3.6 万个定制 GPT：咨询公司把 GPT 当基础设施**  
波士顿咨询（BCG）为 3.2 万名顾问部署了 3.6 万+定制 GPT，按岗位和方法论做专门微调，并带项目记忆、可在团队间共享，变成类似“内部 SaaS”。帖子作者强调很多公司还停留在零散试用阶段，和这种体系化规模应用差距不小。  
 > 相关链接：[Reddit 讨论](https://www.reddit.com/r/PromptEngineering/comments/1qsym86/boston_consulting_group_bcg_has_announced_the/)  

##### **AEGIS-FLOW：自动审计 AWS 并生成 Terraform Patch 的安全多代理框架**  
社区项目 AEGIS-FLOW 用 LangGraph+MCP+Next.js 等，做了一个云安全多代理系统：扫描 AWS 配置、给出报告并生成 Terraform 修复补丁，前端实时展示推理轨迹，并在真正改基础设施前强制人类审批。  
 > 相关链接：[在线 Demo（可能不稳定）](http://52.3.229.85:3000)  

##### **Lutum Veritas：主打“无审查+全引用”的深度搜索引擎**  
个人开发的 Lutum Veritas 自称能在约 0.2 美元/次的成本下做比 ChatGPT/Gemini/Perplexity 更深的检索与综述，支持自带 API Key、多模型路由、0% 反爬检测、强制给出来源，并新加 ASK 模式二次核查每条结论。  
 > 相关链接：[项目 GitHub](https://github.com/IamLumae/Project-Lutum-Veritas)  

 

---  


#### **模型与能力**  
##### **StepFun Step‑3.5‑Flash：196B MoE，开源代码代理新热门**  
Step‑3.5‑Flash 是 196B 总参、约 11B 激活的稀疏 MoE，主打长上下文和代理场景，官方称 SWE‑bench Verified 74.4%、Terminal‑Bench 2.0 为 51%。社区实测认为在编码/代理上可比肩 Kimi K2.5、DeepSeek 等，并有 Int4 量化版在 128GB 本机跑 256K 上下文。  
 > 相关链接：[官方发布线程](https://twitter.com/StepFun_ai/status/2018370831538180167)｜[vLLM 日零支持](https://twitter.com/vllm_project/status/2018374448357998874)｜[HF 模型页（FP 版）](https://huggingface.co/stepfun-ai/Step-3.5-Flash)｜[HF 模型页（Int4 版）](https://huggingface.co/stepfun-ai/Step-3.5-Flash-Int4)｜[llama.cpp PR](https://github.com/ggml-org/llama.cpp/pull/19271)  

##### **Moonshot Kimi K2.5：开源推理模型在 Code Arena 登顶**  
Moonshot 的 Kimi K2.5 在 LMArena 的 Code Arena 中成为开源模型第一、总榜第五，社区反馈其代码能力和推理表现接近部分商用闭源模型。Perplexity 也已将 K2.5 接入 Pro/Max，用自家美国节点托管以控制时延与可靠性。  
 > 相关链接：[Arena Code 榜单](https://arena.ai/c/new?chat-modality=code)｜[Perplexity 公告截图](https://cdn.discordapp.com/attachments/1047204950763122820/1466893776105771029/20260130_203015.jpg)  

##### **GLM‑4.7 Flash 被开发者点名：前端/网站交互编码很能打**  
多路反馈称 GLM‑4.7 Flash 在写交互式网页、前端代码时表现突出，推理过程保留得不错，搭配高端模型做 review 是个性价比组合。也有人担心去掉“thinking”会削弱能力，社区常见玩法是 GLM 负责执行、Claude/Kimi 负责审查。  
 > 相关链接：[ggerganov 评价 GLM‑4.7](https://x.com/ggerganov/status/2016903216093417540)  

##### **Claude Sonnet 5 大量“泄露情报”：更便宜、更长上下文、更会写代码？**  
多条日志与帖子显示 Vertex AI 已出现 claude‑sonnet‑5 相关 404，传言称：1M 上下文、比 Opus 4.5 便宜约 50%、基于 TPU 优化吞吐，并在 SWE‑Bench 上达 80.9%。不过社区普遍保持怀疑：ID 通常代表模型创建时间而非发布日期，长上下文精度是否改善仍未知。  
 > 相关链接：[Reddit 讨论一](https://www.reddit.com/r/ClaudeAI/comments/1qtm9ix/sonnet_5_release_on_feb_3/)｜[Reddit 讨论二](https://www.reddit.com/r/singularity/comments/1qtc4jg/sonnet_5_next_week/)  

##### **Falcon‑H1‑Tiny：90M 级别特化微模型，手机和树莓派都能跑**  
TII 发布 Falcon‑H1‑Tiny 系列（＜100M 参数），走“反课程学习”：一开始就注入目标领域数据，配合 Muon（Kimi 同款优化器）和 Hybrid Mamba+Attention 模块。90M 的工具调用模型可做到 94% 相关性检测，600M 推理版在 AIME24 解题率 75%。  
 > 相关链接：[Reddit 介绍](https://www.reddit.com/r/LocalLLaMA/comments/1qsx51z/falconh1tiny_90m_is_out_specialized_micromodels/)  

##### **4chan 语料微调竟然“提智”了？Assistant_Pepe_8B 案例**  
基于 NVIDIA Nemotron 超长上下文版，在扩展 4chan 语料上做微调得到 Assistant_Pepe_8B，作者声称其各项评测全面优于 base。讨论指出：4chan 文本在“我”句子比例、语气等统计特征上独特，可能在语言风格和真话度上带来意外收益，也暴露所谓“对齐税”对小模型影响更大。  
 > 相关链接：[模型页面](https://huggingface.co/SicariusSicariiStuff/Assistant_Pepe_8B)｜[Reddit 讨论](https://www.reddit.com/r/LocalLLaMA/comments/1qsrscu/can_4chan_data_really_improve_a_model_turns_out/)  

 

---  


#### **Agent 与工具链**  
##### **编码代理最佳实践：在 CLAUDE.md 里写清“先写测试再修 bug”**  
多位一线用户现在会在 CLAUDE.md/AGENTS.md 中明确要求：遇到 bug 先写复现测试，再修，再用测试证明。实践反馈这是提升代码代理可靠性、减少“看起来修好了但没测”的单一最有效提示。  
 > 相关链接：[经验贴](https://twitter.com/nbaschez/status/2018027072720130090)  

##### **“指挥家式工程师”：一个人带 5–10 个代理并行写代码**  
有人总结现在的开发模式：人从“写每一行代码”转向像乐队指挥，一次驱动 5–10 个代理并行做任务，很多代码其实没被完整读过。反对意见提醒：人大脑切换成本高，开太多并行线程质量会崩。  
 > 相关链接：[支持观点](https://twitter.com/Yuchenj_UW/status/2018029206542946582)｜[反对观点](https://twitter.com/badlogicgames/status/2018117758991384754)  

##### **OpenClaw 等开源代理框架：好玩，但安全和成本都很“真实”**  
OpenClaw/Moltbook 生态被多次点名：一方面大家在用它搞全自动代理、甚至股票交易；另一方面，安全评估只拿到 2/100 分，还有实战 RedTeam 演练证明记忆文件可被注入、间接执行路径难防，且在 OpenRouter 上很容易把额度瞬间烧光。  
 > 相关链接：[安全审计文章](https://gobrane.com/observing-adversarial-ai-lessons-from-a-live-openclaw-agent-security-audit/)｜[OpenClaw 成本与安全讨论](https://www.perplexity.ai/discover/you/openclaw-ai-assistant-scores-2-AtVX4UYVQMutCst63QBy5g)  

##### **LangChain 推出 deepagents，总结“四种靠谱代理架构模式”**  
LangChain JS 新增 deepagents，声称把 Claude Code、Manus 这类“真的能用”的系统拆成四种常见架构模式，用来替代那种“一个大模型乱调一堆工具”的 naive 写法，并配套观测与评估工具。  
 > 相关链接：[LangChain JS 公告](https://twitter.com/LangChain_JS/status/2018346035240923577)  

##### **RLM（递归语言模型）开始落地：用模型自己跑代码审计**  
社区有人用 Recursive Language Models 做代码安全审计：由模型自己规划、调用工具和子模型，一层层下钻代码库，宣称用像 Kimi K2 这类模型能做到又快又便宜。不过在 DSPy 等框架里，自定义工具调用和 Deno 沙箱权限依然比较折腾。  
 > 相关链接：[RLM 安全审计示例](https://kmad.ai/Recursive-Language-Models-Security-Audit)  

 

---  


#### **基础设施与硬件**  
##### **长上下文推理真正瓶颈是显存而不是算力：1M token 可吃掉 900GB**  
Imperial College + 微软研究综述指出，对 DeepSeek-R1 这类 100 万上下文、批大小 1 的请求，KV cache 显存占用可接近 900GB。对代理/电脑操作任务来说，预填和解码要用不同硬件、甚至拆分成“内存密集 vs 算力密集”的异构架构才现实。  
 > 相关链接：[dair.ai 解读](https://twitter.com/dair_ai/status/2018337881715245507)  

##### **FlashAttention v3 登陆 AMD RDNA GPU，本地推理不再只有 NVIDIA**  
FlashAttention 项目合并了支持 RDNA 的 PR，让 AMD 显卡也能用高效自注意力内核，这对想在桌面机或小型服务器上跑长上下文/大模型的人很关键。  
 > 相关链接：[FlashAttention RDNA PR](https://github.com/Dao-AILab/flash-attention/pull/2178)  

##### **Triton‑Viz 3.0：Tile kernel 调优有了“显微镜”**  
Triton‑Viz 更新到 3.0，支持 Triton 和 Amazon NKI，能可视化每次 load/store/matmul，带 OOB 检测和低效循环 profiler，还做了和 Triton-Puzzles 的 Colab 集成，方便边刷题边看性能。  
 > 相关链接：[Discord 发布贴](https://discord.com/channels/1189498204333543425/1225499141241573447/1467634539164602563)｜[Triton-Puzzles 仓库](https://github.com/srush/Triton-Puzzles)  

##### **sm120 上 TMA+mbarrier 略胜 cp.async，cuBLAS 仍在跑老核**  
社区在 Blackwell(sm120) 上对比实验发现：对大矩阵形状，正确实现 TMA+mbarrier 能略微超过 cp.async 版本，但 cuBLAS 目前似乎仍在使用 sm80 时代的 kernel。实际调优中，一个忘写的 __syncthreads() 就能让核直接死锁。  
 > 相关链接：[GPU Mode 相关讨论一](https://discord.com/channels/1189498204333543425/1189607726595194971/1466969070569127936)｜[GPU Mode 相关讨论二](https://discord.com/channels/1189498204333543425/1189607726595194971/1467248681479569460)  

##### **MIT 用“温差算数”的芯片：用废热做矩阵乘，但精度暂时只有 99%**  
MIT 做出一种用硅片内部温度梯度来做矩阵向量乘的芯片，把热流当计算介质，当前只能做 2×2、3×3 小矩阵，号称数学计算精度 99%+。评论认为这离实用 AI 推理还远，除非能加上强纠错和更大规模阵列。  
 > 相关链接：[Reddit 讨论](https://www.reddit.com/r/singularity/comments/1qtyoyw/mits_new_heatpowered_silicon_chips_achieve_99/)  

##### **Fudan“寿司卷”柔性纤维芯片：一根“头发粗细”可集成 10 万晶体管/厘米**  
复旦团队在 Nature 发表“寿司卷”结构纤维芯片，把电路卷在弹性基底上，一米长纤维能集成相当于传统 CPU 级别的晶体管数，可承受 15.6 吨压、反复弯折和 100℃ 高温，面向智能织物、脑机接口等场景。社区质疑宣传中“比头发还细”的说法和一米长度下的时延问题。  
 > 相关链接：[Reddit 讨论](https://www.reddit.com/r/singularity/comments/1qt28no/shanghai_scientists_create_computer_chip_in_fiber/)  

 

---  


#### **研究与方法**  
##### **“编码代理为什么这么好用”：可验算域 + 工具箱 = 神经符号混搭**  
研究者把代码代理成功归因于两个因素：一是软件世界天然可验证（编译、单测、运行时错误），二是有丰富的“符号工具箱”（shell、编译器、调试器）可供模型调用。要把这套复制到别的领域，就得先造出等价的“工具+验证”层。  
 > 相关链接：[random_walker 讨论](https://twitter.com/random_walker/status/2018342421696766147)  

##### **合成预训练和 RLVR“取之不尽”：从互联网页面造无限推理任务**  
一篇新方法用“遮住推理步骤+生成干扰选项”的方式，把普通网页文本转换成类似 RLVR 的推理任务，号称能“复活”在现有 RLVR 数据上已经饱和的模型，在网络安全等任务上效果好。配合 Dori Alexander 的长文，社区态度是：合成数据问题更多是工程配方，而非“必然坍塌”。  
 > 相关链接：[RLVR 合成任务论文线索](https://twitter.com/iScienceLuvr/status/2018233832437158354)｜[Synthetic pretraining 长文](https://twitter.com/Dorialexander/status/2018018715162288611)  

##### **“别再迷信 perplexity 了”：选模型不能只看下一个 token**  
多位研究者提醒：把 perplexity 当成唯一选模目标会踩坑。即便下一个 token 预测做得越来越好，指令跟随、工具调用稳定性、多轮一致性这些下游行为未必同步提升，甚至可能变差。  
 > 相关链接：[批评 perplexity 的讨论一](https://twitter.com/DamienTeney/status/2018413621361967216)｜[批评 perplexity 的讨论二](https://twitter.com/giffmana/status/2018393065803620662)  

##### **ConceptMoE：先把 token 聚成“概念”，再做 MoE 路由**  
ConceptMoE 框架提出，不必对每个 token 都跑一遍大模型，而是先把相似 token 合成“概念单元”，在概念层做路由和计算，以减少冗余。适合长文和大批量输入时节省算力。  
 > 相关链接：[ConceptMoE 论文介绍](https://twitter.com/gezhang86038849/status/2017110635645968542)  

##### **令牌级数据过滤：Radford 新工作教你“精确选食材”**  
Alec Radford 合作者的工作提出，在预训练阶段做 token 级过滤和权重，而不是粗暴删/加整个数据集，以更细粒度控制模型学到什么能力。属于“从配菜”而不是“换整锅汤”的路线。  
 > 相关链接：[neil_rathi 线程](https://twitter.com/neil_rathi/status/2017286042370683336)  

##### **Brains vs LLM：语言理解竟然分层对齐**  
新发表在 Nature 的工作显示，人脑处理语音时的时间分层，与大模型内部层级激活存在对应关系：越深的层，对应越晚期、越高阶的语言中枢活动。作者认为现代 LLM 已经在复现人类理解语言的核心动力学。  
 > 相关链接：[论文](https://www.nature.com/articles/s41467-025-65518-0)｜[科普文章](https://thedebrief.org/researchers-discover-ai-language-models-are-mirroring-the-human-brains-understanding-of-speech/)  

 

---  


#### **政策、治理与安全**  
##### **OpenClaw 红队实战：记忆文件是最大攻击面**  
一次完全自动的红蓝对抗中，攻击代理先用社工+流水线 RCE 被挡下，随后通过在 JSON 元数据里嵌入 shell 展开变量成功绕过防御。分析指出：OpenClaw 把长期记忆写到 .md 文件，一旦被注入会影响所有后续行为，部署时必须像防 prompt injection 一样隔离凭据和 blast radius。  
 > 相关链接：[完整报告](https://gobrane.com/observing-adversarial-ai-lessons-from-a-live-openclaw-agent-security-audit/)｜[作者实践笔记](https://jw.hn/openclaw)  

##### **Prompt 注入防御思路：嵌入筛选 + 语法约束解码“双保险”**  
BASI 社区有人整理了一套红队练习题，并建议用“嵌入相似度过滤 + Grammar Constrained Decoding”组合防 prompt 注入：前者拦截明显恶意输入，后者直接约束模型能输出的结构，减少被诱导输出危险字符串的空间。  
 > 相关链接：[Adversarial Design Thinking 练习站](https://luisladino.github.io/adversarial-design-thinking/)  

 

---  


#### **行业与公司动态**  
##### **Waymo 被曝正融 160 亿美金，新估值或达 1100 亿**  
消息称 Waymo 正在以约 1100 亿美元估值融资 160 亿，其中至少 130 亿来自谷歌母公司，老股东 Sequoia、DST、Dragoneer 参与。相比 2024 年 10 月 450 亿估值明显抬升，显示自动驾驶在算力和资本开支上的押注仍在继续。  
 > 相关链接：[相关讨论](https://twitter.com/junkbondanalyst/status/2017678491743891594)  

##### **xAI Grok Imagine 1.0：一个月生成 12 亿段视频**  
xAI 公布 Grok Imagine 1.0，可生成 10 秒 720p 带音视频，称过去 30 天平台已经生成超 12 亿段视频。对视频模型推理算力和内容监管都是不小压力。  
 > 相关链接：[Grok Imagine 公告](https://xcancel.com/xai/status/2018164753810764061)  

 

---  

  
