#### **模型与能力**  
##### **阿里发布 Qwen3.5 Medium 系列，多款开源中等体量模型**  
阿里推出 Qwen3.5-Flash、35B-A3B（MoE）、122B-A10B（MoE）、27B（致密）等“更聪明更省算”中等模型：Flash 默认 100 万上下文并带内置工具；社区实测 35B/122B 体验接近甚至超越此前 235B 代际；GGUF、本地量化（含 int4、超低比特）和 SGLang 支持已就位，主打本地与边缘推理性价比。  
 > 相关链接：[阿里官方发布](https://x.com/Alibaba_Qwen/status/2026339351530188939)｜[35B/122B 体验反馈](https://x.com/andrew_n_carr/status/2026347588950372752)｜[35B 超 235B 讨论](https://x.com/awnihannun/status/2026353100144218569)｜[Unsloth GGUF & 量化](https://x.com/UnslothAI/status/2026351337970217357)｜[Qwen3.5-35B-A3B HuggingFace](https://huggingface.co/Qwen/Qwen3.5-35B-A3B)｜[Qwen3.5-122B-A10B HuggingFace](https://huggingface.co/Qwen/Qwen3.5-122B-A10B)｜[Code Arena 排名](https://x.com/arena/status/2026337606137725363)  

##### **OpenAI 上线 GPT‑5.3‑Codex，主打高端代码助手**  
OpenAI 将 GPT‑5.3‑Codex 通过 Responses API 全量开放，社区标注价格约为输入 $1.75 / 输出 $14，每 token 不便宜，定位高端 coding/agent 模型。同时官方扩展了 docx/pptx/csv/xlsx 等文件直接作为上下文输入，方便做“喂真实文件”的智能体。  
 > 相关链接：[OpenAI 开发者公告](https://x.com/OpenAIDevs/status/2026379092661289260)｜[价格与基准讨论](https://x.com/scaling01/status/2026379113099862018)｜[多文件格式输入更新](https://x.com/OpenAIDevs/status/2026420817568084436)  

##### **Inception Mercury 2：以推理扩散架构换取 1000 tok/s 超高速**  
Inception Labs 推出“推理扩散 LLM” Mercury 2，声称在生产环境可达约 1000 tokens/s。第三方测评认为智能水平不是天花板，但在编码和 agent 测试上表现尚可，最大卖点是吞吐和延迟，适合作为多轮 agent、语音助手的高速后端。  
 > 相关链接：[官方介绍](https://x.com/StefanoErmon/status/2026340720064520670)｜[Artificial Analysis 测评](https://x.com/ArtificialAnlys/status/2026360491799621744)  

##### **Liquid AI 发布 LFM2‑24B‑A2B：24B MoE，本地 32GB 卡可跑**  
Liquid AI 上线 LFM2‑24B‑A2B：24B 参数 MoE，每 token 仅激活约 2.3B，目标是在 32GB 显存内高效推理。官方给出的速度是 AMD CPU 约 112 tok/s、H100 约 293 tok/s，已适配 llama.cpp、vLLM、SGLang，多种 GGUF 量化可选，目前仍在继续预训练和后续 RL 阶段。  
 > 相关链接：[模型发布博客](https://www.liquid.ai/blog/lfm2-24b-a2b)｜[HuggingFace 模型页](https://www.reddit.com/r/LocalLLaMA/comments/1rdi26s/liquid_ai_releases_lfm224ba2b/)  

##### **Qwen3.5 在本地与 MLX 生态中的体验：4bit 也能“工业革命”**  
社区实测 Qwen3.5 4bit 在 Mac Studio M3 上可跑到约 34–35 tok/s，提示几乎秒出，被戏称“自己的一场工业革命”。但 MLX 版当前不带视觉能力，仅支持文本；同时小型 Qwen3-VL-2B 模型被用户接到家庭摄像头上，表现出不错的场景理解和叙事能力。  
 > 相关链接：[Qwen 3.5 MLX 体验贴](https://www.reddit.com/r/Qwen_AI/comments/1rcqezx/qwen_35_for_mlx_is_like_its_own_industrial/)｜[Qwen3-VL-2B 摄像头案例](https://www.reddit.com/r/Qwen_AI/comments/1rdnzbe/connected_qwen3vl2binstruct_to_my_security/)  

 

---  


#### **Agent 与工具链**  
##### **Claude Code “远程控制”上线：命令行编码可无缝续到手机**  
Anthropic 给 Claude Code 加了“Remote Control”：你可以在本地终端开启会话，外出时在手机上接着写同一项目，相当于把IDE搬到手机。企业侧还更新了 Cowork/插件，用于团队范围内统一自定义 Claude 工作流。  
 > 相关链接：[功能预告](https://x.com/noahzweben/status/2026371260805271615)｜[官方上线帖](https://x.com/claudeai/status/2026418433911603668)  

##### **Cursor 推出 Cloud Agents：不看 diff，看“演示视频”**  
Cursor 新版本允许代理在云端真实运行你写的程序、跑测试，并回传操作视频而不是一堆 diff，口号是“demos, not diffs”。开发者可以免费使用云环境做自动化调试和演示，但目前 sudo 等高权限操作仍受限，社区在催支持更强的自动化能力。  
 > 相关链接：[Cursor 官方发布](https://x.com/cursor_ai/status/2026369873321013568)｜[Cloud Agents 介绍页](https://cursor.com/onboard)  

##### **OpenAI Responses API 支持 WebSocket，Agent 推理提速约 30%**  
OpenAI 在 Responses API 中开放 WebSocket 通道，有开发者实测整条 agent 工作流加速约 30%。配合新上线的 GPT‑5.3‑Codex 和多格式文件输入，基本就是官方版“长上下文代码/文档代理”栈。  
 > 相关链接：[OpenAI WebSocket 提示](https://x.com/OpenAIDevs/status/2026379092661289260)｜[gdb 的性能测评](https://x.com/gdb/status/2026380170765152302)  

##### **Agent 上下文文件 AGENTS.md 研究：乱写反而拖后腿**  
新论文系统评估了给 Agent 加“AGENTS.md”这类上下文文件的影响：LLM 自动生成的长说明往往让成功率下降、成本上升；人手写的精简说明略有帮助，但同样增加 token 花费。结论是：只写少量关键约束和接口信息，不要堆一大篇“设定小说”。  
 > 相关链接：[论文科普总结](https://x.com/omarsar0/status/2026306141181898887)｜[实用写法指南](https://x.com/_philschmid/status/2026354033418547444)  

##### **OpenRouter 推出 openrouter/free 路由与 GPT‑5.3‑Codex 接入**  
OpenRouter 新增 openrouter/free 路由，会自动选一批免费模型帮你省钱；同时已接入 GPT‑5.3‑Codex，并在模型页上统一展示基准分数与“有效价格”，方便按性能/延迟/成本选模型。  
 > 相关链接：[free 路由说明](https://openrouter.ai/openrouter/free)｜[GPT‑5.3‑Codex on OpenRouter](https://openrouter.ai/openai/gpt-5.3-codex)｜[Rankings & Pricing 页面](https://openrouter.ai/rankings#benchmarks)  

 

---  


#### **基础设施与硬件**  
##### **Meta × AMD 达成 6GW 超大规模 GPU 采购协议**  
Meta 宣布未来五年部署约 6GW 的 AMD Instinct GPU 基础设施（主要是 MI300X），金额估算在数百亿美元级。配套工程博客披露了自研 RRCLLX 通信库，用于大规模 AMD GPU 互联，市场解读为对 NVIDIA 垄断的一次实质性掰腕。  
 > 相关链接：[Meta 官方公告](https://x.com/AIatMeta/status/2026266818789454057)｜[RRCLLX 技术细节](https://engineering.fb.com/2026/02/24/data-center-engineering/rrcclx-innovating-gpu-communications-amd-platforms-meta/)  

##### **MatX 获 5 亿美元 B 轮融资，自研“高带宽+低延迟” LLM 芯片**  
MatX 宣布完成 5 亿美元 B 轮融资，将打造 MatX One 专用 LLM 加速器：采用可拆分的 systolic array，同时利用 SRAM 做低延迟计算、HBM 扛长上下文大带宽。Karpathy 点评称，“算力+两级存储”调度将是未来 token 需求的关键瓶颈之一。  
 > 相关链接：[融资与芯片介绍](https://x.com/reinerpope/status/2026351870852358492)｜[Karpathy 评论](https://x.com/karpathy/status/2026452488434651264)  

##### **FlashAttention-3 官方轮子发布，免编译直接用**  
PyTorch 官方放出了 FlashAttention‑3 预编译轮子，覆盖 CUDA 12.6+/13、x86/ARM、Linux/Windows，并保证 LibTorch ABI 兼容，Python≥3.10、Torch≥2.9 可直接 pip 装。对做自定义内核和高性能推理的同学来说，大幅简化了环境折腾。  
 > 相关链接：[FlashAttention‑3 下载页](https://download.pytorch.org/whl/flash-attn-3/)  

##### **llama.cpp 最新提交“翻车”：Qwen3.5 GGUF 无法加载**  
社区反馈从 master 编译的最新版 llama.cpp 会在加载 Qwen3.5 GGUF 时报 “Failed to read magic”，且不再分配 VRAM，确认与一次溢出修复相关。临时解决方案是回滚到 8145 版本或使用正式 release。  
 > 相关链接：[LM Studio 讨论串](https://discord.com/channels/1110598183144399058/1225909444727013466/1475968015534395505)  

##### **GPU MODE：eBPF 扩展到 GPU、Helion 0.3.0、NCCL/NVSHMEM 实战**  
GPU 开发圈本周热点：eBPF 被研究扩展到 GPU 设备与驱动上下文；PyTorch Helion 0.3.0 带来自适应调优和 Triton‑TileIR 桥接；不少人在摸索 NVSHMEM 的 nvshmem_ptr/put/get 性能差异，以及如何在多 GPU/多节点场景下稳定重现 CUDA 内存错误并调试。  
 > 相关链接：[eBPF for GPU 讲座摘要](https://arxiv.org/abs/2512.12615)｜[Helion v0.3.0 发布](https://github.com/pytorch/helion/releases/tag/v0.3.0)  

 

---  


#### **研究与方法**  
##### **Princeton 等提出“能力–可靠性鸿沟”：模型更强但不更稳**  
新工作把“可靠性”拆成 12 个维度，系统测了多代大模型：能力飙升，但可靠性只小幅改善，典型现象就是 agent 在长尾场景频繁翻车。作者做了线上 dashboard，很多人拿自动驾驶类比：问题不在平均水平，而在极端情况和长链条任务的失败率。  
 > 相关链接：[论文与仪表盘](https://x.com/steverab/status/2026383575080108436)｜[Random Walker 评论](https://x.com/random_walker/status/2026384543700115870)  

##### **OpenClaw 研究：把危险指令拆成小步骤，安全策略就失效**  
一篇安全论文展示了典型 agent 漏洞：如果用户把“删除所有邮件”拆成一串看似安全的例行操作，现有守护策略往往放行，最终依然完成高危操作。作者给出一个开源修复方案，提醒大家在做工具调用/多步骤规划时别只看单步风险。  
 > 相关链接：[论文线程](https://x.com/shi_weiyan/status/2026300129901445196)  

##### **SWE‑bench Multilingual 榜单发布：300 任务、9 语言的编程评测**  
新榜单把软件工程任务扩展到 9 种语言、300 个问题，并刻意避开 SWE‑bench Verified 的数据，当前最佳模型约能解 72%。结果显示模型在不同语言上的排序会反转，对想做全球开发者工具和多语言数据采集的人很有参考价值。  
 > 相关链接：[榜单发布](https://x.com/OfirPress/status/2026324248973689068)｜[更多统计细节](https://x.com/KLieret/status/2026322986907652295)  

##### **OCR 基准被刷满：OmniDocBench 接近天花板但真实文档仍难**  
多方指出 OmniDocBench 上很多模型已到 90%+，但真实复杂 PDF 仍经常翻车，且 exact-match 指标会惩罚语义正确但格式略有差异的输出。有工作表明，对 PDF 问答时先抽文本再喂模型往往比直接图像端到端效果更好。  
 > 相关链接：[llama_index 讨论](https://x.com/llama_index/status/2026342120236396844)｜[PDF QA 研究](https://x.com/cwolferesearch/status/2026344301907583469)  

##### **“Nature 新优化器”遭质疑：基线没调好就宣布碾压**  
一篇发在 Nature 的 MI 优化器论文被多名研究者点名：怀疑其对比的 baseline 学习率等参数没认真调，甚至可能直接在测试集上选超参，导致曲线“好看过头”。不少人呼吁重做实验、用 nanogpt 这类公开 baseline 来复现。  
 > 相关链接：[质疑长帖](https://x.com/giffmana/status/2026223201957597563)｜[补充实验背景](https://x.com/YouJiacheng/status/2026224486367027622)  

 

---  


#### **产品与应用落地**  
##### **Claude Code COBOL 工具一篇博客，让 IBM 股价跌了一成多**  
Anthropic 发文展示用 Claude Code 分析和现代化 COBOL 老系统（如银行主机、ATM 核心），市场一度理解成“自动迁移工具要干掉 IBM 咨询业务”，IBM 股价当日跌超 10%。细看其实只是能力展示，真要迁移仍离不开大量人工审查和风险控制。  
 > 相关链接：[Singularity 讨论串](https://www.reddit.com/r/singularity/comments/1rcz68x/ibm_is_the_latest_company_victim_of_anthropic/)｜[ClaudeAI 相关讨论](https://www.reddit.com/r/ClaudeAI/comments/1rddo3m/anthropic_just_dropped_an_ai_tool_for_cobol_and/)  

##### **Perplexity/Comet 上线新语音模式**  
Perplexity 及其姊妹产品 Comet 推出升级后的语音模式，覆盖所有用户，主打更自然的语音交互体验。与此同时，部分 Pro 用户抱怨配额策略调整后更容易撞上限，认为官方在向高价值企业/Max 用户倾斜。  
 > 相关链接：[语音模式更新](https://fixvx.com/comet/status/2026384898802724878)｜[Perplexity Pro 限额讨论](https://www.perplexity.ai/rest/rate-limit/all)  

##### **安防场景：1GB 级 Qwen3-VL-2B 接摄像头做“文字监控”**  
有开发者用约 0.7GB 的 Qwen3-VL-2B-Instruct（IQ2 量化）接入家庭摄像头，不只是识别人/车，而是输出完整文字叙述，比如“快递员走近门口放下包裹”。整个 pipeline 跑在 MacBook M3 + SharpAI Aegis 上，展示了小视觉模型在边缘端的可用性。  
 > 相关链接：[Reddit 使用案例](https://www.reddit.com/r/Qwen_AI/comments/1rdnzbe/connected_qwen3vl2binstruct_to_my_security/)  

##### **OpenClaw/Manus/kollect 等小工具：从编码助手到“语音填表”**  
生态里涌现不少细分工具：OpenClaw 被用户改造成打印机保养 bot、抢二手表 bot 等自动脚本平台；Manus.im 用户呼吁推出“无限对话”订阅以支撑 Telegram Agent 的高频使用；Kollect 则把传统表单变成实时 AI 对话，用户用自然语言回答问题即可完成问卷。  
 > 相关链接：[OpenClaw showcase 频道](https://discord.com/channels/1456350064065904867/1456609488202105005/1475605224990183464)｜[Manus.im 反馈页](https://manus.im/feedback?source=help_center)｜[Kollect 项目](https://kollect.admildomanuel.com)  

##### **Gemini 应用端更新：2 小时做小游戏，App 加入视频模板**  
有玩家用 Gemini 3.1 Pro 两小时内做出了一个简单的《合金装备》风格小游戏；移动端 Gemini App 则上线了视频模板，方便直接生成适配社媒的视频。虽然底层 Veo 3.1 等模型被吐槽“像十年前的效果”，但对短视频创作者来说门槛进一步降低。  
 > 相关链接：[Gemini 做游戏帖子](https://www.reddit.com/r/Bard/comments/1rd0kkz/gemini_31_pro_created_this_metal_gear_solid_game/)｜[App 视频模板报道](https://9to5google.com/2026/02/23/gemini-video-templates/)  

 

---  


#### **行业与公司动态**  
##### **Anthropic × DeepSeek 等“蒸馏大战”：24k 账号、1600 万对话被点名**  
Anthropic 连发博客和材料，称 DeepSeek、Moonshot、MiniMax 通过 2.4 万个假账号，对 Claude 发起逾 1600 万次调用，用于大规模蒸馏训练，并强调蒸馏过程中安全特性无法完整迁移。社区一边围观“中美开源/闭源大战”，一边吐槽：大家自己训练时也在大规模抓公开数据，很难站在道德高地。  
 > 相关链接：[官方“蒸馏攻击”博客](https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks)｜[Reddit 高赞讨论 1](https://www.reddit.com/r/LocalLLaMA/comments/1rcpmwn/anthropic_weve_identified_industrialscale/)｜[Reddit 高赞讨论 2](https://www.reddit.com/r/singularity/comments/1rcpdwz/anthropic_is_accusing_deepseek_moonshot_ai_kimi/)｜[“只是想反击中国开源叙事”的观点](https://www.reddit.com/r/LocalLLaMA/comments/1rd2x61/people_are_getting_it_wrong_anthropic_doesnt_care/)  

##### **Anthropic 从未开源过 LLM，引发“安全 vs 开放”争论**  
有人盘点发现 Anthropic 从未真正开源过任何 LLM，也没有公开 tokenizer 和多语种细节，对比 OpenAI/Gemini 的部分开源做法，引出“你天天讲安全，却不让外界审计”的吐槽。还有用户指出 Claude 连弯引号这种细节都不支持，影响到特定代码场景。  
 > 相关链接：[相关 Reddit 贴](https://www.reddit.com/r/LocalLLaMA/comments/1rcseh1/fun_fact_anthropic_has_never_opensourced_any_llms/)  

##### **MatX 获 5 亿 B 轮、OpenAI/Meta 投资版图继续扩张**  
除了 MatX One 芯片融资，本周还有分析整理了 SpaceX、OpenAI、Anthropic 等可能上市时对二级市场流动性的巨大压力，以及大厂在 GPU/数据中心上的总投资规模。整体信号：算力和基础设施仍是当前 AI 资本故事的核心。  
 > 相关链接：[MatX 融资线程](https://x.com/reinerpope/status/2026351870852358492)｜[大模型公司 IPO 流动性分析](https://x.com/ttunguz/status/2025982590977823082)  

 

---  


#### **政策、治理与安全**  
##### **Anthropic 的“蒸馏攻击”叙事，被质疑是在为对华限制找理由**  
有人认为 Anthropic 高调曝光 DeepSeek 等“工业级蒸馏攻击”，真正目的不是怕自家模型被学走，而是要对外讲一个故事：中方开源模型之所以强，是因为“偷闭源权重”，从而说服监管加大对中国的算力/芯片出口管制。反方则列出一堆中方论文，说明本土创新并不少。  
 > 相关链接：[“真正目标是舆论战”的讨论](https://www.reddit.com/r/LocalLLaMA/comments/1rd2x61/people_are_getting_it_wrong_anthropic_doesnt_care/)  

##### **蒸馏 vs 版权：用闭源 API 生成数据训练，算不算侵权？**  
多条讨论把“蒸馏攻击”和“用版权文本训练模型”类比：一边是从闭源 API 批量要输出再训练自家模型，一边是从互联网上抓书和代码。有人认为两者本质相似，既然大家都在灰色地带里搞训练，单独把蒸馏扣成“攻击”说服力有限。  
 > 相关链接：[OpenAI/Claude 社区讨论](https://www.reddit.com/r/ClaudeAI/comments/1rd1j8u/anthropic_just_dropped_evidence_that_deepseek/)｜[更多 Reddit 讨论](https://www.reddit.com/r/ClaudeCode/comments/1rcp658/anthropic_weve_identified_industrialscale/)  

##### **AI 安全视角：拆分步骤绕过安全、越狱 prompt 持续进化**  
除了 OpenClaw 的“拆步骤绕过安全”，BASI Jailbreaking 等社区持续在玩 Kimi 2.5、Gemini 3.1 low、DeepSeek 的越狱提示词，典型套路是构造内部角色对话、链式思维冲突，让安全策略和“完成任务”自己打架，最终逼出被禁止内容。  
 > 相关链接：[Kimi/DeepSeek 越狱讨论](https://discord.com/channels/1105891499641684019/1228043845967544380/1475538108857454825)｜[Gemini ENI 越狱技巧](https://discord.com/channels/1105891499641684019/1228043845967544380/1475538108857454825)  

##### **SWE‑bench Verified 正式下线：OpenAI 认定污染严重、不再有用**  
OpenAI 宣布自废自家高频使用的 SWE‑bench Verified 基准，理由是：很多 frontier 模型已经能凭记忆直接给出问题的原始 commit；剩下约 60% 未解问题里，也有大量任务本身就有缺陷。继续在这种榜单上卷，意义不大还费算力。  
 > 相关链接：[OpenAI deprecate 公告](https://x.com/OpenAIDevs/status/2026025368650690932)  

 

---  

  
