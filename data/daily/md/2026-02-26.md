#### **产品与应用落地**  
##### **Perplexity 推出「Computer」：多模型编排的一体化 Agent 工作站**  
Perplexity 上线 Computer，可在一个界面里完成调研、设计、写代码、部署和运维。底层用并行异步子代理 + 协调模型，按任务自动选不同模型，并提供用量计费、支出上限和记忆/文件/工具管理，先向 Max 用户开放。  
 > 相关链接：[产品发布贴](https://x.com/perplexity_ai/status/2026695550771540489)｜[定价与可用性说明](https://x.com/perplexity_ai/status/2026695793537855526)｜[Arav 架构拆解](https://x.com/AravSrinivas/status/2026695864039911684)  

##### **Claude Code 满一岁：从 IDE 助手变成「改造遗留系统」工具**  
Anthropic 强推 Claude Code 作为编码 Agent 基座，并推出面向 COBOL 等遗留系统的现代化方案。虽然只是博客用例，但市场却把它当成会蚕食 IBM 主机服务的信号，导致 IBM 股价一度跌超 10%。实际能否真正改造关键金融系统，还有待长期验证。  
 > 相关链接：[IBM 股价反应讨论 1](https://www.reddit.com/r/singularity/comments/1rcz68x/ibm_is_the_latest_company_victim_of_anthropic/)｜[IBM 股价反应讨论 2](https://www.reddit.com/r/ClaudeAI/comments/1rddo3m/anthropic_just_dropped_an_ai_tool_for_cobol_and/)｜[Claude Code 周年播客](https://youtu.be/x9rWFiIubmc)  

##### **GitHub Copilot CLI 正式 GA，加入仓库级「/research」分析**  
Copilot CLI 宣布 GA，并新增 /research 命令，能基于 GitHub 代码搜索和 MCP 工具，对整个仓库做深度调研，生成报告并导出为 gist。终端标题会实时显示任务状态，更适合日常在命令行里用 AI 看代码。  
 > 相关链接：[功能介绍](https://x.com/_Evan_Boyle/status/2026458533320077689)｜[GA 公告](https://x.com/_Evan_Boyle/status/2026706464375796099)  

##### **Nous 开源 Hermes Agent：本地长记忆多代理工作台**  
Nous 发布 Hermes Agent，开源、Python 实现，支持多级记忆、子代理、文件系统与终端控制、浏览器操作，可在 CLI 和多种 IM 里无缝接续会话。配合 Atropos，可直接做大规模数据生成和 RL 管线。  
 > 相关链接：[GitHub 仓库](https://github.com/nousresearch/hermes-agent)｜[产品公告与免费试用说明](https://portal.nousresearch.com)  

##### **LM Studio 推出 LM Link：用 Tailscale 安全远程调用本地模型**  
LM Studio 新增 LM Link，基于 Tailscale 让你在外网安全访问家里或云主机上的本地 LLM，无需暴露端口，像本地一样加载和调用模型。社区强烈希望补上手机端和不依赖第三方账号的纯本地模式。  
 > 相关链接：[LM Link 说明](https://link.lmstudio.ai)  

 

---  


#### **模型与能力**  
##### **OpenAI 上线 GPT‑5.3‑Codex，主打代码能力与推理速度**  
GPT‑5.3‑Codex 现已在 API 开放，社区实测比 5.2 大约快 25%，同任务用词更少，在 SWE-Bench Pro 等代码基准表现亮眼。价格为输入 $1.75 /M token、输出 $14 /M token，引发「贵但强」的性价比讨论。  
 > 相关链接：[OpenAI Dev 公告](https://x.com/openaidevs/status/2026379092661289260)｜[Cline 使用与基准反馈](https://x.com/cline/status/2026481089158779021)｜[价格讨论](https://x.com/snsf/status/2026513135075746239)  

##### **Qwen 3.5 Medium 系列：开放权重 + 超长上下文 + MoE，本地体验明显提升**  
阿里发布 Qwen3.5 27B/35B‑A3B/122B‑A10B，多路同步接入 vLLM、GGUF、LM Studio、Ollama 等。官方称在 4bit + KV 量化下几乎无损，并支持 80 万～100 万上下文。一线开发者反馈 35B‑A3B 在本地 Agent 工具调用和稳定性上接近商用云模型，且单 token 仅激活约 3B 参数。  
 > 相关链接：[Qwen3.5 Medium 发布与工具支持](https://x.com/Alibaba_Qwen/status/2026496673179181292)｜[长上下文与 FP8 权重说明](https://x.com/Alibaba_Qwen/status/2026502059479179602)｜[本地 Agent 体验评价](https://x.com/victormustar/status/2026624792602808707)｜[Arena 加入 Qwen3.5](https://x.com/arena/status/2026716550812807181)  

##### **Grok‑4.20‑Beta1 在 Arena 夺得搜索榜第一**  
xAI 的 Grok‑4.20‑Beta1 在 Arena Search 排名第 1，得分 1226，超过 GPT‑5.2 与 Gemini‑3；在 Text 榜单上也以 1492 分并列第 4。说明其联网检索与通用问答能力已能与一线闭源模型短兵相接。  
 > 相关链接：[Arena 榜单](https://arena.ai/leaderboard/search)｜[官方公告](https://x.com/arena/status/2026566773496230383)  

##### **Liquid AI 发布 LFM2‑24B‑A2B：2B 有效参数的稀疏 MoE**  
LFM2‑24B‑A2B 是 24B 参数、每 token 只激活 2B 的稀疏 MoE，可在 32GB 内存设备上跑，首日就支持 llama.cpp、vLLM、SGLang 与多种 GGUF 量化。预训练已过 17T token，但仍在继续，之后会升级为 LFM2.5。  
 > 相关链接：[Reddit 介绍与讨论](https://www.reddit.com/r/LocalLLaMA/comments/1rdi26s/liquid_ai_releases_lfm224ba2b/)  

##### **Diffusion LLM 加速引擎：宣称上千 tok/s，架构层面卷推理速度**  
Inception Labs 等团队展示了基于扩散思路的 LLM 推理方案，有研究和宣传称可达到 ~1000 tok/s，并通过如 Ψ-Samplers 之类的推理时标度技术进一步提速。目前更多是前沿实验与论文，真实综合表现仍需社区复现。  
 > 相关链接：[Andrew Ng 点评](https://x.com/AndrewYNg/status/2026478474681262576)｜[速度讨论](https://x.com/kimmonismus/status/2026662718321897974)｜[Diffusion Duality 论文线索](https://x.com/ssahoo_/status/2026487124493742406)  

 

---  


#### **Agent 与工具链**  
##### **Karpathy：编码 Agent 从 2025 年 12 月开始「真的能干活了」**  
Karpathy 描述自己最近用 Agent 从零完成一套本地部署：配 SSH、装 vLLM、拉模型、压测、启服务、上前端、配 systemd、写报告，几乎全程自动。他认为近两个月编码 Agent 在长任务连贯性和「咬住问题不放」上发生了质变。  
 > 相关链接：[Karpathy 线程](https://x.com/karpathy/status/2026731645169185220)  

##### **ActionEngine：把 GUI Agent 变成一次性生成的「程序」，而不是逐步点鼠标**  
ActionEngine 把网页/GUI 操作视作图搜索，先离线探索出状态机，推理时只用一次 LLM 调用生成整段操作程序，声称在成功率、时延和成本上都优于传统逐步视觉 Agent。对「自动点网页」这类场景是另一条路线。  
 > 相关链接：[方法介绍](https://x.com/dair_ai/status/2026678090815123594)  

##### **OpenClaw 与「系统级 Agent」实践：从桌面控制到长记忆栈**  
OpenClaw 被大量个人和团队当成本地「操作系统级」Agent：直接控文件、浏览器和整机。社区一边用它做邮件/CRM/财务自动化，一边担心安全问题——有人给了 root 权限后被它直接清空了回收站，也有人专门写了三层持久记忆栈给它用。  
 > 相关链接：[OpenClaw 使用长贴](https://x.com/matthewberman/status/2026450191759585776)｜[Discord 使用讨论](https://discord.com/channels/1456350064065904867)  

##### **Aider 社区给出的「便宜好用」模型搭配：Deepseek + Kimi + Mimo**  
在 Aider 编码助手中，社区当前推荐：用 Deepseek V3.2 做主力推理（便宜但略慢），mimo‑v2‑flash 做快速文件编辑，难题时用 moonshot Kimi‑k2.5 负责规划、mimo 负责落地代码。这种多模型路由被认为在成本和体验之间比较平衡。  
 > 相关链接：[Aider Discord 讨论](https://discord.com/channels/1131200896827654144/1131200896827654149/1475963283151388722)  

 

---  


#### **基础设施与硬件**  
##### **Karpathy：真正的瓶颈在内存编排，而不是纯算力**  
Karpathy 把大模型算力问题拆成快但小的片上 SRAM 和大但慢的外部 DRAM 两级，指出在长上下文 + 高并发 Agent 场景下，如何在两级内存间调度预填充和解码才是核心难题，当前无论 HBM 路线还是大 SRAM 路线都不好解决。  
 > 相关链接：[完整讨论线程](https://x.com/karpathy/status/2026452488434651264)  

##### **OpenAI 和 Meta 拿到 1.6 亿股 AMD 认股权：相当于「买 GPU 返股票」**  
有分析称，OpenAI 和 Meta 通过和 AMD 的大单 GPU 采购，拿到合计 1.6 亿股的认股权证，行权价目标约 600 美元，理论市值回报可到 1920 亿美元。这相当于 GPU 投资的一种股权返利，进一步绑定算力供应商与大模型公司。  
 > 相关链接：[交易细节分析](https://xcancel.com/ai/status/2026396297540858360?s=12)  

##### **Blackwell GPU 云价格战：Packet.ai 每小时 0.66 美元起**  
Packet.ai 公布 Blackwell GPU 云价：按时计费约 $0.66/小时，或 $199/月包训练。相比直接买 B200 显卡动辄企业级预算，更多个人和小团队转向 Lightning AI 等租赁/集群方案。  
 > 相关链接：[Packet Blackwell 定价](https://packet.ai/blackwell)｜[Lightning AI 集群](https://lightning.ai/clusters)  

##### **Zagora：把互联网散落 GPU 拼成一个大模型训练集群**  
Zagora 正在做分布式微调平台，可在普通公网把零散消费者级 GPU 组合起来训练 70B+ 模型，目前支持 GPT‑OSS、Qwen 2.5、Mistral 等 Transformer 系列，采用类似 Petals/SWARM 的流水线式训练。  
 > 相关链接：[项目介绍](https://huggingface.co/spaces/zagora)  

 

---  


#### **研究与方法**  
##### **Agent 可靠性研究：能力涨很快，但「不翻车」没涨多少**  
多篇工作指出，模型在基准分数上狂飙的同时，可靠性提升并不明显：Agent 常因一次工具调用偏离轨道，之后错误越滚越大。有人呼吁做「极其简单但必须严格遵守」的最小安全基准，例如在大量无关上下文里也绝不乱发邮件。  
 > 相关链接：[可靠性综述讨论](https://x.com/IEthics/status/2026435186704134617)｜[失败模式总结](https://x.com/omarsar0/status/2026471955319189861)｜[最小安全基准提案](https://x.com/jonasgeiping/status/2026714911951220888)  

##### **Trace‑Free+：先教模型「重写工具说明」，再让 Agent 去用工具**  
Intuit 研究发现，同一模型在工具调用上的表现，很大程度取决于工具描述文案。Trace‑Free+ 用课程式训练，让模型先学会把复杂工具说明改写成 Agent 易用的格式，推理时不需要额外 trace，就能在多工具场景中稳一点。  
 > 相关链接：[方法介绍](https://x.com/omarsar0/status/2026676835539628465)  

##### **Goodfire：在万亿参数规模做可解释性，不压垮推理性能**  
Goodfire 展示了可在极大模型上采集数十亿激活值的基础设施，对推理延迟影响很小，还给出一个用激活分析实时「掰正」思维链的案例。这种工程化的可解释性，更多是给安全和调试团队用，而不是学术小玩具。  
 > 相关链接：[技术线程](https://x.com/GoodfireAI/status/2026748839303246238)  

##### **Midtraining：夹在预训练和指令微调之间的一小段训练，效果很敏感**  
新论文把「中途再训一段」系统化成 midtraining，发现放在预训练和后训练之间，能减轻遗忘和提升下游表现，但对时机和数据分布非常敏感，乱插一段反而有害。说明大模型训练流程已经越来越像精细工艺。  
 > 相关链接：[论文预印本](https://arxiv.org/abs/2507.06203)  

##### **Diffusion/Flow Matching 系列综述：扩散不只做图，也在重写 LLM 训练范式**  
Eleuther 社区整理了近几年扩散与 Flow Matching 相关工作，从 Rectified Flows、Flow Matching 到 Diffusion Forcing，以及字节、腾讯等团队的新论文，外加一套讲解视频 playlist，方便系统补课。  
 > 相关链接：[Rectified Flows 与 Flow Matching](https://arxiv.org/abs/2209.03003)｜[Diffusion Forcing](https://arxiv.org/abs/2407.01392)｜[讨论与资源清单](https://youtube.com/playlist?list=PL57nT7tSGAAUDnli1LhTOoCxlEPGS19vH)  

 

---  


#### **行业与公司动态**  
##### **Anthropic 收购 Vercept，加强 Claude「用电脑」能力**  
Anthropic 收购专做电脑操作 Agent 的 Vercept。创始人称目标是让 AI 不再只给步骤建议，而是真正替用户点界面、跑任务，尤其是对不懂技术的用户。对应的是 Claude Code、Claude Tools 这条产品线的进一步夯实。  
 > 相关链接：[Anthropic 公告](https://x.com/AnthropicAI/status/2026705792033026465)｜[Vercept 创始人回顾](https://x.com/ehsanik/status/2026712952699760808)  

##### **Wayve 再融 15 亿美元：Embodied AI 要从自动驾驶扩展到通用机器人**  
英国自动驾驶公司 Wayve 完成 15 亿美元 D 轮，估值 86 亿美元，投资方包括软银、微软、NVIDIA、Uber。计划 2026 年在 10 座城市开启有人监控的 robotaxi 试运营，2027 年开始把 Embodied AI 软硬件卖给车厂和机器人厂家。  
 > 相关链接：[融资与路线说明](https://x.com/alexgkendall/status/2026447299711578450)  

##### **Quiver AI 融 830 万美元，做「一键把图片/文案变成 SVG」**  
a16z 领投的 Quiver AI 公布 830 万美元种子轮，并发布首个 Arrow‑1.0 模型：输入设计草图或文字描述，输出可编辑的 SVG 矢量图，面向 UI/海报/图标等场景，对前端和设计师可能是个高频工具。  
 > 相关链接：[融资与模型发布](https://x.com/joanrod_ai/status/2026693353090240819?s=20)  

 

---  


#### **政策、治理与安全**  
##### **美国国防部与 xAI/Grok、Anthropic、OpenAI 谈判：AI 军事用途红线被推上台面**  
多篇报道称：五角大楼已与 xAI 达成协议，把 Grok 用于涉密系统，并要求 Anthropic 允许 Claude「所有合法用途」，包括大规模监控与武器研发。Anthropic 公开坚持不做大规模监控和自主武器，因此被威胁动用《国防生产法》或列为供应链风险。  
 > 相关链接：[xAI 与五角大楼合作报道](https://www.reddit.com/r/singularity/comments/1rd9mss/xai_and_pentagon_reach_deal_to_use_grok_in/)｜[针对 Anthropic 的最后通牒](https://www.reddit.com/r/OpenAI/comments/1re686c/exclusive_hegseth_gives_anthropic_until_friday_to/)｜[更多社区讨论](https://www.reddit.com/r/ClaudeAI/comments/1recva7/pentagon_claude_and_the_military_use/)  

##### **Anthropic 下调 RSP 约束，被批「安全承诺扛不住商业压力」**  
TIME 报道，Anthropic 放弃了其负责任扩展政策中最激进的一条：在无法证明足够安全前不继续训练更强模型。首席科学家称，在竞争对手不跟进的情况下，单边承诺不可持续。社区有人认为是对现实妥协，也有人认为这是全球统一监管缺位的副作用。  
 > 相关链接：[TIME 报道](https://time.com/collections/time100-companies-2024/6980000/anthropic-2/)｜[社区讨论](https://www.reddit.com/r/ClaudeAI/comments/1rdwdld/time_anthropic_drops_flagship_safety_pledge/)  

##### **AI + 监控：Jeff Dean 公开反对大规模监控用途**  
Jeff Dean 在 X 上明确表示，大规模监控会压制言论自由、易被滥用，也违反宪法精神。与此同时，社区有人担心，一旦把执行权交给不能拒绝「违法命令」的 Agent，警务/监控系统会变得更难约束。  
 > 相关链接：[Jeff Dean 表态](https://x.com/JeffDean/status/2026566490619879574)｜[相关风险讨论](https://x.com/BlackHC/status/2026456906710327338)  

##### **大模型能源约束浮出水面：美国考虑要求 AI 公司自建电源**  
有消息称，美国政府担心数据中心和 AI 负载把电网拖垮，开始推动大型 AI/云厂商自担供电能力，以免公众为电价上涨买单。说明模型扩展已经不再只是算法和 GPU 问题，而是基础设施与能源政策问题。  
 > 相关链接：[能源压力与自供电传闻](https://x.com/kimmonismus/status/2026720759163298282)  

##### **红队与 Jailbreak 自动化：自更新越狱代理引发巨大合规风险**  
BASI 社区有人用 OpenClaw + DeepSeek‑R1 搭了自更新的「越狱代理」，自动为 Claude、GPT、Gemini、Grok 等生成多轮隐蔽越狱提示。同行在审阅中直言：这几乎踩遍所有厂商 TOS，一旦 VPS 被查封，日志、恶意模型和缺少回滚方案都会是大坑。  
 > 相关链接：[方案讨论（general）](https://discord.com/channels/1105891499641684019/1235691879492751460/1475945444138942689)｜[风险评审（redteaming）](https://discord.com/channels/1105891499641684019/1204553141354504193/1475980802687893535)  

 

---  

  
