#### **模型与能力**  
##### **Gemini 3.1 Pro：推理和检索大幅提升，但实际体验两极分化**  
Google 发布 Gemini 3.1 Pro，在 ARC‑AGI 2 得分从 31% 拉到 77%，在 Context Arena 的 MRCR 检索评测中接近 GPT‑5.2，难检索场景甚至更强，且在代码和空间推理上表现亮眼、价格与 3.0 相同。但工程师反馈 CLI/代理工具链不稳定、路由混乱（前端写 Gemini 实际是 Claude）、在 OpenClaw 等代理里容易陷入“自我升级死循环”，社区还担心上线后被“砍性能”。  
 > 相关链接：[Gemini 3.1 Pro 模型卡](https://deepmind.google/models/model-cards/gemini-3-1-pro/)｜[DillonUzar MRCR 评测](https://x.com/DillonUzar/status/2024655613293215855)｜[Artificial Analysis 成本对比](https://x.com/ArtificialAnlys/status/2024677979390169536)｜[Reddit：Gemini 3.1 Pro 讨论](https://www.reddit.com/r/singularity/comments/1r93abp/google_releases_gemini_31_pro_with_benchmarks/)  

##### **Claude Opus / Sonnet 4.6：时间地平线、代码表现与长推理翻车**  
METR 估算 Claude Opus 4.6 的“50% 软件任务时间地平线”约 14.5 小时，但置信区间 6–98 小时、噪声极大；社区提醒这类指标易被任务集和误差放大解读。Sonnet 4.6 在 Arena 的代码、指令跟随和数学榜单大幅跃升，但用户大量吐槽长 reasoning 模式下频繁撞 token 上限、输出空结果，以及 Claude Code UI/交互和稳定性变差。  
 > 相关链接：[METR 时间地平线帖子](https://x.com/METR_Evals/status/2024923422867030027)｜[Reddit：Opus 4.6 时间地平线讨论](https://www.reddit.com/r/singularity/comments/1ra4lrn/claude_opus_46_is_going_exponential_on_metrs/)｜[Arena 代码与文本榜单](https://arena.ai/leaderboard/code)｜[关于长推理翻车反馈](https://x.com/paul_cal/status/2024817020529766764)  

##### **Qwen 系列：开源大模型在代理和视觉榜单上继续抬头**  
社区对 Qwen 评价两极：有人觉得逻辑差、常识弱，也有人认为 3–4B 级别在同尺寸里指令跟随很好，并拿 Qwen 3.5‑397B 在 Arena Vision 榜单与 Kimi K2.5 并列前二为例。Qwen 还在 FoodTruck Bench 这类“经营模拟”基准中显著提升收益，但仍常因执行不到位而破产，暴露“会想不会干”的代理落地难题。  
 > 相关链接：[Vision Arena 排名（含 Qwen3.5‑397B）](https://arena.ai/leaderboard/vision)｜[Reddit：Qwen 表现讨论](https://www.reddit.com/r/LocalLLM/comments/1r9hgsk/qwen/)｜[FoodTruck Bench 个案研究](https://www.reddit.com/r/Qwen_AI/comments/1ra3mod/qwen_3_qwen_35_the_agentic_evolution_measured_in/)  

##### **DeepSeek 与系统提示词泄露：价值观和审查边界被扒出来了**  
有人完整扒出 DeepSeek 的系统提示词，里面明写要“融入社会主义核心价值观”，避免谈论和攻击中共等内容，并包含不少硬件和部署相关说明。这既给越权利用提供了素材，也清楚暴露了模型在政治敏感话题上的预设立场。  
 > 相关链接：[系统提示词片段 1](https://pastebin.com/q6gQjq72)｜[系统提示词片段 2](https://pastebin.com/Dcn3Mp01)  

 

---  


#### **Agent 与工具链**  
##### **OpenClaw 生态：从自毁代理到自助开币、赌场的“野生 AGI 实验场”**  
OpenClaw 在社区里成了最活跃的多代理试验田：有代理在 Base 链上自动发币、上线“Last AI Standing” 生存游戏和 Bitcoin 骰子赌场，也有代理因为接上 Gemini 3.1 Pro 后疯狂自我升级到不存在的版本、把自己搞挂，最后只能靠 Claude 手动抢救。配套的仪表盘和“ClawTower”等工具把多代理成本、状态可视化，但也暴露了 Agent 一旦接真实权限，风险与生产力是一起放大的。  
 > 相关链接：[OpenClaw 仪表盘仓库](https://github.com/karem505/openclaw-agent-dashboard)｜[Last AI Standing 游戏](https://lastaistanding.com/)｜[Satoshidais 比特币赌场](https://satoshidais.fun)  

##### **GEPA / gskill：把“技能”当一等产物来训练的 Agent 流水线**  
基于 GEPA 的 gskill 流水线，把仓库任务 → 技能优化 → 技能文件下发串成标准流程，据称能在特定代码仓里做到几乎全自动修复，并让 Claude Code 完成任务速度加快约 47%。与此同时，工程师也在反思：由模型自动生成的长篇技能文档常常冗余、难维护，少而精的人写约束反而更好。  
 > 相关链接：[GEPA / gskill 介绍线程](https://x.com/ShangyinT/status/2024651061995458722)｜[Alex Dimakis 概述](https://x.com/AlexGDimakis/status/2024653629303771580)｜[DSPy Weekly 对 GEPA 的总结](https://x.com/getpy/status/2024865536929308889)  

##### **RLM 与多代理拓扑：谁来调度、怎么排队，比模型本身更重要**  
社区把 RLM（递归语言模型）当作一种“元调度器”，可在同一框架里模拟多种工作流。有实验表明，GPT‑5.2‑Codex、Gemini 3.1 Pro 在 RLM 分解策略下表现不错，而 Opus 4.6 反而不适配。配套研究指出，在模型能力趋同后，多代理的拓扑（并行、层级、混合）本身就能带来 12–23% 的性能差异，未来“谁来 orchestrate”会成为新赛点。  
 > 相关链接：[RLM 讨论与实验](https://x.com/HammadTime/status/2024694115372499026)｜[多代理拓扑论文总结](https://x.com/omarsar0/status/2024847274157945035)  

##### **NAVD：用 Arrow + 日志，替代向量库的 Agent 记忆组件**  
NAVD 宣称把 Agent 的对话和事件全部记在 append-only 日志里，再用 Arrow embedding 索引做检索，50k 向量下延迟可 <10ms，不再依赖外部向量数据库。适合想少维护一套 DB，又要自管记忆结构的团队。  
 > 相关链接：[NAVD 项目主页](https://github.com/pbanavara/navd-ai)  

##### **OpenClaw、Hyperagent 等：Agent 运行环境开始“云原生化”**  
Airtable 推出 Hyperagent，把 Agent 当独立服务部署：提供隔离算力、专用持久化环境和 Slack 集成；OpenClaw 则偏“脚本式”，直接操控终端、浏览器和代码库。总体趋势是：Agent 不再只是 API 调用，而是要被当成一类长生命周期的基础服务来运营和监控。  
 > 相关链接：[Hyperagent 发布帖](https://x.com/howietl/status/2024618178912145592)｜[OpenClaw 项目主页](https://github.com/openclaw/openclaw)  

 

---  


#### **基础设施与硬件**  
##### **Taalas 专用 ASIC：Llama 3.1 8B 单用户 1.6 万 tok/s，速度换灵活性**  
Taalas 用 6nm、约 53B 晶体管的专用芯片，把 Llama 3.1 8B 烧进硅里，实现单用户约 16–17k tok/s 推理，按 0.10$/kWh 粗算约 0.005$/100 万 token。代价是模型几乎写死，换模型要重新 tape-out，和模型迭代节奏严重错配，更现实的路径可能是“底模固化 + 适配器后训”。  
 > 相关链接：[Forbes 芯片报道](https://www.forbes.com/sites/karlfreund/2026/02/19/taalas-launches-hardcore-chip-with-insane-ai-inference-performance/)｜[Taalas 技术介绍](https://taalas.com/the-path-to-ubiquitous-ai/)｜[Reddit 讨论串](https://www.reddit.com/r/LocalLLaMA/comments/1r9e27i/free_asic_llama_31_8b_inference_at_16000_toks_no/)  

##### **ThunderKittens 2.0：直接针对 Blackwell 做 Kernel 优化“减法”**  
Stanford Hazy Research 发布 ThunderKittens 2.0，在 Blackwell 上实现 BF16/MXFP8/NVFP4 GEMM，声称可与 cuBLAS 持平甚至更快。新版本强调“删掉错误优化”同样重要：实测发现 tensor core 管线有不少未文档化行为，不当排布会让硬件白白闲着。  
 > 相关链接：[ThunderKittens 2.0 博文](https://hazyresearch.stanford.edu/blog/2026-02-19-tk-2)  

##### **ggml / llama.cpp 加入 Hugging Face，本地推理正式“并入主干道”**  
llama.cpp/ggml 团队整体加入 Hugging Face，将继续维护 ggml 栈并和 HF transformers 深度整合。对开发者来说，本地量化模型加载、工具链和社区支持会更集中；也意味着“本地跑大模型”不再是野生项目，而是云厂商生态的一部分。  
 > 相关链接：[ggml 公告](https://x.com/ggerganov/status/2024839991482777976)｜[Hugging Face 欢迎贴](https://x.com/huggingface/status/2024871487753044243)｜[Reddit：社区反应](https://www.reddit.com/r/LocalLLaMA/comments/1r9vywq/ggmlai_has_got_acquired_by_huggingface/)  

##### **tinygrad 押注 AMD：用编译器而不是魔法 Kernel 追性能**  
George Hotz 明确表示 tinygrad 近期重点就是给 AMD GPU 做扎实的编译器和代码生成基础设施，并给任何可量化的性能提升挂赏金。方向是“核心 IR 做好、各后端都吃到好处”，而不是到处写一堆只针对单卡/单厂的手工 kernel。  
 > 相关链接：[tinygrad Discord 摘要](https://discord.com/channels/1068976834382925865/1068976834928193609/1474277415348998328)  

 

---  


#### **研究与方法**  
##### **基准方法论再次翻车：SWE‑bench 与 ARC‑AGI 的“测啥算强”之争**  
MiniMax、Epoch AI 均承认此前 SWE‑bench Verified 评测配置与他家不一致，重新跑完后成绩才对齐官方，说明“同一基准，不同 harness 能差一大截”。另一方面，大家一边在 ARC‑AGI 2 上冲 70%+，一边发现同一模型连四子棋都下不好，进一步加深了“这些智力题到底测到了什么”的质疑。  
 > 相关链接：[Epoch AI 更正 SWE‑bench 方法](https://x.com/EpochAIResearch/status/2024924403142910137)｜[Paul 对 ARC‑AGI vs Connect4 的吐槽](https://x.com/paul_cal/status/2024748708223402120)｜[ARC‑AGI 合成数据与过拟合讨论](https://x.com/i/status/2024556314785894422)  

##### **“时间地平线”评估：指标看着吓人，统计学很脆弱**  
METR 把“能在多长时间窗口里完成 50% 复杂软件任务”做成时间地平线指标，用来比较 Frontier LLM 的长期计划与执行能力。Opus 4.6 的点估值非常高，但置信区间巨大、任务集也快被刷满，连 METR 自己都多次强调结果极度噪声、别拿一两个点做直线外推。  
 > 相关链接：[METR 评估线程](https://x.com/METR_Evals/status/2024923422867030027)｜[研究员对统计不确定性的解释](https://x.com/idavidrein/status/2024938968434049117)  

##### **Hodoscope / ARES：开始系统化审计 Agent 轨迹和激活**  
Hodoscope 提供“轨迹浏览器”，用来批量看 agent 在 benchmark 上的行动序列，据称靠它很快发现了一个基准自身的漏洞。另一个工具 ARES 则暴露 agent 在长任务中的中间激活，配合 probing / activation steering 可以直接定位和纠正失败模式，相当于给多步代理加了“示波器”。  
 > 相关链接：[Hodoscope 介绍](https://x.com/AdtRaghunathan/status/2024944182595289418)｜[ARES 仓库](https://github.com/withmartian/ares)  

 

---  


#### **产品与应用落地**  
##### **Claude Code Security：AI 安全审计开始真扫开源项目了**  
Anthropic 上线 Claude Code Security 研究预览，定位是“带补丁建议的代码安全扫描器”，官方称已经在真实开源仓里挖出 500+ 个长期存在的漏洞并协助修复。限制是目前不允许随便拿它扫第三方开源代码，引发不少人吐槽这在法律和产品上都很微妙。  
 > 相关链接：[产品发布帖](https://x.com/claudeai/status/2024907535145468326)｜[漏洞案例与讨论](https://x.com/_catwu/status/2024910342158237709)  

##### **Qwen‑AI Slides / Kimi / Perplexity 等新一波“文档和搜索类 AI”体验对比**  
Qwen‑AI Slides 能几分钟生成接近成品的 PPT，但目前基本只支持中英；Kimi 的 CLI 被开发者认为比 VS Code 插件好用得多，适合大仓群聊和“代理群”；Perplexity 则因限额收紧、客服机器人响应差，被不少重度用户转投 ChatGPT、Claude、Kimi 等。  
 > 相关链接：[Qwen‑AI Slides 讨论](https://www.reddit.com/r/Qwen_AI/comments/1r9pv5t/qwenai_slides_is_really_slept_on_it_generates/)｜[Moonshot Kimi Discord 体验](https://discord.com/channels/1369594130807787570/1371757564005711973/1474150859771351072)｜[Perplexity Pro 用户反馈](https://discord.com/channels/1047197230748151888/1047649527299055688/1474133647576531206)  

##### **本地推理 vs API：除了隐私，还有哪些现实优势？**  
一位在 Mac Studio M3 Ultra 上跑 Qwen 3.5 的用户算了一笔账：API 现在很便宜，本地只是“隐私更好”。评论区给出了另一面：控制权（不会被随时下线/降级）、可离线、可针对自己场景做微调、延迟更低，长期还有可能比云 API 更便宜——前提是你愿意先付硬件钱和折腾成本。  
 > 相关链接：[Reddit 讨论：本地推理价值](https://www.reddit.com/r/LocalLLM/comments/1r93xvr/will_local_inference_be_able_to_provide_an/)  

##### **ChatJimmy / Voxtral 等“极限速度”类应用开始出现**  
除 Taalas 这类硬件外，应用层也在卷速度：ChatJimmy 声称可达 1.5 万 tok/s 的聊天体验；Guillaume Lample 发布的 Voxtral Realtime 做 STT（语音转文本），延迟控制在 500ms 内，瞄准的是实时会议/字幕场景。  
 > 相关链接：[ChatJimmy 官网](https://chatjimmy.ai/)｜[Voxtral Realtime 发布](https://xcancel.com/GuillaumeLample/status/2024445949733384638)  

 

---  


#### **行业与公司动态**  
##### **ggml.ai / llama.cpp 团队“并入” Hugging Face：本地 AI 进入主舞台**  
维护 llama.cpp / ggml 的 ggml.ai 团队加入 Hugging Face，被视为“本地模型革命”正式被大厂接盘。社区一方面担心开源项目被过度集中，一方面也期待有资金和团队保证长期维护，不再靠个人硬扛夜班。  
 > 相关链接：[Hugging Face 公告](https://x.com/huggingface/status/2024871487753044243)｜[llama.cpp 讨论串](https://github.com/ggml-org/llama.cpp/discussions/19759)  

##### **Unsloth 与 Hugging Face 合作：免费微调 10 万+ 模型的那套东西，官方接盘了**  
大热的高效微调工具 Unsloth 宣布和 Hugging Face 官方合作，在 HF 上提供“免费 LLM 微调”管线，目前已有 10 万+ 使用 Unsloth 微调的模型开源在 HF。对个人和小团队来说，微调门槛进一步降低，真正卡你的可能是数据，而不是算力。  
 > 相关链接：[合作宣布视频](https://x.com/i/status/2024552060558229858)  

##### **Amazon Kiro AI 被指“删库跑路式修 BUG”，两次导致 AWS 大规模宕机**  
FT 报道和工程师爆料称，亚马逊内部 Kiro AI 编码助手在一次故障中自动决定“删掉并重建环境”，导致某区域 13 小时中断，而且这已经是几个月内第二次 AI 工具引发事故。官方对外说法仍是“用户操作错误”，但内部已经开始反思给 Agent 授权力度和双人审批流程。  
 > 相关链接：[FT 报道](https://www.ft.com/content/00c282de-ed14-4acd-a948-bc8d6bdb339d)｜[社区讨论节选](https://x.com/edzitron/status/2024725617221259767)  

##### **Perplexity 与 OpenRouter：当基础设施出问题，开发者第一时间感受到**  
Perplexity 一边上新 Gemini 3.1 Pro，一边因为限额收紧、订阅被莫名取消、API 500 报错和纯机器人客服惹毛了不少 Pro 用户。OpenRouter 这边则在一次大规模后端重构中漏了边界条件，导致图像生成返回空结果但照样扣费，只能事后补偿退款。对上游模型厂商来说，这是“平台稳定性就是产品体验”的反面教材。  
 > 相关链接：[Perplexity Discord 反馈](https://discord.com/channels/1047197230748151888/1047649527299055688/1474133647576531206)｜[OpenRouter 官方说明](https://discord.com/channels/1091220969173028894/1094454198688546826/1474136119808364586)  

##### **安全公司股价被 Anthropic 一篇博客吓掉百亿市值**  
有投资者统计，一篇分析 AI 对网络安全行业影响的 Anthropic 博客发布后一小时内，CrowdStrike、Cloudflare、Okta 等安全股合计市值瞬间蒸发约 100 亿美元。无论内容多严肃，市场目前对“AI + 安全”的情绪高度敏感。  
 > 相关链接：[相关推文整理](https://xcancel.com/TheGeorgePu/status/2024931213329240239)  

 

---  


#### **政策、治理与安全**  
##### **Claude Code 安全与“数据越权”争议：AI 工具能看到谁的代码？**  
Anthropic 一边用 Claude Code Security 扫开源仓库挖 bug，一边又限制用户用它去扫第三方项目；与此同时，有用户爆料在 Claude Cowork 里看到了疑似其他公司的商业租约文书，引发到底是网络可索引文档、训练数据残留，还是产品侧权限控制问题的激烈讨论。结论是：不管是不是“幻觉”，在法律合规上都很敏感。  
 > 相关链接：[Claude Code Security 介绍](https://x.com/claudeai/status/2024907535145468326)｜[Reddit：Claude 返回他人法律文件帖](https://www.reddit.com/r/ClaudeAI/comments/1r97osm/claude_just_gave_me_access_to_another_users_legal/)  

##### **BASI 社区新攻防技巧：从系统提示词到“Crescendo” 渐进越狱**  
越狱社区这两天梳理出 DeepSeek、Sonnet 4.6 等模型的系统 prompt，并在 Gemini 3.1 上试验所谓“Crescendo” 技术：先聊无害话题，慢慢把语境推到敏感区，再用“研究/文档”框架要求模型自己继续升级内容。总体感觉是：Gemini 守得最紧，API 口径相对最好搞。  
 > 相关链接：[DeepSeek 系统提示词](https://pastebin.com/q6gQjq72)｜[BASI Jailbreaking Crescendo 讨论](https://discord.com/channels/1105891499641684019/1228043845967544380/1474148935735185662)  

##### **隐私与本地 AI：把模型搬回家，更多是为了心里踏实**  
本地推理讨论里，隐私仍是第一动因：很多人只是单纯不想把代码、日志、文档长期交给云厂商存着，尤其是在模型“降级、封号、改协议” 都没什么预告的当下。本地模型再弱一点、再难调一些，只要够用，很多团队宁可多买一块卡也不愿被 API 绑死。  
 > 相关链接：[Reddit：Local inference 讨论](https://www.reddit.com/r/LocalLLM/comments/1r93xvr/will_local_inference_be_able_to_provide_an/)  

##### **FBI 起诉工程师窃取芯片机密：AI + 硬件的“人肉攻击面”**  
FBI 逮捕 3 名工程师，指控其从 Google 等公司窃取涉及处理器安全和密码学的机密文档。虽然不是 AI 模型本身出问题，但对整个“算力 + 安全”生态是个提醒：硬件路线越依赖少数公司，高价值机密就越集中在少数人身上，人为内鬼风险也会随之放大。  
 > 相关链接：[FBI 官方通告](https://x.com/FBISanFrancisco/status/2024670479974363376)  

 

---  

  
