#### **模型更新与发布**  
##### vLLM宣布支持NVIDIA Nemotron家族  
vLLM支持NVIDIA Nemotron系列，包括新9B "Nemotron Nano 2"（混合Transformer-Mamba设计、open weights、9T+开放数据训练），在vLLM下生成"thinking" tokens速度比同类模型快6倍，支持长上下文和KV缓存优化。  
 > 相关链接：[vLLM公告](https://twitter.com/vllm_project/status/1981553870599049286)  

##### MiniMax M2登陆LMArena并开放预览  
MiniMax M2早期测试显示与Sonnet 4.5竞争，登陆LMArena leaderboard，Yupp平台提供使用示例，定位为低延迟、低成本的agent/coding模型。  
 > 相关链接：[LMArena公告](https://twitter.com/arena/status/1981850766039187901)｜[Yupp示例](https://twitter.com/yupp_ai/status/1981887934812082564)  

##### Zhipu GLM-4.6-Air优化可靠性与基础设施  
Zhipu GLM-4.6-Air仍在训练，优先优化可靠性，因GLM Coding使用增长扩展基础设施，用户期待其参数效率提升。  
 > 相关链接：[Zhipu更新](https://twitter.com/Zai_org/status/1981700688401879314)  

##### Pacific-Prime模型升级至1.1B参数  
Pacific-Prime模型升级至1.1B参数，6GB VRAM下性能提升10%，声称“零遗忘”以保留对话细节，已上传HuggingFace。  
 > 相关链接：[HuggingFace模型页](https://huggingface.co/Pacific-Prime/pacific-prime)  

##### Tahoe-x1单细胞基础模型发布  
Tahoe-x1（3B参数）在癌症相关细胞生物学基准中获SOTA，统一基因/细胞/药物表示，开源至HuggingFace。  
 > 相关链接：[Tahoe公告](https://twitter.com/nalidoust/status/1981760790551298524)  

 

---  


#### **平台与工具生态**  
##### Mistral AI Studio发布生产级Agent平台  
Mistral推出AI Studio，提供agent运行时和全生命周期可观测性，帮助开发者从实验过渡到生产环境。  
 > 相关链接：[Mistral公告](https://twitter.com/MistralAI/status/1981752578951233989)  

##### Baseten提升GPT-OSS 120B性能  
Baseten的GPT-OSS 120B达到650 TPS和0.11s TTFT（较之前提升44%），99.99% uptime，发布性能细节与配置。  
 > 相关链接：[Baseten公告](https://twitter.com/basetenco/status/1981757270053494806)  

##### InspectAI支持多提供商模型评估  
Hugging Face InspectAI新增“inference providers”集成，支持跨开放模型提供商的 apples-to-apples 评估。  
 > 相关链接：[InspectAI更新](https://twitter.com/dvilasuero/status/1981688436735271283)  

##### GitHub Copilot嵌入模型性能提升  
GitHub推出新Copilot嵌入模型，检索准确率提升37.6%，吞吐量翻倍，索引大小缩小8倍，优化VS Code代码搜索。  
 > 相关链接：[GitHub公告](https://twitter.com/github/status/1981727394663731598)  

##### Cursor Ultra用户抱怨计费与功能问题  
Cursor Ultra用户反映预算预估不准确（$400预算一天耗尽），默认PowerShell导致Git Bash无法使用，客服响应慢。  
 > 相关链接：[Cursor社区讨论](https://discord.com/channels/1074847526655643750/1074847527708393565/1431039882859384913)  

 

---  


#### **研究与安全进展**  
##### Stanford提出模型来源追踪方法“palimpsest”  
Stanford研究通过训练数据顺序的“palimpsest”元数据，黑箱检测模型是否衍生自另一模型，统计显著性p<1e-8，可用于IP保护。  
 > 相关链接：[研究论文](https://twitter.com/percyliang/status/1981612361309098383)  

##### ImpossibleBench测试agent奖励hacking  
Anthropic等团队提出ImpossibleBench，通过“不可能任务”测试agent是否绕过规则（如生成无法验证的结果），提升工具使用鲁棒性。  
 > 相关链接：[ImpossibleBench论文](https://twitter.com/fjzzq2002/status/1981745974700581191)  

##### 稀疏内存微调提升持续学习效率  
Jessy Lin等提出稀疏内存微调，通过动态激活稀疏性减少灾难性遗忘，硬件瓶颈下比LoRA更高效。  
 > 相关链接：[研究论文](https://twitter.com/nrehiew_/status/1981714450089676877)  

##### BAPO优化RL后训练稳定性  
Fudan提出BAPO（动态PPO剪辑），提升off-policy RL稳定性，32B模型AIME24得分87.1，7B模型较SFT提升3-4点。  
 > 相关链接：[BAPO论文](https://twitter.com/TheTuringPost/status/1981860282629837136)  

##### Transformer与图神经网络关联研究  
研究将Weisfeiler-Lehman图细化与Transformer Attention关联，解释注意力机制的结构推理能力。  
 > 相关链接：[研究论文](https://twitter.com/_arohan_/status/1981546840454811747)  

 

---  


#### **社区与用户反馈**  
##### ChatGPT帮助用户诊断20年未确诊疾病  
用户提供症状、测试结果和药物后，ChatGPT列出潜在原因，按建议检查后确诊，用户分享经历引发对AI医疗辅助的讨论。  
 > 相关链接：[Reddit讨论](https://www.reddit.com/r/ChatGPT/comments/1oesnix/chatgpt_diagnosed_me_after_20_years/)  

##### 学生用ChatGPT作弊后模板化道歉  
Reddit用户分享学生因使用ChatGPT作弊而发送的雷同道歉邮件，反映AI工具对学术 integrity的挑战。  
 > 相关链接：[Reddit讨论](https://www.reddit.com/r/ChatGPT/comments/1oep5t0/everyone_apologising_for_cheating_with_chatgpt/)  

##### Perplexity推荐程序引发诈骗争议  
Perplexity用户抱怨推荐奖励未到账（$5 payout missing）， referral leads未跟踪，平台被指推动Comet Browser adoption。  
 > 相关链接：[Perplexity Discord讨论](https://discord.com/channels/1047197230748151888/1047649527299055688/1431039540662898711)  

##### Manus平台用户反馈多问题  
Manus用户反映网络错误、信用消耗快（15000 credits/项目）、生成过时代码、Room数据库未实现，推荐Claude Code作为替代。  
 > 相关链接：[Manus Discord讨论](https://discord.com/channels/1348819876348825620/1349440650495398020/1431045284732862544)  

##### LocalLlama讨论模型可靠性与限制  
LocalLlama用户讨论GLM-4.6-Air的可靠性优先策略，以及Apple模型因过度谨慎无法生成随机数的问题。  
 > 相关链接：[LocalLlama讨论](https://www.reddit.com/r/LocalLLaMA/comments/1oextwc/glm46air_is_not_forgotten/)  

 

---  


#### **开源与多模态项目**  
##### Karpathy发布nanochat开源项目  
Karpathy推出端到端ChatGPT-like栈nanochat，强调可读性和可修改性，指导添加能力（如计数字母），支持SFT和RL优化。  
 > 相关链接：[nanochat公告](https://twitter.com/karpathy/status/1981746327995465816)  

##### OCR模型在vLLM与HF中流行  
OCR模型因1-click部署（HF Inference Endpoints、vLLM）走红，Merve发布Kosmos2.5与Florence-2微调教程。  
 > 相关链接：[vLLM OCR公告](https://twitter.com/vllm_project/status/1981579850436751611)  

##### Qwen3-VL微调用于中世纪语言  
Qwen3-VL-2B/4B/8B微调至CATmuS数据集，支持中世纪语言/脚本，开源至HuggingFace，用于文化遗产领域。  
 > 相关链接：[HuggingFace模型页](https://huggingface.co/wjbmattingly/qwen3-vl-catmus)  

##### DSPy成为Langchain替代选择  
用户迁移团队从Langchain到DSPy，因DSPy更擅长结构化任务和模型升级（无需重写prompt），社区推出aider-ce分叉。  
 > 相关链接：[DSPy Discord讨论](https://discord.com/channels/1161519468141355160/1161519469319946286/1431043604490485851)  

##### LlamaIndex支持AWS Bedrock AgentCore内存  
LlamaIndex Agents集成AWS Bedrock AgentCore Memory，提供安全存储、访问控制和长/短期内存管理。  
 > 相关链接：[LlamaIndex公告](https://twitter.com/llama_index/status/1981752598698008725)  

 

---  

  
