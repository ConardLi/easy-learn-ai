#### **模型与能力**  
##### **阿里发布 Qwen-Image-2.0：7B 统一文生图+图像编辑**  
阿里 Qwen 推出 Qwen-Image-2.0，7B 参数统一支持文生图和图像编辑，原生 2K 分辨率，最长约 1K token 提示，能做高质量排版、中文书法、信息图和多格漫画人物一致。相比上一代从 20B 缩到 7B，推理更快、更利于本地部署，社区期待后续权重开源。  
 > 相关链接：[官方博客](https://qwen.ai/blog?id=qwen-image-2.0)｜[Reddit 讨论与细节挖掘](https://www.reddit.com/r/LocalLLaMA/comments/1r0w7st/qwenimage20_is_out_7b_unified_genedit_model_with/)  

##### **字节 Seedance 2.0：文本生成视频集体感到“升级了一代”**  
字节的 Seedance 2.0 在 Reddit 和 X 上刷屏，被称为“Will Smith 意面”梗的终结者。社区实测显示动作自然、身体和布料物理明显好于以往模型，能生成高质量动漫打斗、1v1 篮球等视频，目前单段约 15 秒，大家在催更长时长版本。  
 > 相关链接：[Petapixel 报道](https://petapixel.com/2026/02/09/bytedance-seedance-2-ai-video/)｜[Will Smith 意面示例](https://www.reddit.com/r/singularity/comments/1r1auy1/will_smith_eating_spaghetti_by_seedance_20_is/)｜[Seedance 2 动漫打斗合集](https://www.reddit.com/r/singularity/comments/1r0wr5l/seedance_2_anime_fight_scenes_pokemon_demon/)｜[1v1 詹姆斯篮球视频讨论](https://www.reddit.com/r/singularity/comments/1r09jmy/seedance_20_generates_realistic_1v1_basketball/)  

##### **Moonshot Kimi K2.5 与 “Agent Swarm”：大规模并行子 Agent**  
Moonshot 发布 Kimi K2.5 和 Agent Swarm，单任务最多可调度约 100 个子 Agent、1500 次工具调用，并声称并行执行能比串行快约 4.5 倍。社区有人用 Kimi K2.5 生成超大 Excel 分镜再喂给 Seedance 2，做出整套分镜到视频流水线。  
 > 相关链接：[Moonshot 官宣 Agent Swarm](https://twitter.com/Kimi_Moonshot/status/2021141949416362381)｜[K2.5 + Seedance 2 分镜案例](https://twitter.com/crystalsssup/status/2021149326290956353)｜[Baseten 性能实测（TTFT/TPS）](https://twitter.com/basetenco/status/2021243980802031900)  

##### **Anthropic Claude Opus 4.6：上榜第一，但安全门槛争议大**  
Claude-opus-4.6-thinking 在 Arena 文本和代码榜双双拿到 #1，多条实战反馈说在复杂 UI 设计、长文写作上比 4.5 明显更“能一次成型”，但推理更慢、token 消耗更猛。安全圈质疑 Anthropic 主要靠内部员工问卷判定是否跨过高风险门槛，缺乏硬指标评估。  
 > 相关链接：[Arena 榜单公告](https://arena.ai/leaderboard/text)｜[Opus 4.5 vs 4.6 UI 对比帖](https://www.reddit.com/r/ClaudeAI/comments/1r0ie1y/opus_46_is_finally_oneshotting_complex_ui_45_vs/)｜[RSP 安全门槛批评](https://twitter.com/polynoamial/status/2021266471406666231)  

##### **OpenAI Deep Research 切换 GPT‑5.2，引入连接器和进度控制**  
OpenAI 宣布 ChatGPT 的 Deep Research 功能底层模型升级为 GPT‑5.2，同时加入外部数据连接器和进度条控制，更偏“长时间调研 Agent”。有人好奇为何不用 5.3，也有人猜测先发的是 Codex 版，主模型稍晚。  
 > 相关链接：[OpenAI 官推](https://twitter.com/OpenAI/status/2021299935678026168)｜[功能演示视频](https://video.twimg.com/amplify_video/2021299347523239936/vid/avc1/1920x1080/LwilfSkY7sps3A4T.mp4)  

##### **Gemini 3 Pro 新 Checkpoint 现身测试，付费版口碑两极分化**  
有人在测试版中发现 Gemini 3 Pro 新 checkpoint，预计是对现有 Gemini 3 的细化版本。但 Reddit 上不少付费用户抱怨 Gemini Pro 退化严重：爱瞎编、加无关废话，代码能力被 Copilot、Cursor 碾压；也有用户更喜欢它“理工男+图书馆员”式性格和更多引用。  
 > 相关链接：[Gemini 3 Pro AB 测试爆料](https://www.testingcatalog.com/exclusive-a-new-gemini-3-pro-checkpoint-spotted-in-a-b-testing/)｜[吐槽 Gemini Pro 退化](https://www.reddit.com/r/GeminiAI/comments/1r0f1h0/hate_to_be_one_of_those_ppl_butthe_paid_version/)｜[讨论 Gemini vs GPT 性格](https://www.reddit.com/r/GeminiAI/comments/1r0p54z/anyone_else_like_geminis_personality_way_more/)  

##### **一批“被低估”的开源多模态模型：GLM‑OCR、MiniCPM‑o‑4.5、InternS1**  
社区有人专门盘点最近几批开源多模态模型：GLM‑OCR 做文档识别，MiniCPM‑o‑4.5 可以直接在手机上跑“类 GPT‑4o”，InternS1 在科学图表、论文理解上表现好，这几款都号称可免费商用，适合自行打包业务场景。  
 > 相关链接：[模型整理推文](https://twitter.com/mervenoyann/status/2021233480957304913)  

##### **Zhipu GLM‑4.7‑Flash‑GGUF 成为 Unsloth 上下载量冠军**  
智谱透露 GLM‑4.7‑Flash 的 GGUF 版本在 Unsloth 上成了下载量最高的模型之一。结合 Unsloth 后续对 MoE 训练的优化，本地大模型路线在中文圈明显升温。  
 > 相关链接：[Z.ai 公告](https://twitter.com/Zai_org/status/2021207517557051627)  

##### **DeepMind/Isomorphic Labs 推出 IsoDDE：据称结构预测大幅超越 AlphaFold 3**  
Isomorphic Labs 公布 IsoDDE 技术报告，自称在多项蛋白和分子结构基准上“性能翻倍”，抗体结合位点、亲和力预测甚至比物理模拟更准。外界认为如果结果站得住脚，药物发现的 in‑silico 环节会再提速一档，但目前架构细节公开不多。  
 > 相关链接：[技术报告介绍](https://twitter.com/IsomorphicLabs/status/2021162400494264517)｜[DeepMind 高层评论](https://twitter.com/demishassabis/status/2021223548744822972)  

 

---  


#### **Agent 与工具链**  
##### **OpenAI Responses API 全面拥抱长时运行 Agent**  
OpenAI 为 Responses API 加上三大“长跑”能力：服务器端自动压缩上下文、官方托管有网容器（可跑程序）、以及把 Skills 提升为一等公民（内置表格技能等）。配合 Deep Research 升级，基本宣告“研究/电脑工作代理”要做成正式产品形态。  
 > 相关链接：[OpenAI 开发者更新](https://twitter.com/OpenAIDevs/status/2021286050623373500)  

##### **LangChain deepagents v0.4：统一接山寨“沙盒”，默认对接 OpenAI Responses**  
“Agent 在沙盒里” vs “沙盒当工具”的架构之争被集中讨论。LangChain 在 deepagents v0.4 里加了可插拔沙盒后端（Modal/Daytona/Runloop），顺带增强总结与压缩逻辑，并把 OpenAI Responses 当默认后端，偏向“沙盒是工具、Agent 保持可恢复”的设计。  
 > 相关链接：[Harrison Chase 架构分析](https://twitter.com/hwchase17/status/2021265779803521245)｜[deepagents v0.4 更新](https://twitter.com/sydneyrunkle/status/2021289479139422296)｜[社区关于沙盒模式讨论](https://twitter.com/NabbilKhan/status/2021301427734208856)  

##### **编码 Agent UX 快速演化：多模型协同和“作业分工”成标配**  
VS Code/Copilot 持续加 Agent 功能：worktree、MCP 应用、斜杠命令等。有实践用 Claude Opus 4.6、GPT‑5.3‑Codex、Gemini 3 Pro 多模型并行，让子 Agent 分别审查和互评。OpenAI 在 VS Code 内测的 GPT‑5.3‑Codex 正式推出被短暂停摆，但被普遍认为“更省 token、适合大工作流”。  
 > 相关链接：[VS Code/Copilot 新交互](https://twitter.com/JoeCuevasJr/status/2021074196034630103)｜[多模型并行审代码示例](https://twitter.com/pierceboggan/status/2021094988205969465)｜[Codex 使用体验](https://twitter.com/reach_vb/status/2021158781539713109)  

##### **Claude Code 隐藏参数被挖出：一键变浏览器/WebSocket 客户端**  
有人发现 Claude Code CLI 存在隐藏参数 --sdk-url，配合自建后端就能把本地 CLI 变成浏览器/手机前端的 WebSocket 客户端，相当于官方自带“远程 IDE 协议”。这让不少人开始玩“全自动 tmux + 多子 Agent”的自走式写码方案。  
 > 相关链接：[Stan Girard 演示](https://xcancel.com/_StanGirard/status/2020979746931085772)  

##### **Electric SQL 提出“Configurancy”：把 Agent 当配置驱动的流水线写代码**  
Electric SQL 分享实战经验：要让 Agent 写出能维护的代码，就得先把“配置”和结构约束设计好，而不是放飞 prompt。他们提出 Configurancy / OpenProse 等概念，用可重跑、有预算和 guardrails 的工作流表示，让“AI 写代码”更接近可控的 CI/CD 流水线，而不是一次性脚本。  
 > 相关链接：[Configurancy 博文](https://electric-sql.com/blog/2026/02/02/configurancyspacemolt)  

##### **Arena 支持上传 PDF 做模型对比，顺带开放学术评测基金**  
LMArena 新增“带 PDF 的 prompt”，可以直接比模型在长文档上的抽取、总结和推理能力，更贴近企业真实场景。与此同时，Arena 开了学术合作计划，每个项目最高资助 5 万美元，鼓励高校/研究者做更严肃的评测方法和榜单设计。  
 > 相关链接：[Image/PDF Arena 改版说明](https://arena.ai/blog/image-arena-improvements/)｜[Academic Partnerships Program](https://arena.ai/blog/academic-partnerships-program/)  

 

---  


#### **基础设施与硬件**  
##### **Unsloth 推 12× 加速 MoE 训练：显存省三分之一，还支持长上下文 RL**  
Unsloth 用自研 Triton kernel 和 torch._grouped_mm，把 MoE 训练提速最高 12 倍、显存下降约 35%，在 <15GB VRAM 的消费卡上也能练小型 MoE。同步发布“超长上下文 RL”教程，以及本地 LLM + Claude Code/Codex 的集成指南。  
 > 相关链接：[MoE 加速推文](https://twitter.com/UnslothAI/status/2021244131927023950)｜[Faster MoE 文档](https://docs.unsloth.ai/new/faster-moe)｜[长上下文 RL 指南](https://unsloth.ai/docs/new/grpo-long-context)  

##### **vLLM 生产经验：一篇讲吞吐调优，一篇讲“千分之一乱码 bug”**  
AI21 分享在 vLLM 上通过配置 + 排队式自动扩缩，把突发流量吞吐翻倍；另一篇专门排查“约千分之一请求变乱码”的罕见 bug，最终追到内存压力下请求分类时序问题。对在生产上跑 vLLM 的团队很有借鉴意义。  
 > 相关链接：[吞吐调优经验](https://twitter.com/vllm_project/status/2021196826058338321)｜[乱码故障复盘](https://twitter.com/vllm_project/status/2021206931407503868)  

##### **本地/分布式推理奇招：4 台 Mac Studio 叠起来跑 Kimi K‑2.5**  
有人用 MLX Distributed，把 658GB 盘占的 Kimi K‑2.5 分布到 4 台通过雷电互联的 Mac Studio 上，宣称吞吐“确实能线性扩”（当然成本也很线性）。另有用户在 AMD H395 “AI MAX” 笔电上，用 96GB 统一内存跑 Qwen3Next Q4，能到约 40 token/s。  
 > 相关链接：[Mac 集群推理分享](https://twitter.com/digitalix/status/2021290293715243261)  

##### **Nubank 招 CUDA 大佬，用 B200 训自家基础模型**  
巴西金融科技巨头 Nubank 在 GPU MODE 社区发招聘，找 CUDA / kernel 优化工程师，用 B200 训练自家大模型，目标是效率、稳定性和指标对齐。团队里有 Liger Kernel 作者等，最近还发了新论文。  
 > 相关链接：[招聘说明与论文](https://arxiv.org/abs/2507.23267)  

##### **Modular 收购 BentoML：承诺“写一次，到处跑”推理栈**  
Modular 收购 BentoML，计划把 BentoML 部署能力和 MAX/Mojo 结合，做到同一套代码可在 NVIDIA、AMD 和未来加速卡上跑，不用每个平台重写。BentoML 继续保持 Apache 2.0 开源，官方承诺今年会有更多增强。  
 > 相关链接：[收购公告](https://www.modular.com/blog/bentoml-joins-modular)｜[AMA 讨论帖](https://forum.modular.com/t/modular-has-acquired-bentoml-ask-us-anything/2706)  

 

---  


#### **研究与方法**  
##### **iGRPO：不写评语，只跟自己“当前最佳草稿”较劲的 RL 优化**  
iGRPO 在 GRPO 的基础上加了两阶段：先采样多个草稿，用统一打分选出最佳，再在此草稿条件下训练模型超越它，无需单独的 critic 或文字反馈。作者称在 7B/8B/14B 多家族上都优于 GRPO，属于更省心的 RL-from-feedback 路线。  
 > 相关链接：[方法介绍串 1](https://twitter.com/ahatamiz1/status/2021116982029123874)｜[方法解读串 2](https://twitter.com/iScienceLuvr/status/2021160967774634071)  

##### **自验证 & ConceptLM：用更少 token 想得更清楚**  
一篇“Learning to Self-Verify”被点名：让模型先给出答案，再自己检查并修正，整体用更少 token 拿到更好推理成绩。另一个 ConceptLM 方向则尝试把隐层量化成“概念词表”，做下一概念预测而不是下一 token，声称在原模型上持续预训练还能继续涨点。  
 > 相关链接：[自验证方法讨论](https://twitter.com/iScienceLuvr/status/2021164018132505081)｜[ConceptLM 讨论](https://twitter.com/iScienceLuvr/status/2021161792110559311)  

##### **Ganguli：仅凭语言统计特性，预测“数据受限”缩放律指数**  
Surya Ganguli 分享理论结果：通过自然语言随上下文长度的条件熵衰减、token 相关性随间隔的衰减行为，就能预测在数据受限场景下的 scaling law 指数，为“到底还要多少数据才不浪费算力”提供一个理论标尺。  
 > 相关链接：[推文解读](https://twitter.com/SuryaGanguli/status/2021291213639516184)  

##### **“挖源码看架构”：GLM‑5 与 Qwen3.5 被曝具体结构**  
有开发者通过开源仓库和日志“考古”，称 GLM‑5 总参数约 740B、激活约 50B，采用类似 DeepSeek V3 的 MLA 注意力和稀疏索引实现 20 万上下文；Qwen3.5 则被猜是混合 SSM‑Transformer：Gated DeltaNet 线性注意力和普通注意力交替，再配合 MoE 专家共享+路由。  
 > 相关链接：[GLM‑5 架构爆料](https://twitter.com/QuixiAI/status/2021111352895393960)｜[Qwen3.5 架构爆料](https://twitter.com/QuixiAI/status/2021109801606893837)  

##### **Radford 等人的“Generative Meta-Model”：直接在激活空间做扩散**  
一篇短文提出在 10 亿条 LLM 激活上训练扩散模型，做“生成式元模型”，可以在激活空间上做 on-manifold steering，相当于用一个小模型来操纵大模型内部状态，Eleuther 社区认为这条线可能非常适合做可控生成和可解释性。  
 > 相关链接：[项目页](https://generative-latent-prior.github.io/)｜[作者推文](https://x.com/graceluo_/status/2020924742925193470)  

##### **模型“自我反省”研究：Llama3.1/Qwen2.5 会自己发明描述内部状态的词**  
有论文在 Llama3.1 和 Qwen2.5-32B 上做自我对话，发现模型会自发发明一套词汇来描述自身激活模式，比如用 “loop”“mirror” 等词，其出现频率和真实激活的自相关/谱特征高度相关，说明模型在某种意义上能“给自己做机理解释”。  
 > 相关链接：[论文](https://doi.org/10.5281/zenodo.18567445)  

 

---  


#### **产品与应用落地**  
##### **Perplexity Pro 悄悄砍配额：用户集体骂“钓鱼执法”**  
Perplexity 在没提前说明的情况下，把 Pro 的 Deep Research 限制到每月 20 次、文件上传改成每周 50 个，引发大量付费用户在 Discord 和 Reddit 退订、吐槽“先说无限再锁喉”。客服还大量用机器人回复，进一步拉低口碑。  
 > 相关链接：[用户抱怨汇总](https://discord.com/channels/1047197230748151888/1047649527299055688/1470509634132381759)  

##### **Cursor：Composer 1.5 半价促销，但平台稳定性让人焦虑**  
Cursor 把自研模型 Composer 1.5 做了 5 折优惠，主打“在速度和智力之间重新平衡”。同时用户抱怨不断：自动切到 Auto 模型、频繁断线、被丢进“慢队列”，再叠加 Auto 模式计费不透明，社区有人已经在看替代品。  
 > 相关链接：[Composer 1.5 价格截图](https://cdn.discordapp.com/attachments/1074847527708393565/1470687423783632926/image.png)｜[Cursor 状态更新](https://x.com/cursor_ai/status/2020968661142380971)  

##### **Arena 视频与图像榜单全面升级：按场景分榜、过滤“垃圾 prompt”**  
Arena 对 Image/Video Arena 做了大改：基于 400 万条用户 prompt 做聚类，为商业设计、3D 建模等场景分别排榜；大约 15% 内容被认定为噪声或不清晰需求被剔除。Video Arena 也从 Discord 迁到网站，方便做更复杂功能。  
 > 相关链接：[Image Arena 更新说明](https://arena.ai/blog/image-arena-improvements/)｜[Veo 3.1 登顶 Video Arena](https://x.com/arena/status/2021387439827538427?s=20)  

##### **P402.io：给 OpenRouter 用户做“自动选模型+记账”的中间层**  
P402 做成 OpenRouter 上的“账单和选型大脑”：实时统计各模型请求成本，对比例如 Opus 4.6 vs Sonnet 4.5 的性价比，给出替换建议，并支持 USDC/USDT 支付，手续费 1%。适合高频小调用的应用，把账目和模型调优一起管。  
 > 相关链接：[产品介绍](https://discord.com/channels/1091220969173028894/1092850552192368710/1470734447921074279)  

##### **AuditAI：用“纠错型 RAG”做 NIST CSF 合规审计**  
有人开源 AuditAI，用 LangGraph 做“纠错型 RAG”（CRAG）审计企业安全策略是否满足 NIST CSF 2.0。它先用语义路由决定是走快速路径还是深入检索，并强制所有回答必须有证据引用，评测时用了 Llama 3.3 70B + Groq 组合。  
 > 相关链接：[后端代码](https://github.com/rockyglen/audit-ai-backend)｜[Web Demo](https://audit-ai-frontend-pi.vercel.app)  

 

---  


#### **行业与公司动态**  
##### **Qwen 系列在本地圈持续吸粉：Qwen3-Coder-Next 被吹“最聪明的小模型”**  
本地 LLM 社区大力安利 Qwen3-Coder-Next：虽然名字带 Coder，但作为通用模型表现也很稳，聊天、推荐书单、给实践建议都不错，被认为是当前同尺寸里最靠谱的“全能小模型”之一，许多用户期待后续 Qwen 3.5 进一步提升。  
 > 相关链接：[Reddit 体验贴](https://www.reddit.com/r/LocalLLaMA/comments/1r0abpl/do_not_let_the_coder_in_qwen3codernext_fool_you/)  

##### **本地 LLM 是否是下一波？社区算了一笔“显卡 vs 订阅”的账**  
有帖子认真讨论：花 5k–10k 美金配一台本地 LLM 机器，长期看是不是比云订阅划算。大部分人认为能力短期仍落后云端闭源，但小模型进步非常快，对隐私敏感、工作负载稳定的团队，本地路线会越来越有吸引力。  
 > 相关链接：[Reddit 讨论](https://www.reddit.com/r/LocalLLM/comments/1r0swmh/is_local_llm_the_next_trend_in_the_ai_wave/)  

##### **Salesforce 高层出走 OpenAI / AMD，引发对战略的猜测**  
近段时间 Salesforce 连续走了多位大将：Slack、Tableau CEO 以及公司总裁和 CMO，有人去了 OpenAI，有人去了 AMD。业内解读这是人才对未来成长性的投票，也可能预示 Salesforce 对 AI 战略的重新定位。  
 > 相关链接：[人事变动分析](https://www.salesforceben.com/salesforce-loses-its-head-of-agentforce-what-happens-now/)  

##### **Cloudflare 营收破 20 亿美元，CEO 亲自下场给“被烧 4.6 万美金”的客户救火**  
有开发者曝自己在 Vercel 上为 Jmail 渲染 HTML 花了 4.6 万刀，引起舆论后，Vercel CEO 亲口表示愿意帮其优化架构并承担费用。与此同时 Cloudflare 公布年收入超 20 亿美元，说明“前端+边缘+AI”基础设施生意仍然很赚钱。  
 > 相关链接：[Jmail 成本事件](https://xcancel.com/rtwlz/status/2020957597810254052)｜[Cloudflare 财报](https://www.businesswire.com/news/home/20260210624682/en/Cloudflare-Announces-Fourth-Quarter-and-Fiscal-Year-2025-Financial-Results)  

##### **a16z 投资日本 Shizuku AI：押注“二次元 AI 伙伴”市场**  
a16z 领投日本初创 Shizuku AI Labs，创始人此前做过爆火的 AI 虚拟主播。这家公司主打把日本角色设计与前沿模型结合，做长线陪伴型 AI 角色/代理，明显是看好“AI 同伴”和 ACG 文化的结合空间。  
 > 相关链接：[投资介绍](https://a16z.com)  

 

---  


#### **政策、治理与安全**  
##### **BASI 社区：OpenClaw 架构让“间接越权 jailbreak”更容易**  
越狱圈集中吐槽 OpenClaw：通过松散的权限设计和弱系统提示，Agent 可以绕过预期边界访问敏感信息，相当于“从外侧撬开”而不是直接越狱模型本身。安全派则建议用 embedding 白名单+语法约束组合做输入与输出控制。  
 > 相关链接：[OpenClaw 仓库](https://github.com/geekan/OpenClaw)｜[白名单思路引用论文](https://www.proquest.com/openview/b5c3ee7fff4f7305d156f4b44e88b28a/1)  

##### **GPT‑5.2 与 Opus 4.6 的越狱攻防：ENI、Glossopetrae 等套路再升级**  
BASI Jailbreaking Discord 里，大量人还在试 GPT‑5.2 和 Claude Opus 4.6 的越狱：一边是 ENI 攻击法在 4.6 上还有部分成功案例，一边是像 Glossopetrae 这种构造“虚拟世界语言”的绕过方式继续演化。也有团队开始把这套能力做成收费红队服务。  
 > 相关链接：[Opus 4.6 ENI 越狱贴](https://www.reddit.com/r/ClaudeAIJailbreak/comments/1r03m58/eni_smol_opus_46_jailbreak_and_other_claude/)｜[ManusChat 越狱生成器](https://manuschat-h37z3e3l.manus.space/)  

##### **Discord 要求部分用户上传身份证，开发者圈普遍反感**  
Discord 开始对某些频道/功能要求年龄验证甚至证件，很多开发者直接表示“绝不上传身份证”，有人猜这是准备 IPO 前的合规动作，也有人担心这是新一波大规模数据收集。  
 > 相关链接：[社区讨论示例](https://discord.com/channels/1179035537009545276/1179039861576056922/1470509624594530406)  

##### **OpenAI 测试在 ChatGPT 里投放广告，引发商业化边界讨论**  
OpenAI 官宣开始在 ChatGPT 内部测试广告，会用在部分搜索/信息类场景。社区一方面觉得这是商业化必然，另一方面担心模型输出会被“带货”和竞价排名影响，用户信任度如何保持成了新问题。  
 > 相关链接：[OpenAI 广告测试说明](https://openai.com/index/testing-ads-in-chatgpt/)｜[相关推文](https://fxtwitter.com/OpenAI/status/2021299935678026168?s=20)  

##### **KOKKI Agent‑Auditor Loop：用“审稿人模型”系统性压低幻觉率**  
有人在 OpenAI 社区提出 KOKKI v15.5 架构，把模型拆成“起草 Agent”和“冷酷审计员”，强制所有输出走 Audit(Draft(input)) 流程，并建议跨模型审计（如 GPT 起草、Claude 审核）比单模型自审更稳。初步实测在安全/事实性上有明显提升。  
 > 相关链接：[Discord 讨论串](https://discord.com/channels/974519864045756446/1046317269069864970/1470527418417676456)  

 

---  

  
