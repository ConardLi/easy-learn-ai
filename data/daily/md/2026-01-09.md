#### **政策、治理与安全**  
##### **OpenAI 推出面向医疗行业的 ChatGPT Health / OpenAI for Healthcare**  
OpenAI 上线医疗场景产品组合：ChatGPT Health 与 OpenAI for Healthcare，宣称符合 HIPAA，用于临床问答、文书与知识检索，已在 AdventHealth、UCSF、MSK、HCA 等医院上线。医生使用 AI 的比例被称“在一年内翻倍”，也引发隐私和“用 AI 代替医生”的担忧。  
 > 相关链接：[OpenAI 医疗公告](https://openai.com/index/openai-for-healthcare/)｜[ChatGPT Health 介绍](https://openai.com/index/introducing-chatgpt-health/)  

##### **斯坦福新论文：可从多家前沿大模型中抽取受版权保护内容**  
斯坦福团队研究称，多款线上大模型都会大规模记忆训练语料，可在特定设置下抽取受版权保护作品片段，声称 Claude 3.7 Sonnet 在实验中能复现《哈利波特1》约 95.8% 内容，而 GPT‑4.1 要低得多，用来反驳“LLM 不会记忆训练数据”的说法。  
 > 相关链接：[论文总结线程](https://twitter.com/ednewtonrex/status/2009201019184415218)  

 

---  


#### **模型与能力**  
##### **Zhipu GLM‑4.7 登顶开源能力榜，并推动公司在港交所上市叙事**  
Artificial Analysis 最新指数中，开源 GLM‑4.7 Reasoning 得分 42（较 4.6 提升 10 分），在编程、Agent 与科学推理上大幅领先，同家评测的开源模型中 GDPval-AA ELO 最高。模型为 355B MoE（激活 32B）、20 万上下文、MIT 许可证，BF16 权重约 710GB，单机 8×H100 也放不下。GLM 背后的公司 Z.ai 同时宣布在港交所上市并办社区挑战。  
 > 相关链接：[GLM‑4.7 评测数据](https://twitter.com/ArtificialAnlys/status/2009117037667422457)｜[Z.ai 里程碑与活动](https://twitter.com/Zai_org/status/2009290783678239032)  

##### **阿里 Qwen3‑VL 推出多模态 Embedding 与 Reranker 方案**  
Qwen 发布 Qwen3‑VL‑Embedding 和 Qwen3‑VL‑Reranker，两阶段检索架构，支持文本、图片、截图、视频、多语言（30+）、可调 embedding 维度、指令化与量化部署。官方称在 MMEB‑V2、MMTEB 等多模态检索基准上刷榜，模型已上 Hugging Face、ModelScope，vLLM 夜版已支持，云 API 即将上线。  
 > 相关链接：[官方介绍](https://twitter.com/Alibaba_Qwen/status/2009264754917863924)｜[基准成绩讨论](https://twitter.com/HuggingPapers/status/2009295485966672072)｜[vLLM 支持](https://twitter.com/vllm_project/status/2009316281275830351)  

##### **百度 ERNIE‑5.0 与腾讯 Hunyuan‑Video‑1.5 挤入 LMArena 榜单**  
LMArena 更新视觉与视频榜：ERNIE‑5.0‑Preview‑1220 以 1226 分升至 Vision 榜第 8，目前前十里唯一中国实验室；Hunyuan‑Video‑1.5 则进入文本转视频榜第 18、图生视频榜第 20。社区一边用来“看热闹”，一边也依赖这些主观榜单来选模型。  
 > 相关链接：[Vision 榜单](https://lmarena.ai/leaderboard/vision)｜[视频榜单](https://lmarena.ai/leaderboard/text-to-video)｜[榜单更新说明](https://news.lmarena.ai/leaderboard-changelog/)  

##### **AI21 开源 Jamba2：面向企业的混合 SSM‑Transformer 模型**  
AI21 发布 Jamba2 系列，主打“企业级可靠与可控”，采用 SSM+Transformer 混合结构和 KV‑cache 优化，号称在同等成本下支持更长上下文与更稳定行为。模型采用 Apache 2.0 许可，可通过 AI21 云服务与 Hugging Face 使用。  
 > 相关链接：[AI21 公告](https://twitter.com/AI21Labs/status/2009259475643846978)  

##### **TII Falcon‑H1R‑7B：小参数“推理型”混合 Transformer‑Mamba 模型**  
阿联酋 TII 的 Falcon‑H1R‑7B 被人工分析评为“小模型推理赛道新选手”，采用 Transformer+Mamba 混合结构，在 Humanity’s Last Exam、τ²‑Bench Telecom、IFBench 上有不错表现，在其 Openness 指数中开放度得分 44。  
 > 相关链接：[模型评测摘要](https://twitter.com/ArtificialAnlys/status/2009343487855219171)  

##### **Lightricks 开源 LTX‑2：可本地跑的音视频生成模型**  
Facetune 背后的 Lightricks 开源 LTX‑2，包含权重、代码、训练器、LoRA 与文档，定位为“生产可用”的音视频生成基础模型，可在消费级 GPU 本地运行。官方强调不再走 Wan 2.6 闭源路线，同时对训练数据做 NSFW/版权限制，后续能力扩展留给社区。  
 > 相关链接：[LTX‑2 模型页](https://ltx.io/model)｜[Reddit AMA](https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/im_the_cofounder_ceo_of_lightricks_we_just/)  

##### **Gemini 3 在 PokerBench 中长局表现亮眼**  
社区用 PokerBench 让 Gemini 3 Pro / Flash 等模型打了 2.1 万手德扑，整体曲线显示 Gemini 3 Pro 最终盈利最高。但有开发者指出一对一对局中 Flash 反而更强，说明长局收益可能有运气成分，PokerBench 数据和代码已开源。  
 > 相关链接：[PokerBench 网站](https://pokerbench.adfontes.io/)｜[Reddit 讨论](https://www.reddit.com/r/GeminiAI/comments/1q7gy25/i_made_gemini_3_proflash_play_21000_hands_of_poker/)  

 

---  


#### **基础设施与硬件**  
##### **vLLM + B200 记录 1.6 万 token/s，并引入 KV Cache 下沉方案**  
vLLM 社区在 NVIDIA B200 上实测吞吐约 16k token/s。团队与 IBM Research 合作，将 KV Offloading Connector 合进 vLLM，可把 KV cache 异步下沉到 CPU 内存以抗抢占、提升并发，官方称在 H100 上吞吐最高可提升 9 倍，cache 命中场景 TTFT 可降 2–22 倍，命令行参数已给出。  
 > 相关链接：[B200 吞吐里程碑](https://twitter.com/vllm_project/status/2009196819331600648)｜[KV Offloading 详解 1](https://twitter.com/vllm_project/status/2009217642507477222)｜[KV Offloading 详解 2](https://twitter.com/vllm_project/status/2009217648224247840)  

##### **AI 生成内核开始进主线：vLLM 中的 Oink RMSNorm Kernel 提速 40%**  
Mark Saroufim 披露一段由“Kernel LLM/Oink”生成的 fused RMSNorm kernel 已进 vLLM，单 kernel 提速约 40%，整体推理提速约 1.6%。代码针对热门形状（如 7168 BF16）做了近似自动调优，采用直接 gmem 读、只用 smem 做归约，同时也带来更复杂的崩溃/稳定性问题。他认为像 vLLM、FlashInfer 这种系统级 benchmark 套件会是“AI 写 kernel”走向主流的关键。  
 > 相关链接：[作者技术长文](https://twitter.com/marksaroufim/status/2009096176789016600)  

##### **CuteDSL Flex Attention 在 H100 上提速约 30%**  
GPU MODE 社区把 CuteDSL 版 flex attention 集成进现有框架，在 H100 前向上比基础 flex attention 吞吐快约 30%。目前 backward 在 SM100 已有支持，SM90 的后向支持正在 Flash‑Attention PR #2137 中推进。  
 > 相关链接：[相关 PR](https://github.com/Dao-AILab/flash-attention/pull/2137)  

##### **Transformers v5 大改架构：更偏 PyTorch、服务与量化**  
Hugging Face 发布 Transformers v5，统一 tokenizer 后端、重构模型定义，更聚焦 PyTorch，并在推理服务、量化和部署体验上做了较大升级；同时推出 Apple 端的 swift‑huggingface 和 AnyLanguageModel，让本地 + 远程模型在苹果生态下用一个 API 调。  
 > 相关链接：[Transformers v5 博文](https://huggingface.co/blog/transformers-v5)｜[swift‑huggingface](https://huggingface.co/blog/swift-huggingface)｜[AnyLanguageModel](https://huggingface.co/blog/anylanguagemodel)  

##### **Epoch：全球算力已超 1500 万张 H100 等效，芯片功耗超 10GW**  
Epoch AI 估算全球 AI 专用芯片保有量已相当于 1500 万块 H100，单算芯片功耗就超过 10GW，数据中心其他开销还不算在内。并提供“AI Chip Sales” 可视化工具，用于跟踪供应链和地区分布。  
 > 相关链接：[Epoch 数据与可视化](https://twitter.com/EpochAIResearch/status/2009366360183460237)  

 

---  


#### **Agent 与工具链**  
##### **LangChain + VS Code：把 Agent 做成“文件夹”和 Skills 标准**  
Harrison Chase 提倡用文件结构来描述 Agent：agents.md、subagents/、skills.md、mcp.json 等，让 Agent 更像仓库工件可版本化。VS Code 同步推出“Agent Skills”，基于 Anthropic 提出的开放标准，可从文件夹加载专用技能，设置项为 chat.useAgentSkills。  
 > 相关链接：[LangChain 文件化 Agent 思路](https://twitter.com/hwchase17/status/2009388479604773076)｜[VS Code Agent Skills](https://twitter.com/code/status/2009428464626016700)  

##### **DSPy 将重写多轮会话机制，历史不再硬塞进 system prompt**  
DSPy 教程里目前是把对话历史拼进 system prompt，引发困惑。维护者回应这是“适配器实现细节”，可以自写 adapter 改掉，优化器逻辑不受影响，并透露近期会重做多轮会话与历史序列化方式，让“改历史”变成一等配置项。  
 > 相关链接：[会话历史教程](https://dspy.ai/tutorials/conversation_history)  

##### **MCP 社区讨论为“有副作用工具”加标准化预演（staging）机制**  
MCP 贡献者建议，在真正执行会修改外部状态的工具调用前，标准化一层“预演”调用，方便审计与确认，并询问是否应写成 SEP。也有人认为更适合放在 SDK 最佳实践，而不是改协议本身，另外还在讨论与 W3C WebMCP 的合作方式。  
 > 相关链接：[MCP 贡献者工作组讨论](https://discord.com/channels/1358869848138059966/1416012674663452752/1458837264435122197)｜[SEP 规范网站](https://sep.dev)  

##### **Claude Code“专家用法”：把指令、错误与子 Agent 系统性工程化**  
Claude Code 社区有人分享长文“serious sauce”：用 hooks 读取本地 .ps1 路由文件选技能、建立错误日志系统收集失败 prompt、用 /commands 当本地小应用、强制所有子 Agent 用 Opus、严格管理上下文压缩与循环式“编译‑测试”，极大提高大项目可控性。  
 > 相关链接：[Claude Code 技巧文档](https://docs.google.com/document/d/1I9r21TyQuAO1y2ecztBU0PSCpjHSL_vZJiA5v276Wro/edit?usp=sharing)｜[Reddit 讨论贴](https://www.reddit.com/r/ClaudeCode/comments/1q7fs2o/what_is_some_serious_claude_code_sauce_people/)  

 

---  


#### **研究与方法**  
##### **MAGMA：用多种图结构做 Agent 长期记忆，而不是一锅 embedding**  
MAGMA 提出把 Agent 记忆拆成语义图、时间图、因果图、实体图等多图结构，再由策略控制检索路径，而不是单次大向量相似度检索。在 LoCoMo 和 LongMemEval 等长程任务上有明显收益，提示“知识库结构设计”本身就是一层算法空间。  
 > 相关链接：[dair.ai 论文速览](https://twitter.com/dair_ai/status/2009270633398718480)  

##### **SPOT@ICLR 2026：聚焦“大模型后训练如何规模化”的工作坊**  
ICLR 2026 的 SPOT 工作坊面向后训练（SFT/RL 人类反馈等）规模化问题征稿，强调算法、数据与系统的交叉设计，截稿为 2 月 5 日。说明“如何高效调后端模型”，正在被当作独立研究方向看待。  
 > 相关链接：[SPOT ICLR 征稿介绍](https://twitter.com/spoticlr/status/2009137185510052302)  

##### **人工分析把评测做成“现实任务 + 开放度指数”，而不只看几道选择题**  
Artificial Analysis 一边做 GDPval‑AA 这类“带工具/终端/浏览器的真实知识工作”任务评测，一边给模型打 Openness Index，把权重、数据、部署限制等折成开放度分数。他们在 Latent Space 讨论提示敏感、评测脆弱和“神秘顾客”式测试，也有人提倡更关注“人+AI”整体产能，而不是单看 AI 分数。  
 > 相关链接：[评测与开放度讨论](https://twitter.com/ArtificialAnlys/status/2009367497913585905)｜[人+AI 能力观点](https://twitter.com/paraschopra/status/2009118690823033165)  

##### **“死鲑鱼效应”重现：随机网络也能被解释得头头是道**  
Eleuther 社区关注一篇新论文指出，很多解读方法（特征归因、probe、稀疏自编码、因果分析等）在随机初始化的网络上也能给出“看起来合理”的解释，类似 fMRI 里的死鲑鱼伪阳性，提醒大家对可视化/解释结果要非常谨慎。  
 > 相关链接：[论文 Dead Salmon Artifacts](https://arxiv.org/abs/2512.18792)  

 

---  


#### **产品与应用落地**  
##### **Gmail 进入“Gemini 时代”：邮件内 AI 总结、写作与自然语言搜索**  
Google 宣布 Gmail 上线 Gemini 3 驱动的新功能：会话 AI 总结、回复与润色、AI Inbox 视图、以及“像跟人说话一样”搜索邮箱，强调用户可开关控制。安全圈人士立刻联想到未来可做反钓鱼与诈骗识别，也提醒要防止被“被信任的邮件 Agent”反向劝诱。  
 > 相关链接：[Gmail Gemini 功能介绍 1](https://twitter.com/Google/status/2009265269382742346)｜[Gmail Gemini 功能介绍 2](https://twitter.com/Google/status/2009266902112104711)  

##### **OpenAI 把 ChatGPT 正式推成医疗场景工作流的一环**  
除了面向 B2B 的 OpenAI for Healthcare，ChatGPT Health 也被包装为面向患者与医生的问答入口。官方宣传“基于可信医学证据”，并支持记忆/存储更新，但社区担心隐私、诊断责任以及“一切都进 ChatGPT”的平台垄断问题。  
 > 相关链接：[ChatGPT Health 介绍](https://openai.com/index/introducing-chatgpt-health/)  

##### **本地 LLM 实践：GLM‑4.7 被大量用来写代码，便宜、长上下文、不乱编 import**  
多位 Reddit 用户用 GLM‑4.7 替代 Claude Sonnet 4.5 做调试、重构和生成代码，称其在长文件场景下表现稳定、不乱造依赖，代码可用率 85–90%，API 花费约是 Claude 的五分之一。Sonnet 仍在设计和高层讨论上更顺手，但“批量写代码”很多人已切到 GLM。  
 > 相关链接：[GLM‑4.7 vs Claude 讨论](https://www.reddit.com/r/LocalLLM/comments/1q79orf/been_using_glm_47_for_coding_instead_of_claude/)  

##### **Qwen‑Image 系列在本地端落地：14GB 级别即可玩高质量文生图与编辑**  
社区写了详细教程教你在本地跑 Qwen‑Image‑2512 与 Qwen‑Image‑Edit‑2511，结合 ComfyUI、stable‑diffusion.cpp、diffusers 等工具，14GB 级内存/显存即可使用，支持 4bit/FP8/GGUF 多种量化，GGUF 版本还做了“重要层优先”的更新来提质。  
 > 相关链接：[运行指南](https://www.reddit.com/r/LocalLLM/comments/1q7e2ol/guide_how_to_run_qwenimage_diffusion_models_14gb/)｜[Qwen‑Image GGUF](https://huggingface.co/unsloth/Qwen-Image-2512-GGUF)  

 

---  


#### **行业与公司动态**  
##### **华尔街日报：Anthropic 计划再融 100 亿美元，估值或达 3500 亿**  
WSJ 爆料 Anthropic 正在谈一轮约 100 亿美元融资，估值从 4 个月前的 1830 亿拉到 3500 亿，被认为是史上最大私募 AI 融资之一。讨论普遍认为钱主要砸在算力和基础设施，而非短期营收，进一步加剧“头部大模型公司吸走绝大部分资本”的趋势。  
 > 相关链接：[WSJ 报道总结](https://www.reddit.com/r/singularity/comments/1q75o0z/wsj_anthropic_reportedly_raising_10b_at_a_350b/)  

##### **TailwindCSS 资金风波后，Google AI Studio 宣布成为赞助商**  
在“AI 工具用开源却不出钱”争议后，Google AI Studio 对外宣布赞助 TailwindCSS。开发者把代码 Agent 视作“新分发渠道”，呼吁大厂按 token 使用或依赖关系给开源项目分成，有人甚至建议在 IDE 中按依赖自动做“微打赏”。  
 > 相关链接：[赞助官宣](https://twitter.com/OfficialLoganK/status/2009339263251566902)｜[开源资助讨论](https://twitter.com/nateliason/status/2009279537343836261)  

##### **Autonomous 与 Protege AI 等数据/金融新创拿下数千万级融资**  
金融类 Agent 初创 Autonomous 宣布获得 1500 万美元融资，YC 的 Garry Tan 领投，号称做 0 手续费 AI 理财顾问；数据基础设施公司 Protege AI 则拿到 a16z 领投的 3000 万美元，用于构建“为模型准备数据”的平台。社区也开始吐槽“数据公司一周一个”，同质化严重。  
 > 相关链接：[Autonomous 融资](https://xcancel.com/dlnrb/status/2009008876834922949)｜[Protege AI 融资](https://xcancel.com/withprotegeai/status/2009274652183363639)  

##### **NVIDIA 罕见地在 CES 不发新显卡，把舞台让给 AI**  
Tom’s Hardware 报道，NVIDIA 五年来首次在 CES 上不发布任何新 GeForce GPU，之前盛传的 RTX 50 Super 系列被官方否认。业内普遍解读为重心全面偏向数据中心和 AI 芯片线，而不是消费级显卡的小步更新。  
 > 相关链接：[相关报道](https://www.tomshardware.com/pc-components/gpus/for-the-first-time-in-5-years-nvidia-will-not-announce-any-new-gpus-at-ces-company-quashes-rtx-50-super-rumors-as-ai-expected-to-take-center-stage)  

 

---  

  
