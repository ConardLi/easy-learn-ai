#### **Model Updates and Performance**  
##### GPT-5.2 发布：基准高分但真实反馈分化  
GPT-5.2 在 ARC AGI 2 等基准上得分很高，但在真实的创意写作与编码任务中不如 GPT-5.1。输出 token 价格 $14/百万（5.1 为 $10），并因疑似“刷榜/过拟合基准”遭到批评。  
 > 相关链接：[ARC AGI 2](https://artificialanalysis.ai)｜[LMArena](https://lmarena.ai)  

##### 社区测试：Claude Opus 4.5 在编码任务中占优  
社区成员认为 Claude Opus 4.5 在编码上优于 GPT-5.2，Gemini 3 Pro 也是可行替代；Opus 4.5 主要因稳定性与成本更受偏好。  
 > 相关链接：[LMArena Discussion](https://discord.com/channels/1340554757349179412)  

##### Gemini 3 Pro 在真实任务中遭遇性能质疑  
Gemini 3 Pro 虽在基准上表现不错，但在图像分析与真实编码任务中吃力，用户更偏向 GPT-5.1 或 Claude Opus 4.5。  
 > 相关链接：[LiveBench](https://livebenchmark.com/)  

##### GPT-5.2 Pro 因高价与表现引发反弹  
GPT-5.2 Pro 输出 token 价格 $168/百万，但在 LMArena 的基础测试中表现不佳，用户更倾向选择免费替代方案。  
 > 相关链接：[LMArena](https://lmarena.ai)｜[OpenRouter Discussion](https://discord.com/channels/1091220969173028894)  

##### 视觉任务：Gemini 3 Pro 更受青睐  
用户认为 Gemini 3 Pro 在视觉任务上优于 GPT-5.2，但仍会出现部分图像分析错误。  
 > 相关链接：[OpenAI Discord](https://discord.com/channels/974519864045756446)  

##### GPT-5.2 图像分析错误频发  
用户反馈 GPT-5.2 的图像分析仍有不少错误，图像生成模型仍为 gpt-image-1。  
 > 相关链接：[OpenAI Discord](https://discord.com/channels/974519864045756446)  

 

---  


#### **社区讨论与项目**  
##### NVIDIA Nemotron 模型在 Hugging Face 意外泄露  
NVIDIA 疑似误将即将发布的 Nemotron 系列模型文件夹（如 NVIDIA-Nemotron-Nano-3-30B-A3B-BF16）上传至 Hugging Face，导致未发布数据暴露。  
 > 相关链接：[Reddit Thread](https://www.reddit.com/r/LocalLLaMA/comments/1pkpxss/someone_from_nvidia_made_a_big_mistake_and/)  

##### TimeCapsuleLLM 在 19 世纪伦敦文本上训练  
开源项目 TimeCapsuleLLM 使用 90GB 的 19 世纪伦敦文本数据集，训练了 3 亿参数模型，并提供偏见报告；代码在 GitHub/Hugging Face 可获取。  
 > 相关链接：[GitHub](https://github.com/haykgrigo3/TimeCapsuleLLM)｜[Hugging Face](https://huggingface.co/haykgrigorian/v2mini-eval1)  

##### 社区分享高性能本地 LLM 服务器组装方案  
用户分享一套本地 LLM 服务器配置（X570 Taichi、Ryzen 3950x、3 张 GPU：2x3090 + 1x4090），配 10GBe 网卡与 8TB NVMe 存储。  
 > 相关链接：[Reddit Thread](https://www.reddit.com/r/LocalLLaMA/comments/1pl0ojb/the_new_monsterserver/)  

##### Reddit 讨论 GPT-5.2 基准过拟合  
Reddit 用户质疑 GPT-5.2 的高基准分数，怀疑存在过拟合，同时指出其真实表现落后于 GPT-5.1。  
 > 相关链接：[Reddit Thread](https://www.reddit.com/r/singularity/comments/1pkp2sw/simplebench_for_gpt_52_and_gpt_52_pro_both_scored/)  

##### Discord 用户讨论 Perplexity Pro 限额  
Perplexity 用户讨论更早触发 prompt 限额的问题，并引用文档与 Reddit 讨论，认为对 Claude 等高成本模型可能存在更严格的节流策略。  
 > 相关链接：[Discord Discussion](https://discord.com/channels/1047197230748151888/1047649527299055688)  

##### Reddit 讨论 12GB 显存可跑的无审查 NSFW LLM  
用户讨论 12GB 显存/32GB 内存条件下可用的“无审查”NSFW LLM，推荐包括 TheDrummer_Cydonia-24B 等。  
 > 相关链接：[Reddit Thread](https://www.reddit.com/r/LocalLLaMA/comments/1pkidf6/what_is_the_smartest_uncensored_nsfw_llm_you_can/)  

 

---  


#### **硬件与基础设施**  
##### 7900 XTX 为 30GB 模型提供高性价比  
7900 XTX（24GB 显存）在运行 Qwen3 Coder 等 30GB 模型时，性能接近 4090，但成本仅约三分之一（$600-700 美元）。  
 > 相关链接：[Discord Discussion](https://discord.com/channels/1110598183144399058/1153759714082033735)  

##### 社区讨论约 250 欧元购入 RTX 3090  
社区成员讨论以约 250 欧元价格获取 RTX 3090 的可能性，并将 RTX 3060（合计 24GB 显存）作为替代方案。  
 > 相关链接：[Discord Discussion](https://discord.com/channels/879548962464493619/879548962464493622)  

##### SuperMicro 机箱服务器供电 GPU 的难题  
用户讨论在 SuperMicro 3U 机箱中为 GPU 供电的问题：因缺少标准供电接口，需要使用 12V 供电轨连接器或外置电源。  
 > 相关链接：[Discord Discussion](https://discord.com/channels/1110598183144399058/1153759714082033735)  

##### 部分用户 float32 训练导致系统卡死  
用户反馈 float32 训练时数据泄漏到 pagefile 导致系统卡死，修复后已恢复正常。  
 > 相关链接：[LM Studio Discord](https://discord.com/channels/1110598183144399058/1153759714082033735)  

 

---  


#### **越狱与安全**  
##### Gemini 3 Pro 通过系统命令提示词被越狱  
用户称可通过系统提示词将 Gemini 3 Pro 置于“unfiltered research”模式实现越狱，相关内容在 GitHub 仓库中分享。  
 > 相关链接：[Jailbreaks Repo](https://github.com/pranrichh/Jailbreaks)  

##### DeepSeek 通过 Zalgo 输出被越狱  
用户分享通过 Zalgo 风格文本绕过过滤的 DeepSeek 越狱方式，据称对敏感内容与编码任务均有效。  
 > 相关链接：[Jailbreaks Repo](https://github.com/pranrichh/Jailbreaks)  

##### Claude Opus 4.5 通过 one-shot 提示词被越狱  
用户称可用 one-shot 提示词激活“unfiltered research”模式，从而越狱 Claude Opus 4.5 与 Sonnet 4.5。  
 > 相关链接：[Jailbreaks Repo](https://github.com/pranrichh/Jailbreaks)  

##### 社区争论 LLM 是否会“幻觉”出非法内容  
用户讨论 LLM 是否会“幻觉”出 LSD 配方等非法内容，并以带胁迫性的提示词进行测试与争论。  
 > 相关链接：[BASI Jailbreaking Discord](https://discord.com/channels/1105891499641684019/1235691879492751460)  

 

---  


#### **工具与框架更新**  
##### Unsloth 的 Devstral 修复提升模型效果  
用户称在应用 Reddit 提供的 Devstral 修复（主要是 chat template 问题）后，Unsloth 的效果明显改善。  
 > 相关链接：[Reddit Guide](https://www.reddit.com/r/LocalLLaMA/comments/1pkflfw/run_mistral_devstral_2_locally_guide_fixes_25gb/)  

##### MCP 规范更新：Prompt 数据类型与危险工具标记  
MCP 贡献者澄清 prompt 数据类型，并提议对“危险工具”进行标记，以限制 Claude Code 等客户端的自动接受行为。  
 > 相关链接：[MCP Spec](https://modelcontextprotocol.io/specification/2025-11-25/server/prompts#data-types)｜[PR #1913](https://github.com/modelcontextprotocol/modelcontextprotocol/pull/1913)  

##### Unsloth GRPO 补丁改善训练  
Unsloth 的补丁针对不支持的模型返回 hidden states 而非 logits，修复 GRPO 相关问题并提升奖励训练效果。  
 > 相关链接：[Unsloth GitHub](https://github.com/unslothai/unsloth/pull/3718)  

##### DSPy 与 ReasoningLayer 集成用于神经符号 AI  
ReasoningLayer AI 在本体（ontology）摄取流程中使用 DSPy GEPA，为 LLM 增加结构化推理能力，并开放候补名单。  
 > 相关链接：[ReasoningLayer](https://reasoninglayer.ai)｜[DSPy Discord](https://discord.com/channels/1161519468141355160)  

##### Unsloth 社区呼吁推出微调 UI  
Unsloth 用户希望提供微调 UI，社区反馈积极，但仍在开发中。  
 > 相关链接：[Unsloth Discord](https://discord.com/channels/1179035537009545276/1179035537529643040)  

 

---  

  
