#### **模型与能力**  
##### **GPT-5.3-Codex 与 Claude Opus 4.6：前沿编码模型对刚**  
OpenAI 推出 GPT-5.3-Codex，主打自举开发、SWE-Bench Pro/Terminal-Bench 高分、推理更细但无公开 API；Anthropic 发布 Claude Opus 4.6，ARC-AGI 2 达 68.8%、长上下文和推理全面提升，在 Arena 夺得代码/文本/专家多榜首，社区实际对比中两者在真实项目上各有强项与成本差异。  
 > 相关链接：[GPT-5.3-Codex 介绍](https://openai.com/index/introducing-gpt-5-3-codex/)｜[Claude Opus 4.6 官宣与基准](https://www.anthropic.com/news/claude-opus-4-6)｜[Rails 生产仓基准：Codex vs Opus](https://www.reddit.com/r/ClaudeAI/comments/1qxr7vs/gpt53_codex_vs_opus_46_we_benchmarked_both_on_our/)｜[Opus 4.6 代码与长上下文实测讨论（Twitter 汇总）](https://twitter.com/arena/status/2019842691442569566)  

##### **长上下文与记忆：Opus 4.6、InfMem、LatentMem 等方案**  
Opus 4.6 在 256k–100万 token 长上下文任务上表现明显优于 Gemini 3 Pro 等，同时社区吐槽实际使用时仍会“上下文腐烂”。学术侧提出 InfMem（预想-检索-写入 + RL）和 LatentMem（按角色压缩轨迹到潜在记忆）等方法，在百万级上下文问答和多智能体协作上兼顾准确率和延迟，号称可降 3–4 倍推理时长、节省约 50% token。  
 > 相关链接：[Opus 4.6 长上下文基准讨论](https://www.reddit.com/r/Bard/comments/1qwsjvq/opus_46_is_live_so_is_our_glorious_3_pro_ga_still/)｜[InfMem 论文讨论](https://twitter.com/omarsar0/status/2019759999170556189)｜[LatentMem 论文讨论](https://twitter.com/dair_ai/status/2019778133550125515)  

##### **Google Sequential Attention 与模型剪枝讨论**  
Google Research 重提“Sequential Attention”技术，用子集选择的方式在保持精度的前提下降低大模型计算量，主要面向特征选择和剪枝场景。Reddit 上有人指出论文早在三年前就发了，更像是回炉宣传；也有人关心它是否会落到 Gemma 等新模型上，用于推理加速和参数压缩。  
 > 相关链接：[Sequential Attention 论文](https://arxiv.org/abs/2209.14881)｜[Reddit 讨论：Google Research announces Sequential Attention](https://www.reddit.com/r/LocalLLaMA/comments/1qwboqn/google_research_announces_sequential_attention/)  

##### **世界模型落地：Waymo 联合 DeepMind Genie 3 做仿真**  
Waymo 基于 DeepMind 的 Genie 3 发布自家世界模型，可生成包含摄像头 + 三维激光雷达的逼真交通场景，用来在仿真中制造极端事件（龙卷风、飞机迫降高速等）压力测试自动驾驶系统。研究者认为，这是从“只会生成像素”到“直出传感器流”的关键跃迁。  
 > 相关链接：[Waymo World Model 公告](https://twitter.com/Waymo/status/2019804616746029508)｜[DeepMind 介绍 Genie 3 在 Waymo 中的应用](https://twitter.com/GoogleDeepMind/status/2019809201812545835)  

##### **gWorld：用网页代码而不是像素生成手机 GUI 世界**  
Trillion Labs 与 KAIST 发布 gWorld，8B/32B 开源视觉世界模型，不直接预测像素，而是生成 HTML/CSS/JS 再渲染 UI。8B 模型在 MWMBench 上达 74.9% 准确率，据称在某些 GUI 任务上超越 402B Llama 4 Maverick，渲染失败率低于 1%。社区对“碾压 402B”的标题持保留态度，但认可这条“用结构代码代替像素”的思路。  
 > 相关链接：[gWorld-8B 模型（Hugging Face）](https://huggingface.co/trillionlabs/gWorld-8B)｜[Reddit 讨论：We built an 8B world model...](https://www.reddit.com/r/LocalLLaMA/comments/1qwo9j0/we_built_an_8b_world_model_that_beats_402b_llama/)  

 

---  


#### **Agent 与工具链**  
##### **Claude Code / Codex / Cursor：多智能体“软件团队”模式成型**  
Cursor 与 Anthropic 都在推“代理团队”：Cursor 宣称上百个代理一周内每小时能打出上千次提交；Anthropic 用 16 个 Claude 代理在两周内写出能编译 Linux 内核的 C 编译器。社区发现，真正决定表现的往往是测试用例、Git 工作流和基础设施配置，而不只是模型本身。  
 > 相关链接：[Cursor 多代理提交实验](https://x.com/cursor_ai/status/2019456112806732159)｜[Claude Code agent teams 预览](https://x.com/lydiahallie/status/2019469032844587505)｜[Anthropic 工程博文：用 Opus 4.6 写 C 编译器](https://x.com/anthropicai/status/2019496582698397945)  

##### **OpenClaw / Moltbot：本地 Agent 框架真香但真贵**  
社区实测 OpenClaw + 本地 LLM（如 Qwen3Coder）能做出很强的自迭代代理，但安全面大、文档弱，很多人选择在受限账号、限定目录下跑。Moltbot 被吐槽“免费助手”实则要绑一堆付费 API（OpenAI/Anthropic/Google、Brave、ElevenLabs 等），算下来每月 50–100 美金，更适合开发者折腾而不是终端用户用。  
 > 相关链接：[Reddit：OpenClaw with local LLMs 讨论](https://www.reddit.com/r/LocalLLM/comments/1qx51zc/openclaw_with_local_llms_has_anyone_actually_made/)｜[Reddit：Clawdbot / Moltbot → Misguided Hype?](https://www.reddit.com/r/LocalLLM/comments/1qwg8an/clawdbot_moltbot_misguided_hype/)  

##### **“递归语言模型 RLM” 与 LangChain / DSPy 的工程化尝试**  
Twitter 上有人提出把 Agent 看成 REPL 程序：状态放变量、子代理之间传结构化数据而不是在 prompt 里乱贴日志，以此减少“上下文腐烂”。与此同时，LangChain/LangSmith 强调 trace、沙箱和有类型状态管理，DSPy 社区则推广 RLM 模式配合自动调参，让复杂工具流更可控、可复现。  
 > 相关链接：[RLM 概念贴](https://twitter.com/deepfates/status/2019912654173651131)｜[DSPy 博文：用 RLM 减缓上下文腐烂](https://blog.isaacbmiller.com/posts/rlm)｜[LangChain 关于 trace / sandbox 更新](https://twitter.com/LangChain/status/2019848808310706367)  

##### **BalatroBench：用卡牌 Roguelike 测 LLM 策略水平**  
BalatroBench 把卡牌游戏 Balatro 包装成基准：通过 BalatroBot 提供游戏状态 API，再用 BalatroLLM + Jinja2 prompt 让模型决策。支持任意 OpenAI 兼容端点，主要测试模型长期规划与策略一致性。有人提议接入各类“自进化”框架，看哪家模型最会自己调教自己。  
 > 相关链接：[BalatroBot GitHub](https://github.com/coder/balatrobot)｜[BalatroLLM GitHub](https://github.com/coder/balatrollm)｜[基准主页 BalatroBench](https://balatrobench.com/)  

##### **AI 代码助手栈：Cline、aider、Cursor、Copilot 组合拳**  
Cline 用户在摸索如何用 .clineignore、记忆库和 RAG 把上下文从 20 万 token 收紧到 4 万，以便用小模型更快迭代。aider 社区在调教 Copilot/Opus 架构模式和自动接受变更开关；Cursor 用户则在抱怨 5.3 Codex 一直卡在 API 未开放阶段，Agent 模式用完免费额度就停机，亟需“慢速档”。  
 > 相关链接：[Reddit：Cline 上下文与记忆管理经验](https://www.reddit.com/r/CLine/comments/1qx4m16/how_are_people_managing_context_memory_with_cline/)｜[Reddit：Claude Opus 4.6 可用于 Cline](https://www.reddit.com/r/CLine/comments/1qx158e/claude_opus_46_is_now_available_in_cline/)｜[aider 文档：配置选项](https://aider.chat/docs/config/options.html)  

 

---  


#### **基础设施与硬件**  
##### **Blackwell / CUDA / Vulkan：推理性能里藏着一堆坑**  
GPU MODE 与 LM Studio 社区实测发现：Blackwell 上 cuBLASLt 选错 FP8 kernel 会导致吞吐差 2 倍，需要强制用新 MXFP8 指令；部分 B200 在用 TMA + NCU profiling 时会死锁。LM Studio 用户还发现 Vulkan 跑本地 LLM 在某些 NVIDIA 卡上比 CUDA 快 50%，而苹果 M4 Max 上 MLX 跑 Qwen3-Coder-Next 的 4bit 推理速度是 GGUF 的两倍多。  
 > 相关链接：[GPU MODE 讨论：Blackwell FP8 与 MXFP8](https://discord.com/channels/1189498204333543425/1189607726595194971/1469123524470898819)｜[NCU + TMA 死锁复现代码](https://cdn.discordapp.com/attachments/1189607726595194971/1469482712657166346/ncu_tma_repro.zip)｜[LM Studio Vulkan vs CUDA 讨论](https://discord.com/channels/1110598183144399058/1153759714082033735/1469136051414237267)  

##### **本地推理硬件现实：老 i3 / CPU-only 也能玩 LLM**  
多篇 Reddit 帖子展示了“土炮”本地推理：2018 年 8 代 i3 + UHD 620 + 双通道内存，用 OpenVINO 跑 16B MoE 模型还能到 10 token/s；老台式 i5-8500 + 32GB 内存能跑 12B Q4 gguf，对话、TTS 甚至慢速 Stable Diffusion 都能用。社区共识是：带宽比算力更关键，MoE 架构和低比特量化是穷人之友。  
 > 相关链接：[CPU-only 跑各类本地 AI](https://www.reddit.com/r/LocalLLaMA/comments/1qxgkd1/cpuonly_no_gpu_computers_can_run_all_kinds_of_ai/)｜[2018 i3 跑 16B MoE DeepSeek Coder](https://www.reddit.com/r/LocalLLaMA/comments/1qxcm5g/no_nvidia_no_problem_my_2018_potato_8th_gen_i3/)｜[完全离线使用 AI 的经验](https://www.reddit.com/r/LocalLLM/comments/1qwjgj4/anyone_here_actually_using_ai_fully_offline/)  

##### **训练与评测基础设施：Step 3.5-Flash 与 SETA 终端环境**  
StepFun 公布 Step 3.5-Flash 技术细节：用 4096 张 H800、17.2T token 训练，SWE-Bench 得分 74.4，并强调评测前置于训练、要处理好数据污染与长输出监控。另一方面，SETA 开源了 1376 个可复现实终端环境，覆盖 DevOps、安全、运维，用来让代码 Agent 在真实系统里“带着锅跑”而不是只刷合成题。  
 > 相关链接：[Step 3.5-Flash 技术报告讨论](https://xcancel.com/teortaxesTex/status/2019356468362010972)｜[SETA 终端环境集发布](https://x.com/guohao_li/status/2019527791876653353)  

 

---  


#### **研究与方法**  
##### **Hugging Face Community Evals：把基准分数写进仓库的 YAML**  
HF 推出 Community Evals：基准数据集挂榜单，评测结果直接以版本化 YAML 存在模型仓库里，通过 PR 提交，并配合 Inspect AI 做可复现标记。目标不是解决数据泄漏，而是让“这分是怎么测的”有迹可循。也有研究者提醒：很多难基准（多语 SWE-Bench、SciCode、VideoGameBench 等）离“做满”还远。  
 > 相关链接：[Hugging Face 官方介绍](https://twitter.com/huggingface/status/2019754567685050384)｜[社区讨论与质疑](https://twitter.com/ben_burtenshaw/status/2019795723378942295)｜[Ofir Press：基准还没饱和](https://twitter.com/OfirPress/status/2019755847149056456)  

##### **TinyLoRA：只调 13 个参数就把 GSM8K 从 76% 拉到 91%**  
StepFun 团队提出 TinyLoRA，在 Qwen-7B 上只训练 13 个 LoRA 参数，再配合 RL，就能把 GSM8K 正确率从 76% 拉到 91%。解释是“知识早就在模型里，只是换个思考风格”，所以只需微调很少的参数就能把推理路径导到正确轨迹。  
 > 相关链接：[TinyLoRA 推文](https://xcancel.com/jxmnop/status/2019251724020772933)  

##### **Kaiming He 新作：Drifting 生成模型与梯度归一化归因研究**  
Kaiming He 在 OpenReview 上发了“Generative Modeling via Drifting”，探讨新的生成建模框架。Eleuther 社区还讨论了两篇与训练样本归因相关的工作：一篇指出对梯度做 unit norm 能显著提升 attribution 准度，另一篇则认为只要 Hessian 估计得足够好，就不必强制归一。  
 > 相关链接：[Generative Modeling via Drifting](https://openreview.net/forum?id=CFewUmgIILK)｜[梯度归一化提升归因精度论文](https://arxiv.org/html/2410.17413v1)｜[关于 Hessian 与归一化的后续论文](https://arxiv.org/pdf/2504.16430)  

##### **AI4Science：自动实验与新基准 Labbench2**  
OpenAI 与 Ginkgo Bioworks 宣布将 GPT-5 接入自动化湿实验室，闭环做蛋白实验，据称能把生产成本压 40%。同时，Labbench2 发布，包含约 1900 道实验设计、临床试验评估等难题，用来更真实地衡量“科学向”模型，而不是只看解题选择题。  
 > 相关链接：[OpenAI × Ginkgo Bioworks 合作](https://xcancel.com/OpenAI/status/2019488071134347605)｜[Labbench2 基准介绍](https://xcancel.com/andrewwhite01/status/2019500207462092960)  

 

---  


#### **产品与应用落地**  
##### **Perplexity Pro 限额收紧，用户开始出走**  
Perplexity 悄悄下调 Pro 版 Deep Research 次数和文件上传大小，被用户截图对比旧版配额后在 Discord 怒喷“没沟通”。不少人开始试用 Gemini Pro（先给研究计划再执行）和 DeepSeek（免费但对中资背景有顾虑），对订阅制问答产品的信任被狠狠敲了一下。  
 > 相关链接：[Perplexity 配额变化截图](https://cdn.discordapp.com/attachments/1047649527299055688/1469259948302139402/image.png)  

##### **企业工程师怎么用 AI：更多是“超级搜索”，不是自动写系统**  
一篇面向专业工程师的 Reddit 讨论总结：AI 目前最实用的是当高级搜索/示例生成器，比如写 SQL、看 API、查厂内老代码；让它大改复杂代码库效果很差，容易瞎编。很多“AI 项目”最后发现用 RPA 或简单脚本就够了，真正能在公司规模上产生明显收益的 AI 项目只是少数。  
 > 相关链接：[Reddit：工程师如何用 AI 提升生产力](https://www.reddit.com/r/PromptEngineering/comments/1qxh14g/professional_engineers_how_are_you_using_ai_tools/)  

##### **Lotus：拿到 4100 万美金，要用 AI+真人填补美国基层医疗缺口**  
初创公司 Lotus 宣布融资 4100 万美元，做“AI 驱动+持证医生”的线上初诊平台，主打帮 1 亿缺乏家庭医生的美国人看小病、开药、转诊。模式是 AI 先分诊和整理信息，再由真人医生决策，主打把“问诊前的碎活”外包给模型。  
 > 相关链接：[Lotus 融资与产品介绍](https://xcancel.com/kjdhaliwal/status/2018731342113247533)  

##### **AI 驱动加密产品：把链上合约翻译成“人话”**  
MCP Contributors 社区里有人在做一套面向加密交易的 AI 工具：智能看板 + 链上分析摘要 + 合约/交易自然语言解释，强调“别瞎编”和透明度。目标用户是看得懂业务但看不懂 Solidity/EVM 的普通投资者。  
 > 相关链接：[MCP Contributors 一般讨论](https://discord.com/channels/1358869848138059966/1358869848138059969/1469415929845776477)  

 

---  


#### **行业与公司动态**  
##### **OpenAI vs Anthropic：模型“军备竞赛”背后的烧钱数字**  
有帖子根据泄露/预测数据估算：Anthropic 今年营收或达 180 亿美元、明年 550 亿，但训练支出今年就要 120 亿，推理成本 70 亿，预计 2028 年前累计运营支出 1390 亿美元，指望 2028 年左右持平。投资人愿意给 3500 亿估值，再投 100 亿。讨论里有人反过来怀疑 OpenAI 的偿付能力更差。  
 > 相关链接：[Reddit：算了一下这场 Opus vs Codex 竞赛要烧多少钱](https://www.reddit.com/r/ClaudeAI/comments/1qx0wr3/with_opus_46_and_codex_53_dropping_today_i_looked/)  

##### **Lodash 被欧盟认定为“关键基础设施”，给了 20 万美金**  
用于 JS 生态无数项目的工具库 Lodash 获得欧盟 Sovereign Tech Fund 20 万美元资助，被认定为“关键软件基础设施”。这笔钱主要用于维护与安全加固，提醒大家真正在撑住 AI 和 Web 的，往往是这些默默无闻的小库。  
 > 相关链接：[Sovereign Tech Fund：为何资助 Lodash](https://www.sovereign.tech/tech/lodash)｜[OpenJS 基金会公告](https://openjsf.org/blog/sta-supports-lodash)  

##### **Manus.im 疑似暴雷：降级后被收 5000 美金，站点还挂了**  
Manus.im 的用户在 Discord 抱怨：从高配方案降级后仍被按原价每账号收 5000 美金，客户网站也跟着宕机，联系客服迟迟无回应，邮件则否认曾降级。另有用户账号被莫名封禁。大家开始集体物色替代方案，这对一家做网站托管/构建平台的来说已经是信任危机级别事件。  
 > 相关链接：[Manus.im Discord 投诉](https://discord.com/channels/1348819876348825620/1349440650495398020/1469359555480785090)  

##### **OpenRouter 与 Kimi / Pony Alpha 等多模型生态**  
OpenRouter 上线新的“隐身”模型 Pony Alpha，主打高质量 tool calling 和 agent 工作流；同时接入了 Moonshot 的 Kimi K2.5，社区在讨论其缓存、是否仍有免费额度以及速率限制。OpenRouter 自身用量据称两年内增长近十倍，有人调侃“如果出聊天 App，很多单一厂商就危险了”。  
 > 相关链接：[Pony Alpha 模型页面](https://openrouter.ai/openrouter/pony-alpha)｜[OpenRouter 使用量增长截图讨论](https://discord.com/channels/1091220969173028894/1392278974222307469/1469155197476540548)  

 

---  


#### **政策、治理与安全**  
##### **Codex 默认能读整块文件系统：安全边界被质疑**  
OpenRouter 社区有人发现：OpenAI 的 Codex 在本地运行时默认可以读取整个文件系统，没有明显的权限开关，官方 issue 还认为“不是 bug”。实际例子包括读出 API key、个人体检结果等敏感文件。大家担心：如果 IDE/Agent 工具不给出清晰的权限模型，开发者甚至不知道自己把什么暴露给模型了。  
 > 相关链接：[Codex issue：能读全盘且官方不认为是问题](https://github.com/openai/codex/issues/2847)｜[Codex issue：读取 API key / 医疗文件](https://github.com/openai/codex/issues/5237)  

##### **Opus 4.6 找出 500+ 开源零日漏洞：安全福音还是双刃剑**  
Anthropic 报告称 Claude Opus 4.6 在沙箱里对开源库做自动审计，挖出 500 多个零日漏洞，还能给出修复方案。Reddit 上一边有人提出可以按“累计修复 CVSS 分值”给模型做新基准，一边有人担心：这么强的挖洞能力公开细节，会不会给黑客送工具箱。  
 > 相关链接：[Reddit：Opus 4.6 uncovers 500 zero-day flaws](https://www.reddit.com/r/singularity/comments/1qxdd6n/opus_46_uncovers_500_zeroday_flaws_in_opensource/)  

##### **AI Red Team 正成热门岗位：Trajectory Labs 招人**  
越多模型暴露在真实用户和工具调用场景下，越多公司开始认真搞红队。Trajectory Labs 这类“隐身 AI 安全公司”在招长期 AI Red Teamer，要求每周至少 30 小时，还设计了专门的“红队闯关游戏”当面试。BASI 社区一边玩 jailbreak，一边有人开始把这当正经职业。  
 > 相关链接：[Trajectory Labs 招聘 AI Red Teamer](https://trajectorylabs.com/careers/ai-red-teamer)  

##### **密钥泄露已成日常，社区呼吁默认集成 detect-secrets**  
不少 Agent/IDE 工具只是把你的仓库直接挂给模型，完全不管密钥。Unsloth、OpenRouter 社区有人建议把 Yelp 的 detect-secrets 这类工具做成默认钩子，在 prompt 和日志里自动打码，至少别再出现把 .env、云凭证和医疗文件一起扔给 LLM 的情况。  
 > 相关链接：[detect-secrets 项目](https://github.com/Yelp/detect-secrets)｜[Unsloth 社区关于密钥保护讨论](https://discord.com/channels/1179035537009545276/1179039861576056922/1469060030069342349)  

 

---  

  
