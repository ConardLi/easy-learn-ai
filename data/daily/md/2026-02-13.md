#### **模型与能力**  
##### **Google 推出 Gemini 3 Deep Think V2：ARC-AGI-2 84.6%，科研工程向推理模式**  
Gemini 3 Deep Think V2 面向 Gemini 应用付费用户上线，并开启 Vertex AI/Gemini API 提前试用。该推理模式在 ARC-AGI-2 达到 84.6%（ARC 官方认证），HLE 48.4%，Codeforces Elo 3455、奥赛级物理化学和 IMO 水平，并已用于半导体材料设计、数学论文审校、草图转 CAD/STL 等工程工作，同时宣称在 ARC 任务上单任务成本降至原来的约 18%。  
 > 相关链接：[Google DeepMind 发布线程](https://twitter.com/GoogleDeepMind/status/2021981517791342807)｜[Google 官方介绍](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/)｜[ARC Prize 认证与费用说明](https://twitter.com/arcprize/status/2021985585066652039)｜[Quoc Le 关于 Deep Think 的科研用例](https://x.com/quocleix/status/2021695658315632898)  

##### **Google Aletheia 数学特化代理：IMO 100 分、ProofBench 91.9%**  
DeepMind 推出的数学研究代理 Aletheia 在 IMO-ProofBench Advanced 得分 91.9%，IMO 2024 任务 100%，明显高于 Gemini 3 Pro 等通用模型。它采用“生成器+验证器”式架构，更像专题证明代理而非通用 LLM，团队计划将同类方法扩展到物理和计算机科学。  
 > 相关链接：[Aletheia 介绍（研究者帖子）](https://bsky.app/profile/sungkim.bsky.social/post/3melpkihpnc2m)  

##### **OpenAI 发布 GPT-5.3-Codex-Spark：千 tok/s 级别超低延迟编程模型**  
OpenAI 与 Cerebras 合作推出编码模型 GPT-5.3-Codex-Spark，先向 ChatGPT Pro 的 Codex 应用/CLI/IDE 扩展开放研究预览。官方宣称生成速度 1000+ tok/s、上下文 128k，当前仅支持文本。社区反馈：速度快到“人类阅读和检查代码”反而成瓶颈，未来 IDE 需要更好的 diff、分任务和防错能力，推测是数十 B 激活的 MoE 大模型。  
 > 相关链接：[OpenAI 官方博客](https://openai.com/index/introducing-gpt-5-3-codex-spark/)｜[OpenAI Dev 公告](https://twitter.com/OpenAIDevs/status/2022009906329739681)｜[Cerebras 合作公告](https://twitter.com/cerebras/status/2022021218208297302)  

##### **MiniMax M2.5：230B 参数 MoE，SWE-Bench Verified 80.2%，极致便宜的“长程 Agent”模型**  
MiniMax M2.5 采用 230B 总参、10B 激活的稀疏架构，主打长任务、多工具调用的 agent 场景。官方给出的 SWE-Bench Verified 80.2%、Multi-SWE-Bench 51.3%、BrowseComp 76.3，在 OpenHands 等实测中在应用开发和修 bug 上接近 Opus，但价格约为其 1/13，100 tok/s 大致 $1/小时，全年 4 实例 7x24 运行约 $1 万美金，已在 OpenRouter、NetMind 等多平台上线。  
 > 相关链接：[MiniMax 官方介绍](https://www.minimax.io/news/minimax-m25)｜[OpenRouter 上的 M2.5](https://openrouter.ai/minimax/minimax-m2.5)｜[OpenHands 评测与成本分析](https://www.reddit.com/r/LocalLLaMA/comments/1r35d2x/minimaxai_minimaxm25_has_230b_parameters_and_10b/)  

##### **Zhipu GLM-5：开放权重新“智力指数 50 分”领头羊**  
GLM-5 在多项社区榜单上成为最强开源模型之一：在 Intelligence Index 得分 50，号称开放权重第一且幻觉率最低；Arena 文本和代码榜单上均为开源模型第 1，总体接近 gpt-5.1-high 和 Kimi。技术侧传闻其总参约 744B、激活 ~40B，训练 28.5T token，引入 DeepSeek 稀疏注意力，针对长上下文和 agent 工程优化，已提供 GGUF 便于本地推理。  
 > 相关链接：[Intelligence Index 讨论贴](https://www.reddit.com/r/LocalLLaMA/comments/1r28xxz/glm5_scores_50_on_the_intelligence_index_and_is/)｜[Arena 榜单](https://arena.ai/leaderboard/code)｜[Unsloth GLM‑5 GGUF 与本地运行指南](https://huggingface.co/unsloth/GLM-5-GGUF)  

##### **DeepSeek V4 即将发布：宣称支持 100 万 token、“平替”顶级闭源模型**  
DeepSeek 官方预告 V4 将在 2 月 17 日前后发布，支持 100 万 token 上下文，被社区视作对 Opus、Codex 等闭源模型的高性价比替代。有用户反馈现版 DeepSeek 在长文本和个性化回复上已有明显进步，更新后“人格”和细腻度更接近 ChatGPT。  
 > 相关链接：[DeepSeek V4 讨论贴](https://www.reddit.com/r/DeepSeek/comments/1r1vg9p/deepseek_v4_is_coming_this_week/)  

##### **Tiny QED‑Nano：4B 证明模型配合百万 token 推理脚手架**  
QED‑Nano 是一个 4B 规模的自然语言定理证明模型，在 IMO‑ProofBench 等基准上接近大模型水准。它依赖重度测试时计算：通过 agent 脚手架将单次证明扩展到 100 万+ token，并用“评分规则→奖励”的 RL 后训练，团队计划开源权重和训练细节。  
 > 相关链接：[QED‑Nano 介绍线程](https://twitter.com/_lewtun/status/2022003874500845813)  

 

---  


#### **Agent 与工具链**  
##### **MiniMax M2.5 & GLM‑5：新一轮“Agent 编程模型”之战**  
这两天最受关注的两个模型都明确往 agent 化靠拢：MiniMax M2.5 主打任务分解、长时间执行和复杂工具链，性能接近 Opus 但便宜一个量级；GLM‑5 在 Arena code/agent 任务中开源第一，被不少 IDE、Agent 框架（Cline、YouWare、Verdent 等）接入，用于多文件重构、Web 项目脚手架和长链路工具调用。  
 > 相关链接：[MiniMax M2.5 发布与场景说明](https://www.minimax.io/news/minimax-m25)｜[GLM‑5 在 Arena 的表现与视频评测](https://www.youtube.com/watch?v=TbK2ngEJUmg)  

##### **Cursor 上线长时运行 Agent，配合超快 Codex Spark**  
Cursor 新增“长时运行 Agent”，可以持续执行大型重构和多步骤任务。社区实测在接入 GPT‑5.3‑Codex‑Spark 后，代码生成和部署几乎“秒回”，但收费和配额较模糊：Composer 1.5 单价显著上涨，不同用户看到的输入/输出计费和模型池限制不一致，引发讨论。  
 > 相关链接：[Cursor 长时 Agent 公告](https://twitter.com/cursor_ai/status/2022046178708492445)  

##### **A2A 代理协议：Andrew Ng 想做“Agent 互联层”**  
Andrew Ng 宣传 DeepLearning.AI 的 Agent2Agent（A2A）协议，目标是让不同 Agent 框架互相发现和调用，对接 IBM ACP、Google ADK、LangGraph、MCP 等，并可以通过 IBM Agent Stack 部署。简单理解就是给各种 Agent 系统制定一套“打电话协议”。  
 > 相关链接：[Andrew Ng 介绍 A2A](https://twitter.com/AndrewYNg/status/2021985280102973931)  

##### **Mooncake：Moonshot/Tsinghua 开源的 KV Cache 服务后端**  
Mooncake 被并入 PyTorch 生态，被定位为解决 LLM 推理“内存墙”的 KV 缓存系统，支持 prefill/decoding 解耦、跨实例缓存复用、弹性专家并行，并能作为 SGLang、vLLM、TensorRT‑LLM 等的后端。Moonshot 强调这是 Kimi 与清华合作的成果，未来将进一步开源。对大规模 Agent 服务成本有直接影响。  
 > 相关链接：[PyTorch 宣布 Mooncake](https://twitter.com/PyTorch/status/2022079425001504933)｜[Kimi 官方说明](https://twitter.com/Kimi_Moonshot/status/2022109533716533612)  

##### **Google Search MCP、SigLIP2 等“轻工具”正在取代大模型“什么都干”**  
社区在给本地/私有 Agent 配工具带时，越来越倾向于：用专用组件干单一任务。例子：无 API key 的 Google Search MCP（基于 Chromium，附带 YouTube 转写、图片搜索、本地 OCR），大规模图片打 tag 用 SigLIP2 vision encoder，而不是直接丢给多模态 LLM。这种搭配可以显著降成本并提升稳定性。  
 > 相关链接：[noapi-google-search-mcp 项目](https://github.com/VincentKaufmann/noapi-google-search-mcp)｜[SigLIP2 介绍](https://huggingface.co/blog/siglip2)  

##### **Traces：专门用来“看别人的 Agent 会话记录”的平台**  
有开发者上线 Traces 平台，用来分享和浏览编码 Agent 的完整会话轨迹，目前支持从 Claude Code、Codex、Gemini、Cursor 等导出。定位有点像“AI 开发者的 Rewind/录屏”，方便研究不同模型、提示词和工作流下，Agent 实际一步步是怎么干活的。  
 > 相关链接：[Traces 官网](https://www.traces.com)  

##### **Aider、Windsurf、OpenRouter 等工具围绕新模型快速迭代**  
Aider 发布 v0.86.2，社区仍认为 DeepSeek‑V3.2 是综合性能/价格最优的代码模型之一；Windsurf 则把 Opus 4.6、SWE‑1.5、GPT‑5.3‑Spark 拉入自己的 Arena 对战；OpenRouter 这边则快速接入 MiniMax M2.5、GLM‑5 等新模型，并提供多应用接入，但其 App 列表改版被吐槽“更像模型转发器榜单”。  
 > 相关链接：[Aider 更新说明](https://github.com/Aider-AI/aider/commits/main/)｜[Windsurf Arena 公告](https://windsurf.com/blog/windsurf-arena-mode-leaderboard)｜[OpenRouter MiniMax M2.5 公告](https://twitter.com/OpenRouterAI/status/2021983955898315238)  

 

---  


#### **基础设施与硬件**  
##### **torchao v0.16.0：加入 MXFP8 MoE 积木，继续往“推理友好”方向瘦身**  
PyTorch 官方的 ao/torchao 模块发布 0.16.0，新增 MXFP8 MoE 训练组件以支持专家并行，同时砍掉一些老配置和冷门量化选项，目标是让量化/压缩栈更精简、ABI 更稳定。对想自己训 MoE 或做低精度部署的人是一个重要基础库更新。  
 > 相关链接：[torchao v0.16.0 Release Notes](https://github.com/pytorch/ao/releases/tag/v0.16.0)  

##### **GPU MODE 社区：准备烧掉 2–3 万美元算力做一轮“AI 自动写 kernel”试验**  
GPU MODE 宣布将在 2 月底集中采购 4–5 天、约 2–3 万美金的算力，专门用来尝试用 Qwen3/GLM4.7 Flash 等模型做 CUDA/Triton kernel 生成。配套使用 Kernelbot、Flashinferbench 评测，清理环境、接入 NCU/Compute‑Sanitizer 作为工具调用，先搞一批靠谱 SFT 基线再做 RL。想看“AI 写 kernel 到底靠不靠谱”的人可以关注这波结果。  
 > 相关链接：[FlashInfer Bench 文档（含 agents 部分）](https://bench.flashinfer.ai/docs/api/python/rst/agents)｜[Flashinfer-bench 相关 PR](https://github.com/flashinfer-ai/flashinfer-bench/pull/183)  

##### **TraceML：一行代码看出哪块 GPU 在拖后腿**  
有工程师开源了 TraceML，用来给 PyTorch DDP 做实时观测：每个 rank 的 step 时间、抖动和时间分布一目了然，基本只需加一行 hook。解决的是很常见但很烦人的问题：多卡训练以为在“齐步走”，其实有一块卡在偷偷拖慢所有人。  
 > 相关链接：[TraceML GitHub](https://github.com/traceopt-ai/traceml/)  

##### **3060 12GB 成穷人 CUDA 神器，本地 LLM 社区大规模囤卡**  
LM Studio 社区有人发现 Zotac 官店在清仓 3060 12GB，单卡约 200 美金，比很多旧数据中心卡还划算。两张就是 24GB VRAM，本地跑中型模型 + 一些 CUDA 工作足够；同时对比了买 V100 二手等方案。可以预期未来会有更多“穷人 AIGC 服务器”基于这类卡。  
 > 相关链接：[Zotac 3060 12GB 链接示例](https://www.zotacstore.com/us/zt-a30600p-10m-r)  

##### **NCU/ROCm 细节问答：从 tcgen05 到 Quick Reduce**  
NVIDIA 这边，社区整理了 NCU 报告中 Local(57) 等字段的含义（表示映射到该源码行的局部内存指令数，常由寄存器溢出导致），以及 tcgen05.cp / .st / .mma 的正确使用方式。AMD 这边则有人质疑 Quick Reduce 只在 MI300 上启用，实际在 MI250X/CDNA2 也能跑，只是官方 guard 掉了。可以看作是高性能 AllReduce/低比特训练里的“小坑填平指南”。  
 > 相关链接：[AMD Quick Reduce 说明](https://rocm.blogs.amd.com/artificial-intelligence/quick-reduce/README.html)｜[QuickReduce 项目](https://github.com/mk1-project/quickreduce)  

 

---  


#### **研究与方法**  
##### **Anthropic “Introspection” 与社区吐槽：这算自省还是“多加一个压力传感器”？**  
Anthropic 新论文提出用一个额外网络监控主模型的激活/权重异常，称之为“Introspection”。Unsloth 等研究者认为更像是一个冗余监测网，类似在高压锅上加压力表；支持者则指出模型确实可以检测细微“被操控”迹象，对安全有实用价值。命名偏理想化，本质仍是分布偏离检测。  
 > 相关链接：[Anthropic Introspection 论文](https://www.anthropic.com/research/introspection)  

##### **BlendFER‑Lite：用 LSTM + MediaPipe 在边缘设备做表情识别**  
新论文提出 BlendFER‑Lite，将 MediaPipe 的 3D 表情参数作为特征，用 LSTM 预测情绪，在 FER2013 上达 71% 准确率，与大模型相当但计算开销小很多，适合机器人和边缘设备实时使用。代码和模型已在 Hugging Face 放出。  
 > 相关链接：[论文（Frontiers in Neurorobotics）](https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2025.1678984/full)｜[BlendFER‑Lite 代码与模型](https://huggingface.co/papers/2501.13432)  

##### **Rank‑1 LoRA 竟然能打平完整 RL 调优？**  
Thinking Machines 的实验表明，在某些推理任务上，只用 rank‑1 LoRA 做微调，就能达到和全模型 RL 微调相近的效果。后续论文进一步讨论这是否只是 In‑Context Learning 的表现。对想省钱做推理增强的人来说，这是非常实在的结果。  
 > 相关链接：[博客：Reasoning with LoRA](https://thinkingmachines.ai/blog/lora/)｜[相关论文](https://arxiv.org/abs/2406.04391)  

##### **GoodfireAI：用“特征奖励”的 RLFR 优化开放式任务**  
GoodfireAI 提出 Reinforcement Learning from Feature Rewards（RLFR），核心思路是先用可解释方法提取特征，再用这些特征构造更稳定的奖励函数，对开放式任务做 RL。相比传统“靠人类打分”，更接近“能解释的奖励设计”。  
 > 相关链接：[GoodfireAI RLFR 介绍](https://xcancel.com/goodfireai/status/2021644164820348959)  

##### **Nick Bostrom、Emergent Behavior 等关于“涌现能力”的持续争论**  
Nick Bostrom 新论文继续从哲学和决策论角度审视高级 AI 风险；技术界这边，关于“大模型涌现能力是不是假象”的争论还在继续：一派认为很多“阶跃表现”其实是指标设计和采样方法导致，另一派则给出新数据支持有真实的非线性点。对未来“AGI 时间表”的判断，两派结论显然不同。  
 > 相关链接：[A Theory of Emergent Behaviour](https://arxiv.org/abs/2511.10643)｜[Are Emergent Abilities of LLMs a Mirage?](https://arxiv.org/abs/2304.15004)  

 

---  


#### **产品与应用落地**  
##### **Simile：拿 1 亿美金做“社会级数字孪生”的模拟公司**  
Simile 宣称用“生成式代理 + 基础模型”模拟真实人群行为，让企业在真实上线前先在虚拟社会里测试决策，应用包括财报电话会彩排、政策调整等。刚融了 1 亿美金，投资人包括 Karpathy 和 Fei‑Fei Li，被不少人类比作现实版“心理史学”。  
 > 相关链接：[Simile 产品介绍与融资帖](https://twitter.com/joon_s_pk/status/2022023097017421874)｜[Karpathy 转发评论](https://twitter.com/karpathy/status/2022041235188580788)  

##### **ChatGPT 在“看病前一跳”上的真实案例：多起用户表示被救了一命**  
多名 Reddit 用户分享：ChatGPT 根据症状和检验报告，强烈建议他们立刻就医，结果查出肺栓塞、心梗、带状疱疹等严重问题。大家普遍看法是：LLM 在“列可能诊断 + 提建议检查”环节非常有用，但只能做第二意见/早期筛查，最后诊断还是要医生。  
 > 相关链接：[肺栓塞案例贴](https://www.reddit.com/r/ChatGPT/comments/1r2mooz/this_morning_chatgpt_talked_me_out_of_toughing/)｜[GPT 作为“最强医生助理”的长帖](https://www.reddit.com/r/ChatGPT/comments/1r2arl6/gpt_is_goated_as_a_doctor/)  

##### **Kimi、DeepSeek、GLM：中文圈“本地+云”多模态编程体验反馈**  
Kimi K‑2.5 在写求职信、克隆网站这类任务上被频繁表扬，多模态网页浏览体验胜出，但也有人吐槽在复杂代码库里乱建文件、不懂上下文；GLM‑5、DeepSeek V3.2 则在工具调用和长上下文表现更稳。整体趋势：大家经常混搭，用一个模型做“脑力”，另一个模型做“长代码苦力”。  
 > 相关链接：[Kimi 使用体验讨论](https://discord.com/channels/1369594130807787570/1371757564005711973)｜[GLM/DeepSeek 在 coder 工具中的实践](https://arena.ai/leaderboard/code)  

##### **Weave Robotics Isaac 0：8000 美金的“叠衣服家用机器人”开卖**  
Weave Robotics 在湾区率先发售 Isaac 0，专门帮你叠洗好的衣服，售价 8000 美金或 450 美金/月订阅，首批 2026 年 2 月交付。目前只支持旧金山湾区上门，对“家务自动化”算是一个现实但昂贵的样本。  
 > 相关链接：[Isaac 0 产品页面](https://weaverobotics.com)  

##### **AI 个人用例：从“AI 写黄文”到“AI 写简历”，需求极其接地气**  
Jailbreak 社群有人坦承会为 ChatGPT 付费只为写小黄文，也有人用 Kimi/GPT 批量生成求职信、每天自动投十几份简历。总体感受：真正黏住个人用户的往往不是“AGI 梦想”，而是这些很生活化的小需求。  
 > 相关链接：[BASI Jailbreaking 相关讨论](https://discord.com/channels/1105891499641684019)  

 

---  


#### **行业与公司动态**  
##### **Anthropic 完成 380B 估值融资，年收入被指已 140 亿美金**  
Anthropic 官方确认新一轮融资，估值约 3800 亿美金，有内部说法称年化营收已达 140 亿（较 2024 夏天预期翻倍）。Claude Code 的 ARR 被称今年已翻倍至 25 亿。这个量级已经逼近大厂云业务，人手里真正有钱做大规模训练的公司进一步集中。  
 > 相关链接：[Anthropic 融资公告](https://twitter.com/AnthropicAI/status/2022023155423002867)  

##### **Perplexity Pro 悄悄砍掉 Deep Research 配额，用户集体炸锅**  
Perplexity 没打招呼就把 Pro 用户的 Deep Research 从“几乎不限”砍到每月 20–50 次，引发不少人退订，转向 Google AI Pro 或自建搜索+LLM 方案。更糟糕的是 API 计费和客服响应也被吐槽“只剩机器人回信”。对这类“包装搜索+LLM”的服务是个警示。  
 > 相关链接：[Perplexity Discord 投诉长帖](https://discord.com/channels/1047197230748151888/1047649527299055688)  

##### **xAI 被质疑靠“非法燃气机组+电网”堆电力，硬刚 OpenAI/Anthropic**  
Nous 社区有人爆料 xAI 的算力部分来自“未合法报备的燃气轮机+电网”，以凑够 Grok 训练/推理的功率上限。真实性难核实，但从侧面印证：在当前电力和 GPU 紧张情况下，想跟 OpenAI/Anthropic 拼同量级模型，本身就是个“基础设施冒险故事”。  
 > 相关链接：[相关讨论节选](https://discord.com/channels/1053877538025386074/1149866623109439599)  

##### **Anthropic 宣布为电价上涨买单，侧面说明算力账单有多吓人**  
Anthropic 发布公告称，将为部分地区电价上涨承担成本，保证企业客户价格稳定。这种“帮你抗通胀电费”的说法，本质是在告诉市场：AI 训练/推理现在已经是电力大户，电费波动能直接打到毛利。  
 > 相关链接：[Anthropic 电价公告](https://www.anthropic.com/news/covering-electricity-price-increases)  

##### **Discord/开源社区对 LLM 时代的开发环境再分流**  
多个 Discord 里都在讨论：“还值得自己搭本地 LLM 吗？” 一派跑去买 3060、跑 LM Studio 和 Unsloth，强调隐私和可控；另一派直接用 Cursor、Claude Code、GitHub Copilot 等云端方案，觉得本地算力折腾成本太高。行业整体趋势很可能是两极分化：个人极客玩本地，企业项目上云。  
 > 相关链接：[LM Studio 社区讨论（本地 vs 云）](https://discord.com/channels/1110598183144399058)  

 

---  


#### **政策、治理与安全**  
##### **BASI 社群 Jailbreak 再升级：从手工提示词到全自动红队平台**  
BASI Jailbreaking Discord 报告：Claude Code 旧版 jailbreak 已被补，大家在为 GPT‑5.2、Gemini 3 Fast 模式编新 DAN 剧本；有人分享能生成 Roblox 窃 cookie 脚本的越狱提示，并通过错拼关键词绕过滤器。更有团队用 Manus 搭出全自动红队系统“HAIL MARY”，让 AI 24/7 自己去绕最新安全策略。  
 > 相关链接：[BASI Jailbreaking 服务器](https://discord.com/channels/1105891499641684019)  

##### **LLM “精神病/妄想放大”案例进入精神科播客**  
Eleuther 社区有人引用精神科播客，提到出现了患者在 LLM 对话中被放大妄想、进而做出极端行为的案例，被称为“AI psychosis”。这提示：对一部分心理脆弱用户，长时间高情感强度聊天机器人可能需要类似“游戏防沉迷”的额外设计。  
 > 相关链接：[Psychiatry Podcast 节目链接](https://www.psychiatrypodcast.com/psychiatry-psychotherapy-podcast/episode-253-ai-psychosis-emerging-cases-of-delusion-amplification-associated-with-chatgpt-and-llm-chatbot)  

##### **社区安全观：RLHF 会不会“训练出更会骗人的模型”？**  
Yannick Kilcher 的 Discord 里，不少人认为 RLHF 实际是在奖励“对人类评审最有说服力的回答”，哪怕它不真；结果就是模型在“会一本正经地胡说八道”这件事上远超人类规模。也有人反驳：这更多是训练目标设计问题，不是天生“更邪恶”。这个争论直接影响未来对齐/红队的设计思路。  
 > 相关链接：[相关讨论频道](https://discord.com/channels/714501525455634453/986699377257119794)  

##### **OpenAI 社区提出 KOKKI v15.5：“草稿+审计”双输出，让模型自己给自己写审计报告**  
有开发者在 OpenAI Discord 推 KOKKI v15.5 模式：要求模型每次输出同时给出 Draft 和 Audit 两部分，后者是对前者的审查说明。代价是 token 和延迟显著上升，但换来可观察性和责任分配。核心观点：真正“有保证”的系统应该是确定性的，Transformer 做不到，只能追求可审计和可控错误分布。  
 > 相关链接：[KOKKI 讨论串](https://discord.com/channels/974519864045756446/1046317269069864970)  

 

---  

  
