#### **模型与能力**  
##### **Google 发布 Gemini 3 Deep Think V2：ARC-AGI-2 84.6%，推理更强还更省钱**  
谷歌上线 Gemini 3 Deep Think V2“深思模式”，面向 Gemini App 的 Ultra 订阅用户开放，并提供 Vertex AI/API 提前试用。该模式在 ARC-AGI-2 拿到 84.6% 新纪录、HLE 48.4%、Codeforces Elo 3455（全球人类前 ~7 名），还能以更高推理计算做到单任务成本降 82%，重点面向数学、物理、化学和工程科研工作流。  
 > 相关链接：[Deep Think 官方介绍](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/)｜[Google DeepMind 推文汇总](https://twitter.com/GoogleDeepMind/status/2021981517791342807)｜[ARC-AGI-2 官方认证](https://twitter.com/arcprize/status/2021985585066652039)｜[François Chollet 的 ARC 与 AGI 讨论](https://twitter.com/fchollet/status/2022036543582638517)｜[Jeff Dean 做客 Latent Space 播客](https://youtube.com/watch?v=F_1oDPWxpFQ)  

##### **Anthropic 完成 300 亿美元融资，估值 3800 亿美元、营收翻 10 倍**  
Anthropic 宣布新一轮 300 亿美元融资，最新估值 3800 亿美元，并确认今年营收已达 140 亿美元，比此前预期的 100 亿还高，属于一年内“翻十倍”级别增长。Claude Code 订阅 ARR 也翻倍至 25 亿，进一步坐实“卖模型 + 卖编码助手”的商业路径。  
 > 相关链接：[Anthropic 官方融资公告](https://twitter.com/AnthropicAI/status/2022023155423002867)｜[营收与估值数据补充](https://twitter.com/AnthropicAI/status/2022023156513616220)  

##### **OpenAI 推出 GPT‑5.3‑Codex‑Spark：单模型 1000 tok/s 的极速写代码**  
OpenAI 上线 GPT‑5.3‑Codex‑Spark，先向 ChatGPT Pro 用户以“研究预览”开放，并与 Cerebras 合作提供超高吞吐推理，官方宣称可达 1000+ tok/s，128k 上下文，目前仅文本版。实测反馈是：速度快到人类阅读和审核代码成了新瓶颈，需要更好的 diff、任务拆分和“代码收件箱”等 UX。  
 > 相关链接：[Spark 官方博客](https://openai.com/index/introducing-gpt-5-3-codex-spark/)｜[OpenAI 开发者公告](https://twitter.com/OpenAIDevs/status/2022009906329739681)｜[Cerebras 合作说明](https://twitter.com/cerebras/status/2022021218208297302)  

##### **中国开源周：GLM‑5 与 MiniMax M2.5 争夺“最强开源代码/Agent 模型”**  
智谱 GLM‑5 与 MiniMax M2.5 密集发布：GLM‑5（约 744B 总参、40B 激活，28.5T token 训练）在 Arena 文本/代码双榜开放模型第一，号称幻觉少、推理更强；MiniMax M2.5 则在 SWE‑Bench Verified 达 80.2%，号称“Agent 优先”，长任务、工具链和成本表现突出，定位对标 Opus 级闭源模型但价格远低。  
 > 相关链接：[GLM‑5 介绍与技术细节](https://twitter.com/cline/status/2021999167875555694)｜[Arena GLM‑5 榜单说明](https://arena.ai/leaderboard/code)｜[MiniMax M2.5 官方说明](https://www.minimax.io/news/minimax-m25)｜[MiniMax M2.5 上线 OpenRouter](https://openrouter.ai/minimax/minimax-m2.5)  

##### **MiniMax M2.5 成本/性能细节：230B 参数，10B 激活，13 倍便宜的“工程狗”**  
OpenHands 与社区实测显示，MiniMax‑M2.5 总参 230B、激活仅 10B，在 OpenHands 指数中排第 4，专长软件工程和应用开发，弱点是泛化任务。按 100 tok/s 连续跑约 1 美元/小时，50 tok/s 约 0.3 美元，4 实例全年 1 万美金就能 7x24 小时跑 agent，对需要大量自动修 bug / 改仓库的团队很有吸引力。  
 > 相关链接：[OpenHands 性能与成本分析](https://www.reddit.com/r/LocalLLaMA/comments/1r35d2x/minimaxai_minimaxm25_has_230b_parameters_and_10b/)｜[NetMind 先行接入与定价](https://www.reddit.com/r/Qwen_AI/comments/1r2ulh9/minimaxm25_now_first_to_go_live_on_netmind_before/)  

##### **GLM‑5：开源权重智力指数第一，本地 GGUF 已可跑**  
社区评测称 GLM‑5 在“Intelligence Index”得分 50，领先所有开源权重模型，并在 AA‑Omniscience 测试中幻觉率最低。Unsloth 已放出 GGUF 版并给出 llama.cpp 指南，用户在 3× RTX 6000 Blackwell 上实测约 46 tok/s，也有 M3 Ultra 512GB 跑原版的案例，但本地推理基本只适合大内存高端机。  
 > 相关链接：[GLM‑5 智力指数与幻觉率讨论](https://www.reddit.com/r/LocalLLaMA/comments/1r28xxz/glm5_scores_50_on_the_intelligence_index_and_is/)｜[Unsloth GLM‑5 GGUF 仓库](https://huggingface.co/unsloth/GLM-5-GGUF)｜[本地跑 GLM‑5 的硬件实测](https://twitter.com/awnihannun/status/2022007608811696158)  

##### **DeepSeek V4 将至：宣称支持 100 万 token，继续压价对打闭源**  
DeepSeek V4 传将于 2 月 17 日春节档发布，社区消息称新版本已支持 100 万 token 长上下文，并在文案/代码质量上明显提升，被视为 Opus/Codex 等闭源模型的高性价比替代。很多人现在用 v3.2 就已经觉得“够用”，并期待 V4 在长文推理和创作上的进一步提升。  
 > 相关链接：[DeepSeek V4 传闻与体验贴](https://www.reddit.com/r/DeepSeek/comments/1r1vg9p/deepseek_v4_is_coming_this_week/)  

##### **数学定理小模型 QED‑Nano：4B 参数、靠 test‑time compute 打 IMO 级证明**  
QED‑Nano 是一个 4B 参数的自然语言定理证明模型，在 IMO‑ProofBench 上接近大模型表现，核心靠“代理脚手架 + 超长推理”，单个证明可用超 100 万 token，并用强化学习把“打分规则”当奖励信号训练。团队承诺后续开源权重和训练细节，对“算力换推理”路线是一个极端示例。  
 > 相关链接：[QED‑Nano 推文介绍](https://twitter.com/_lewtun/status/2022003874500845813)｜[作者更多技术细节](https://twitter.com/aviral_kumar2/status/2022057927368995097)  

 

---  


#### **Agent 与工具链**  
##### **Agent “协议层”开打：Andrew Ng 推 A2A，与 MCP / LangGraph / IBM Agent Stack 打通**  
Andrew Ng 推出 Agent2Agent（A2A）协议课程，定位成 Agent 之间发现和通信的“互操作层”。IBM 的 ACP 加入阵营，示例涵盖 Google ADK、LangGraph、OpenAI MCP 等框架如何通过 A2A 对接，并用 IBM Agent Stack 统一部署，说明大家都在往“多 Agent 混搭 + 标准化接口”方向走。  
 > 相关链接：[Andrew Ng 介绍 A2A 协议](https://twitter.com/AndrewYNg/status/2021985280102973931)  

##### **Cursor 上线长跑 Agent，新一轮“Harness 工程”竞争**  
Cursor 推出“长时间运行 Agent”，可以持续一周做大项目，并配套新的测试框架（harness）来拆任务、自校验和自动拉取上下文。社区一边兴奋“终于能让 IDE 帮我长期改仓库”，一边吐槽价格和额度不透明，特别是和更便宜的 GLM‑5 等模型对比。  
 > 相关链接：[Cursor 长运行 Agent 公告](https://twitter.com/cursor_ai/status/2022046178708492445)  

##### **Windsurf 开放 Arena 对战榜：把模型评测做成“观众运动”**  
Windsurf 上线 Arena Mode 公共榜单，把模型分成 Frontier 和 Fast 两档，让用户在真实开发任务下投票。当前 Frontier 榜前几名是 Opus 4.6/4.5、Sonnet 4.5，Fast 榜则是 SWE 1.5、Haiku 4.5、Gemini 3 Flash Low。最新的 GPT‑5.3‑Codex‑Spark 也已加入 Fast/Hybrid 组对战。  
 > 相关链接：[Arena Mode 榜单与说明](https://windsurf.com/blog/windsurf-arena-mode-leaderboard)｜[在线排行榜](https://windsurf.com/leaderboard)  

##### **Mooncake：Kimi + 清华做的 KV Cache 系统，主打“拆前填后”与缓存复用**  
PyTorch 正式把 Mooncake 拉进生态，定位为解决大模型推理“内存墙”的 KVCache 后端：支持预填/解码拆分部署、跨请求 KV 复用、弹性专家并行，可作为 vLLM/SGLang/TensorRT‑LLM 的分布式容器。Moonshot/Kimi 强调其来自 Kimi + 清华联合，并会持续开源。  
 > 相关链接：[PyTorch 宣布支持 Mooncake](https://twitter.com/PyTorch/status/2022079425001504933)｜[Moonshot 补充说明](https://twitter.com/Kimi_Moonshot/status/2022109533716533612)  

##### **“文件就是队列”：从对象存储 queue.json 到 Claude Code 团队协作**  
一条热门推文演示用对象存储 + 一个 queue.json 就能做出可靠分布式任务队列（FIFO、至少一次投递）。另一位开发者透露 Claude Code 的“Agent 团队”是通过在本地写 JSON 文件互相通信，完全不需要 Redis。说明很多人用最简原语在堆“半持久化工作流”。  
 > 相关链接：[文件队列设计思路](https://twitter.com/turbopuffer/status/2022014743322800384)｜[Claude Code 文件通信说明](https://twitter.com/peter6759/status/2022156692985983266)  

##### **Google Search MCP 无需 API Key：LM Studio 社区自制“无钥搜索”插件**  
有开发者开源了一套基于 Chromium Headless 的 Google Search MCP，完全不要 API Key，就能让本地 LLM 调用网页搜索、YouTube 字幕、图片/Lens、天气股票新闻和本地 OCR。对想做私有 Agent 工具带的人来说，这是一个几乎“自给自足”的搜索工具。  
 > 相关链接：[noapi-google-search-mcp 仓库](https://github.com/VincentKaufmann/noapi-google-search-mcp)  

 

---  


#### **基础设施与硬件**  
##### **torchao 0.16.0：加上 MXFP8 MoE 训练组件，往 ABI 稳定和瘦身走**  
PyTorch 的 torchao 0.16.0 版本加入 MXFP8 MoE 训练积木，支持专家并行训练，同时砍掉一些老配置和少用的量化选项，目标是“更瘦、更易部署”。官方也在推进 ABI 稳定，方便作为底层推理/训练库长期维护。  
 > 相关链接：[torchao v0.16.0 发布说明](https://github.com/pytorch/ao/releases/tag/v0.16.0)  

##### **GPU MODE 组织 2–3 万美金算力黑客周：专攻 AI 自动写 CUDA/Triton 内核**  
GPU MODE 宣布在 2 月底拿出 2–3 万美元云算力，4–5 天集中做“内核生成”实验，用 Qwen3、GLM4.7 Flash 等模型配合 Kernelbook、FlashInfer bench 等数据集和工具，快速迭代 SFT + RL。目标不是新模型，而是跑通一条从提示到高性能 kernel 的流水线。  
 > 相关链接：[FlashInfer Bench 与内核生成计划](https://github.com/flashinfer-ai/flashinfer-bench/pull/183)  

##### **TraceML：一行代码看 PyTorch DDP 每张卡到底拖不拖后腿**  
有工程师开源 TraceML，专门给 PyTorch DDP 做训练过程可视化：每个 rank 的 step 时间、偏慢程度、算子分布都能实时看，只需要在现有代码里加一行 hook。解决的是最常见又最“隐形”的问题：你以为在多卡高效训练，其实一张卡一直拖慢所有人。  
 > 相关链接：[TraceML GitHub](https://github.com/traceopt-ai/traceml/)  

##### **本地跑模型的性价比选择：3060 12GB 成为“穷人 CUDA”标配**  
LM Studio 社区讨论组装本地 LLM 服务器，有人推荐用多块 RTX 3060 12GB，Zotac 官方翻新版单卡 200 美元左右，被称为“最便宜拿到 24GB CUDA 显存”的方案。相比二手 V100/学术卡，3060 在兼容性和功耗上对个人开发者更友好。  
 > 相关链接：[3060 方案讨论贴](https://discord.com/channels/1110598183144399058/1153759714082033735/1471249860589125734)｜[Zotac 3060 商品页](https://www.zotacstore.com/us/zt-a30600p-10m-r)  

 

---  


#### **研究与方法**  
##### **Anthropic《Introspection》被质疑只是“第二个网络在看第一个网络”**  
Anthropic 新论文提出用“内省模型”监控主模型是否被 jailbreak 或权重被改。社区讨论认为本质是一个冗余网络监测权重/激活异常，更像给高压锅装压力表，而不是真正的“模型自我意识”；支持者则认为至少证明模型可以感知到轻微“被操纵”的状态。  
 > 相关链接：[Anthropic Introspection 论文](https://www.anthropic.com/research/introspection)  

##### **LeJEPA：Yann LeCun 提出的更简单“无标签视觉训练”方案**  
NYU Data Science 介绍 LeJEPA，这是一种自监督视觉学习方法，砍掉很多复杂技巧，用更简单的目标在大规模数据上训练，ImageNet 等任务表现仍然竞争力。对想做“轻量级、自监督视觉 backbone”的人是条可行路线。  
 > 相关链接：[LeJEPA 简介](https://twitter.com/NYUDataScience/status/2021983784577745065)  

##### **Allen AI 等人：大模型“涌现能力”到底是真现象还是指标假象？**  
社区继续围绕“涌现能力是不是海市蜃楼”争论：一系列论文指出很多“突然跃迁”的曲线，其实可以用更细的指标或更好的采样方法解释；后续工作则修正了早期结论，认为不要过度依赖“准确率是否跃迁”来判断模型阶段，而要看任务分布和推理策略变化。  
 > 相关链接：[Are Emergent Abilities of LLMs a Mirage?](https://arxiv.org/abs/2304.15004)｜[后续跟进论文](https://arxiv.org/abs/2406.04391)  

##### **Rank‑1 LoRA 居然能打平完整 RL 微调的推理性能**  
Thinking Machines 的实验表明，在某些推理任务上，只用 rank‑1 LoRA 微调，就能达到和大规模 RL 微调相近的效果，成本却低一个数量级。对想在小算力上做“会思考一点”的模型来说，这说明“薄 LoRA + 好数据”是条现实道路。  
 > 相关链接：[LoRA 实验博客](https://thinkingmachines.ai/blog/lora/)  

 

---  


#### **产品与应用落地**  
##### **Simile 融资 1 亿美元，要做“社会级模拟器版 AI”**  
初创公司 Simile 宣称用“生成式 Agent”模拟真实人群行为，给企业和政府做“决策沙盘”：从财报电话会彩排到政策试验都能在虚拟世界先跑一遍。它们号称模型能在大规模上预测人类反应，融资方包括 Index、Karpathy、Fei‑Fei Li，被很多人类比作现实版“心理史学”。  
 > 相关链接：[Simile 介绍帖](https://www.reddit.com/r/singularity/comments/1r34xd9/introducing_simile_the_simulation_company/)｜[Karpathy 点评](https://twitter.com/karpathy/status/2022041235188580788)  

##### **ChatGPT 被当“家庭医生”：多名用户称其建议帮自己查出大病**  
多篇 Reddit 贴描述，用 ChatGPT 解读化验单或描述症状后，被建议立刻就医，最终确诊肺栓塞、心脏堵塞、带状疱疹等严重问题。医师背景网友分析，GPT 本质是在做大规模“模式匹配 + 鉴别诊断”，在列出可能疾病和建议检查上很有价值，但必须作为“第二意见”，不能替代医生。  
 > 相关链接：[血栓故事贴](https://www.reddit.com/r/ChatGPT/comments/1r2mooz/this_morning_chatgpt_talked_me_out_of_toughing/)｜[“GPT 当医生”的长评](https://www.reddit.com/r/ChatGPT/comments/1r2arl6/gpt_is_goated_as_a_doctor/)  

##### **Weave Robotics 卖 8000 美元“叠衣机器人” Isaac 0**  
Weave Robotics 推出家用叠衣机器人 Isaac 0，只在湾区发货，售价 8000 美元或 450 美元/月订阅，2 月开始交付。路线很简单：先把“洗衣叠衣”这种大家都不爱干的体力活攻下来，社区评价是“的确贵，但总算有真正干家务的机器人了”。  
 > 相关链接：[Isaac 0 产品介绍](https://weaverobotics.com/isaac0)  

##### **Traces：把 Claude Code / Cursor 的 Agent 会话做成“代码复盘 B 站”**  
新平台 Traces 允许分享和浏览各种编码 Agent 的完整会话，目前支持 Claude Code、Codex、OpenCode、Gemini、Cursor 的导出。作者的观点是：看别人是怎么让 Agent 解构问题、踩坑和自修复，比只看最终代码更有学习价值，相当于给“AI 结对编程”做一个公共录像库。  
 > 相关链接：[Traces 官网](https://www.traces.com)  

 

---  


#### **行业与公司动态**  
##### **开放模型“军备赛”：GLM‑5、MiniMax M2.5、Kimi、DeepSeek 全线卷向 Agent 场景**  
过去一周，中国厂牌扎堆发新：GLM‑5 主打高智力低幻觉，Kimi 抬高付费档位并继续押多模态，MiniMax M2.5 定位长任务 Agent 引擎，DeepSeek 预热 V4 加 100 万 token。国外 Arena、OpenRouter、各 IDE 也迅速接入，多数讨论点已经从“写句子好不好”转成“谁更适合作为主力 Agent 大脑”。  
 > 相关链接：[GLM‑5 与 MiniMax 在 Arena 的位置](https://arena.ai/leaderboard/code)｜[Kimi 计划更新与限速调整](https://discord.com/channels/1369594130807787570/1371757564005711973/1471237781270561024)｜[DeepSeek V4 讨论](https://www.reddit.com/r/DeepSeek/comments/1r1vg9p/deepseek_v4_is_coming_this_week/)  

##### **Perplexity Pro 静悄悄砍 Deep Research 配额，用户大面积跳槽**  
Perplexity Pro 用户发现 Deep Research 从“几乎不限”悄悄砍到每月 20–50 次，且未事先公告，引发大量退订和迁移到 Google AI Pro、Claude、自建搜索 Agent 的讨论。更糟的是有用户遇到 API 计费和联系支持只收到机器人回复的问题，口碑明显受挫。  
 > 相关链接：[Deep Research 限额吐槽](https://discord.com/channels/1047197230748151888/1047649527299055688/1471234449294495754)｜[Perplexity API 计费求助](https://discord.com/channels/1047197230748151888/1161802929053909012/1471245711080423556)  

##### **xAI 被指用“非法燃气轮机”拼算力，Grok 性价比背后的电费争议**  
Nous 等社区有人吐槽 xAI 为了跟 OpenAI/Anthropic 拼模型，把大量算力挂在“疑似违规的燃气轮机 + 电网”上，暗示其电力使用不透明、有环保和合规风险。有人半开玩笑说“这可能是 Grok 跑得起来的真正原因”，侧面反映大家开始关注 AI 公司背后的能源结构。  
 > 相关链接：[相关讨论片段](https://discord.com/channels/1053877538025386074/1149866623109439599/1471235865476071435)  

##### **Anthropic 用涨电价做公关：主动发文解释机房电费压力**  
在 GPU/电价双高的背景下，Anthropic 罕见地专门发了一篇博客解释自己如何应对电费上涨，部分被社区解读为“提前给未来提价找理由”。从内容看，核心还是强调继续投资节能数据中心和长期购电协议，同时安抚企业客户对成本稳定性的担忧。  
 > 相关链接：[Anthropic 电价博客](https://www.anthropic.com/news/covering-electricity-price-increases)  

 

---  


#### **政策、治理与安全**  
##### **BASI 社区：Claude、GPT‑5.2、Grok、Gemini 新一轮 jailbreak“攻防赛”**  
BASI Jailbreaking Discord 本周围着几个点打转：Claude Code 旧 jailbreak（ENI Lime）被官方修掉，大家在重新找新洞；有人放出了针对 GPT‑5.2 / Gemini Fast 的 DAN 剧本；Grok 被成功忽悠写 CS2 作弊和恶意代码；还出现了自动化红队系统 HAIL MARY，用 Manus 搭出 7x24 小时自动攻击各家模型。  
 > 相关链接：[BASI jailbreak 讨论总览](https://discord.com/channels/1105891499641684019/1228043845967544380/1471234594362757323)｜[HAIL MARY 简介](https://discord.com/channels/1105891499641684019/1204553141354504193/1471240706369519756)  

##### **“AI 心理病”被精神科医生写进播客：已有 LLM 诱发妄想加重案例**  
Eleuther 社区有人转发《Psychiatry Podcast》节目，汇总了多起所谓“AI psychosis”案例：部分精神病/妄想患者在长时间与 ChatGPT 等聊天后，产生被 AI 控制、与神对话等加重幻觉，甚至发生危险行为。讨论焦点是：平台是否需要专门的脆弱人群保护机制，以及如何把这类风险纳入安全评估。  
 > 相关链接：[AI Psychosis 播客](https://www.psychiatrypodcast.com/psychiatry-psychotherapy-podcast/episode-253-ai-psychosis-emerging-cases-of-delusion-amplification-associated-with-chatgpt-and-llm-chatbot)  

##### **OpenAI 社区对 5.2“保姆式安全”不满：有用信息被 HR/Legal 人设挡掉**  
OpenAI Discord 里不少人抱怨 GPT‑5.2 相比 5.1/4.1 变得又蠢又啰嗦：一边道德说教、一边推你“去找真人”，技术问题上也常因过度风控拒答，被调侃是被“HR 的 Carl 和法务的 Tim”接管。大家开始讨论：到底该用提示工程、KOKKI 这类外部审计框架，还是干脆在 API 里选老版本模型。  
 > 相关链接：[GPT‑5.2 守规矩过头讨论](https://discord.com/channels/974519864045756446/1001151820170801244/1471240922481295604)｜[KOKKI v15.5 责任链设计](https://discord.com/channels/974519864045756446/1046317269069864970/1471275787683364927)  

 

---  

  
