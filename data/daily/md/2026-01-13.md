#### **行业与公司动态**  
##### **Apple 选择 Google Gemini 驱动下一代 Siri**  
苹果宣布下一代 Siri 和 Apple Foundation Models 将基于 Google 的 Gemini 模型和云技术，结合本地与 Private Cloud Compute，继续强调隐私。此前苹果也评估过 ChatGPT 和 xAI Grok。此举被视为 Google 的大胜、OpenAI 的失利，同时引发对 Google+Apple 在 AI 领域竞争与反垄断的讨论。  
 > 相关链接：[苹果与 Google Gemini 合作报道](https://www.wcnc.com/article/news/nation-world/apple-google-gemini-siri-ai-features/507-575faa99-217e-498d-8f34-5455759113f8)｜[Google 官方声明推文](https://twitter.com/NewsFromGoogle/status/2010760810751017017)｜[Reddit 讨论：苹果选用 Gemini](https://www.reddit.com/r/OpenAI/comments/1qb7dg6/apple_announces_that_next_version_of_siri_would/)｜[Reddit 讨论：It’s official](https://www.reddit.com/r/OpenAI/comments/1qb79py/its_official/)｜[Reddit：Apple-Google “Mega-Brain” 讨论](https://www.reddit.com/r/GeminiAI/comments/1qb1t6h/the_applegoogle_megabrain_is_here_why_siri_gemini/)｜[MacRumors 解读 Apple Intelligence 与 Gemini](https://www.macrumors.com/2026/01/12/google-gemini-future-apple-intelligence-features/)  

##### **OpenAI 收购 Torch，全面押注医疗健康业务**  
OpenAI 推出 ChatGPT Health，采用独立记忆空间，并收购医疗初创公司 Torch，将化验结果、药物、就诊录音等结构化整合到 ChatGPT Health 中。Torch 团队整体加入 OpenAI，目标是做真正懂临床流程的健康助手，OpenAI 也在推进 HIPAA 合规的医疗版 ChatGPT 和 API。  
 > 相关链接：[OpenAI ChatGPT Health 发布](https://twitter.com/OpenAI/status/2010764845432590469)｜[OpenAI 收购 Torch 公告](https://twitter.com/OpenAI/status/2010813780671021106)｜[Torch 官网](https://torchbio.com/)｜[Torch 创始人说明](https://twitter.com/IlyaAbyzov/status/2010813621022949721)｜[ChatGPT Health 概览与数据规模](https://twitter.com/thekaransinghal/status/2010878203401843114)  

##### **Anthropic 推出 Cowork：把 Claude Code 扩展到所有办公工作**  
Anthropic 上线 Cowork，允许 Claude 读写本地指定文件夹、配合 Chrome 访问网页，自动整理文件夹、做表格、整理笔记写报告等，相当于“非程序员版 Claude Code”。目前是 macOS 上 Claude Max 用户的研究预览，社区关注其安全模型、日志与企业部署成本。  
 > 相关链接：[Cowork 官方博客](https://claude.com/blog/cowork-research-preview)｜[Cowork 官宣推文](https://twitter.com/claudeai/status/2010805682434666759)｜[Reddit：Cowork 功能讨论](https://www.reddit.com/r/ClaudeAI/comments/1qb5r3y/introducing_cowork_claude_code_for_the_rest_of/)  

##### **Phind 宣布关停，开发者寻找替代品**  
面向程序员的搜索与代码助手 Phind 宣布本周末关停，社区开始讨论用 Perplexity、OpenAI + 浏览工具、自建 RAG 等替代，许多人也在反思对单一 AI 工具的依赖与“厂商锁定”风险。  
 > 相关链接：[Phind 关停 Discord 公告](https://discord.com/channels/996538859972214835/1077743365749227630/1460382964029460584)  

##### **中国大模型商业化：智谱 vs MiniMax IPO 故事差异**  
一份总结认为智谱和 MiniMax IPO 表现分化的关键在叙事：智谱更像 ToB/ToG 基础设施，销售周期长、研发投入重；MiniMax 更偏 C 端和全球化平台，增长曲线和毛利改善故事更好讲，资本市场更买单。  
 > 相关链接：[ZhihuFrontier 线程](https://twitter.com/ZhihuFrontier/status/2010642118713512174)  

##### **Meta 招募 Daniel Gross 牵头新一轮 AI 基础设施计划**  
报道显示 Daniel Gross 牵头 Meta 新 AI 基础设施项目，与高管 Dina Powell McCormick 和 Santosh Janardhan 合作，被视为 Meta 在训练/部署大模型基础设施上的新一轮加码。  
 > 相关链接：[相关报道](https://x.com/MeghanBobrowsky/status/2010778788964286832)  

 

---  


#### **模型与能力**  
##### **DeepSeek 发布 Engram：面向静态知识的条件记忆模块**  
DeepSeek 的 Engram 在 Transformer 中引入哈希 n-gram 查表式“条件记忆”，把一部分“死记硬背”从算力昂贵的前向传播迁移到 O(1) 查询，释放主干模型做推理。可将大块嵌入表放在主存/NVMe 上，推理开销小，论文称这是下一代稀疏模型的重要组件。  
 > 相关链接：[Twitter 技术长线程](https://twitter.com/scaling01/status/2010748516788777445)｜[Twitter 讨论与批评](https://twitter.com/tokenbender/status/2010791813964296558)｜[GitHub：deepseek-ai/Engram](https://github.com/deepseek-ai/Engram/tree/main)｜[Engram 论文 PDF](https://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf)  

##### **Gemini 长上下文实测：官方 400k，社区称 120k 开始“掉链子”**  
多名工程师在 Discord 和 Twitter 上反馈，Gemini 在 ~120k token 之后针尖寻针类测试明显退化，而 Claude Haiku/Sonnet 表现更稳。也有人称 400k+ 任务正常，说明与任务类型和提示工程高度相关。社区共识是：长上下文能力不能只看营销数字，必须自己压测。  
 > 相关链接：[Gemini 3 Pro 讨论与 bug 反馈](https://plx.link/GeminiGlitches)  

##### **GLM‑4.7 多渠道上线，主打长上下文和代码能力**  
GLM‑4.7 已可在 Cerebras（Hugging Face）和 Together AI 上使用，宣传点包括 20 万上下文和较强代码能力。属于国产大模型在海外推理平台上的又一次集中分发。  
 > 相关链接：[GLM‑4.7 Hugging Face 集成](https://twitter.com/NielsRogge/status/2010686205961146400)｜[Together AI 推理服务](https://twitter.com/togethercompute/status/2010832877626286113)  

##### **开源模型热度量化：提出 RAM Score 指标**  
有研究者提出 RAM Score（Relative Adoption Metric），按时间和模型规模归一化 Hugging Face 下载量。结果显示 1–9B 参数模型下载量最多，但头部大模型之间中位下载量差距只有约 4 倍，GPT‑OSS 异常受欢迎，中国一些大 MoE 模型动能偏弱。  
 > 相关链接：[RAM Score 分析线程](https://twitter.com/natolambert/status/2010744476516655274)  

##### **Gemini API 大幅放宽输入文件限制**  
Gemini API 将单文件上限从 20MB 提到 100MB，并支持直接从 Google Cloud Storage 导入或使用签名 URL（可来自其他云）。部分场景可用到 2GB 注册文件。文档列出支持的文档格式，方便做高容量 RAG 与文档问答。  
 > 相关链接：[API 更新说明 1](https://twitter.com/osanseviero/status/2010764447988461634)｜[API 更新说明 2](https://twitter.com/_philschmid/status/2010765230134215037)  

 

---  


#### **研究与方法**  
##### **DroPE 与测试时训练：长上下文和“记忆”的新思路**  
Sakana 提出 DroPE：训练时用 RoPE 收敛，推理时去掉位置编码以减小长上下文扭曲；并给出参考训练代码。NVIDIA/Stanford/Astera 的 TTT‑E2E 则在推理阶段继续对当前上下文做增量训练，相当于把关键信息“写进权重”，减小 KV cache 压力。  
 > 相关链接：[DroPE 论文推文](https://twitter.com/SakanaAILabs/status/2010660969719165133)｜[DroPE 代码仓库](https://twitter.com/SakanaAILabs/status/2010738878727217595)｜[TTT‑E2E 介绍](https://twitter.com/NVIDIAAIDev/status/2010773774849724858)  

##### **Agent 记忆方案对比：AgeMem 与 SimpleMem**  
AgeMem 把长短期记忆统一成一组“工具动作”（增删改、检索、摘要等），用分阶段强化学习训练，在 Qwen 系列上相比 Mem0 提升可达 13%。SimpleMem 则主打“语义无损压缩+合并+按需检索”，在 LoCoMo 上 F1 从 34.2 提到 43.24，同时把平均查询 token 从 1.69 万降到 531。  
 > 相关链接：[AgeMem 线程](https://twitter.com/omarsar0/status/2010712137933730234)｜[SimpleMem 线程](https://twitter.com/dair_ai/status/2010720188686348593)  

##### **人类分割专用模型 FASHN Human Parser 开源**  
团队发布面向时尚电商的人体解析模型 FASHN Human Parser，基于 SegFormer‑B4 微调，输出 18 类人体+服饰掩码，支持 384×576 输入，GPU 推理约 300ms、CPU 2–3s，主要解决 ATR/LIP/iMaterialist 数据集质量差的问题。  
 > 相关链接：[模型 PyPI 包](https://pypi.org/project/fashn-human-parser/)｜[Hugging Face 模型](https://huggingface.co/fashn-ai/fashn-human-parser)｜[数据集问题分析博客](https://fashn.ai/blog/fashion-segmentation-datasets-and-their-common-problems)  

##### **用博弈论反馈稳定 LLM Agent：成功率翻倍**  
新论文提出将 agent 交互日志转为图，在其上构造零和攻防博弈，求解纳什均衡后把统计结果写入系统提示词作为控制信号。实验证明，某 44 次基准测试成功率从 20% 提到 42.9%，工具使用方差缩小 5.2 倍，平均完成时间缩短 2.7 倍。  
 > 相关链接：[论文 PDF](https://arxiv.org/pdf/2601.05887)｜[GitHub 代码](https://github.com/aliasrobotics/cai)  

##### **LLM 作为评审：不同模型打分高度不一致**  
《Evaluative Fingerprints》研究发现，同一个 LLM 自己前后评分很稳定，但不同 LLM 之间几乎没有一致性（Krippendorff’s α≈0.042）。根据打分模式和引用证据可以 89.9% 准确识别是哪一个“评审模型”。结论是：用 LLM 做自动评测时，模型选择本身会引入系统性偏差。  
 > 相关链接：[论文 PDF](https://arxiv.org/pdf/2601.05114)  

##### **CURE‑GRPO：自我批评 + 强化学习提升推理能力**  
在 Google Tunix Hackathon 中，一份 CURE‑GRPO 方法总结展示了如何结合 Self‑Critique 和 GRPO 提升 Gemma 等模型的推理表现。社区关注其作为通用“推理微调 recipe”的可复用性和与现有 RLAIF 的对比。  
 > 相关链接：[Kaggle 比赛 writeup](https://www.kaggle.com/competitions/google-tunix-hackathon/writeups/new-writeup-1766255740138)  

 

---  


#### **Agent 与工具链**  
##### **Ramp 开源内部“写代码 Agent”方案，一周写了 30% PR**  
金融 SaaS 公司 Ramp 披露其内部编码代理 Inspect：在云端运行，结合开源工具、Modal 和 Cloudflare，据称一周内产出约 30% 合并的前后端 PR。公司同时开源了搭建蓝图，方便他人复刻类似系统。  
 > 相关链接：[Inspect 介绍推文](https://twitter.com/zachbruggeman/status/2010728444771074493)｜[详细构建说明](https://twitter.com/rahulgs/status/2010734253538267197)  

##### **AI21 大规模跑 SWE‑bench 的经验：评测首先是个基础设施问题**  
AI21 表示他们在生产环境跑了 20 万+ 次 SWE‑bench，最大教训是要把“生成”和“评测环境”解耦：每个 issue 复用构建好的仓库+依赖+MCP 服务，单测失败时可以直接重跑，不必重新生成。这样把失败率从 30% 降到 0%，仓库下载次数从 8000+ 降到 500。  
 > 相关链接：[AI21 经验总结线程](https://twitter.com/AI21Labs/status/2010738309681823992)  

##### **DVCP：把“聊天写代码”改造成可控工作流**  
Doomlaser 提出的 Vibe Coding Protocol（DVCP）用“指挥线程+执行线程”的结构，强制模型输出整文件而不是零碎 patch，并通过多线程切换规避前端 DOM 限制。本质是把 LLM 从临时对话工具，拉回到可复现的批量重构管线。  
 > 相关链接：[DVCP 长文](https://doomlaser.com/longform/dvcp)  

##### **新 Agent CLI 工具对比：Kiro、Aider、Cline 等谁更能干活**  
一份基准测试了 20 个 Web 开发任务下的多款“命令行 Agent”工具：Kiro 成功率最高（77%），Gemini CLI 最低（47%）。有用户吐槽，有的工具明明没跑通也说“完成”，提醒大家实际要多试几家找手感。  
 > 相关链接：[Agentic CLI 综合评测](https://research.aimultiple.com/agentic-cli/)｜[Reddit 对比讨论](https://www.reddit.com/r/CLine/comments/1qaycqj/agentic_cli_tools_comparison/)  

##### **PulseFramework：又一个轻量级 LLM 编程框架加入战局**  
社区开发者开源 PulseFramework，定位是比“全自动 Agent”更轻的工作流编排层，强调方便切换模型、接工具和管控步骤，在 Cursor 社区被拿来与 Claude Code、Codex 等工具对比。  
 > 相关链接：[PulseFramework GitHub](https://github.com/manuelfussTC/PulseFramework)  

 

---  


#### **基础设施与硬件**  
##### **NVIDIA Blackwell 被质疑“11 个时钟完成 256×256 运算”夸大性能**  
GPU MODE 社区拆读 Blackwell 微基准论文，指出所谓 256×256 运算 11 cycles 实际是异步操作，不能当作真实延迟，部分结论可能误导 kernel 设计。大家呼吁做性能分析时必须明确异步、排队和内存访问细节。  
 > 相关链接：[相关讨论 PR/帖子](https://github.com/gpu-mode/kernelbot/pull/386)  

##### **RTX 3090 在 LLM 推理下频繁重启，GSP 固件疑似元凶**  
LM Studio 用户报告 RTX 3090 在 Fedora 和 Windows 上跑大模型会直接重启，排查后发现关闭 GSP 固件、适当降压降频可显著提升稳定性。社区建议用 OCCT 和“极端推理负载”压测以确认硬件问题。  
 > 相关链接：[LM Studio Discord 讨论](https://discord.com/channels/1110598183144399058/1110598183144399061/1460372052598067231)  

##### **popcorn-cli 集成 NCU：命令行直接看 GPU 分析报告**  
GPU MODE 发布 popcorn-cli v1.2.2，把 NVIDIA NCU 集成进 CLI：可以在终端内直接展示概要、并下载 .ncu-rep 结果文件，方便团队用统一格式分享和对比 kernel 性能。  
 > 相关链接：[popcorn-cli v1.2.2 发布](https://github.com/gpu-mode/popcorn-cli/releases/tag/v1.2.2)｜[profiling 使用文档](https://github.com/gpu-mode/popcorn-cli/blob/main/docs/profiling.md)  

##### **LM Studio 成功跑上 ARM 开发板，CPU 上 6.6 token/s**  
有人在 Orange Pi 6 Plus（8 核 ARM + Ubuntu）上装好 LM Studio，用 Qwen3‑4B Q4 在纯 CPU 模式下跑到约 6.6 token/s，但 Electron UI 因显卡驱动问题有严重图形破损，只能“盲点”操作。  
 > 相关链接：[LM Studio 硬件讨论串](https://discord.com/channels/1110598183144399058/1153759714082033735/1460518963212718267)  

##### **TinyBox 服务器 BMC 大面积“锁死”，社区分享刷固件自救指南**  
Tinygrad 社区用户反馈 TinyBox 的 BMC（带外管理）无法登录，报 “LAN Parameter Data does not match”。经验做法是：刷新/更新 BIOS 和 BMC 固件，再在 UEFI 菜单里重置 BMC，并做好配置备份。  
 > 相关链接：[Tinygrad Discord 讨论](https://discord.com/channels/1068976834382925865/1068976834928193609/1460381693314863319)  

 

---  


#### **产品与应用落地**  
##### **Google 推出“通用电商协议”：让 Gemini 直接下单购物**  
Google 公布 Universal Commerce Protocol（UCP），并在 Gemini/AI Mode 中测试“一键结账”、与品牌直接聊天的 Business Agent、Direct Offers 等功能。目标是让模型成为购物界面和交易发起方，而不是只给搜索结果。  
 > 相关链接：[Google UCP 官宣](https://twitter.com/Google/status/2010744570108137524)  

##### **Claude Cowork 桌面版：帮非技术员工整理文件、做报表**  
Cowork 允许用户把某个文件夹“交给 Claude”，自动重命名、分目录、从截图里抠表格做 Excel，用会议笔记生成报告，还能配合浏览器操作网页。目前支持 macOS、Claude Max 用户，Reddit 上不少人认为这是对 Copilot 桌面版的“复盘后再做一遍”。  
 > 相关链接：[Cowork 功能介绍博客](https://claude.com/blog/cowork-research-preview)｜[Reddit 体验讨论](https://www.reddit.com/r/ClaudeAI/comments/1qb6gdx/claude_just_introduced_cowork_the_claude_code_for/)  

##### **AI 前台工作流：用 ChatGPT+n8n 接电话、发短信、排日程**  
有开发者在 LMArena 分享了一个“AI 接待员”工作流：用 ChatGPT 结合 n8n 处理来电咨询、预约和改期，以及短信通知。目前已能跑通 demo，正在寻求改造为可上线的稳定版本。  
 > 相关链接：[LMArena 方案讨论](https://discord.com/channels/1340554757349179412/1340554757827461211/1460364891138298049)  

 

---  


#### **政策、治理与安全**  
##### **FDA 更新临床试验统计指南，AI 医疗验证门槛被抬高**  
美国 FDA 发布新版临床试验统计方法指南，被业内认为会直接影响 AI/ML 在医疗场景的监管：要求更严谨的统计验证、前置注册和不确定性报告。社区预计，做医疗 Copilot 的团队需要提供可审计的推理日志、版本化数据与提示词，以满足合规要求。  
 > 相关链接：[FDA 官方新闻稿](https://www.fda.gov/news-events/press-announcements/fda-issues-guidance-modernizing-statistical-methods-clinical-trials)  

##### **环境变量并不安全：本地 Agent 读环境就能拿到全部密钥**  
Reddit 和多家 Discord 讨论指出：一旦你在本机跑 Agent，它通常能直接读取进程环境，从而拿到存放在 env var 里的 API Key 和密码。建议生产环境改用专门的密钥管理系统（如 Vault/AWS Secrets Manager），并避免在日志和错误信息里 dump 环境。  
 > 相关链接：[Reddit 讨论贴](https://www.reddit.com/r/LocalLLM/comments/1qb0fsg/env_vars_dont_work_when_your_agent_can_read_the/)  

##### **BASI 社区持续研究越狱与提示注入，安全攻防“猫鼠游戏”升级**  
BASI Jailbreaking Discord 里有人学习如何对商用 Bot 做提示注入、骗共享单车客服 Bot 送免费骑行，尝试绕过 Gemini 的图像审核以及 Grok 的安全边界。也有成员强调先拿到系统提示，再“顺着规则找洞”。这些讨论反向说明主流模型的安全策略仍在被持续攻破和加固。  
 > 相关链接：[BASI Jailbreaking 讨论区（general）](https://discord.com/channels/1105891499641684019/1235691879492751460/1460362708150124670)  

 

---  

  
