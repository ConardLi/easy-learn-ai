#### **模型与能力**  
##### **NousCoder-14B：开源奥赛级编程模型+完整RL训练栈**  
Nous Research 基于 Qwen3-14B，用 Atropos 框架在 48 张 B200 上跑了 4 天 RL，发布 NousCoder-14B，在奥赛编程基准上 Pass@1 提升 7.08% 到 67.87%。难得的是把 RL 环境、基准和训练脚本全都开源，可直接复现实验或改自家奖励函数。  
 > 相关链接：[模型介绍博客](https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/)｜[发布帖（X）](https://x.com/NousResearch/status/2008624474237923495)  

##### **DeepSeek-R1 论文从 22 页扩展到 86 页，细节补全**  
DeepSeek-R1 把技术报告从 22 页扩到 86 页，补充了评测 prompt、合成数据生成方法、训练 harness、RL 细节和蒸馏分析等。社区解读是：收益更多来自“轨迹探索+可验证奖励”和行为塑形，而不是单纯更好数据。  
 > 相关链接：[arXiv 论文](https://arxiv.org/abs/2501.12948)｜[机器之心解读（X）](https://twitter.com/jiqizhixin/status/2008805570145644849)  

##### **开源视频与图像生成：FLUX.2、LTX-2、OmniHuman 等更新**  
Black Forest Labs 在 HF 放出量化版 FLUX.2 [dev] 32B，支持最多 10 张参考图、4MP 分辨率；LTX-2 称登上开放 text-to-video 榜首；fal 推出 OmniHuman 1.5 720P 头像视频模型，并发布基于 Qwen-Image-Edit 的多视角相机控制 LoRA，方便按机位重拍画面。  
 > 相关链接：[FLUX.2 量化模型（X 摘要）](https://twitter.com/HuggingPapers/status/2008762251352711235)｜[LTX-2 排行版说明](https://twitter.com/ltx_model/status/2008862459327865121)｜[OmniHuman & 相机 LoRA](https://twitter.com/fal/status/2008954582018248755)  

##### **Gemini 3 系列口碑分化：流量上涨，体验却被指“削弱”**  
Similarweb 数据显示 Gemini 在全球 AI 聊天流量已破 20%，ChatGPT 跌到 65% 以下，Grok 超 3%。但 Reddit 大量反馈称 Gemini 3 Pro/3.0 被“阉割”：上下文记不住几轮对话、常重复、拒绝联网搜索，1M token 上下文基本用不出来。  
 > 相关链接：[流量数据讨论 1](https://www.reddit.com/r/singularity/comments/1q6a3lp/gemini_surpassed_20_traffic_share_threshold_among/)｜[流量数据讨论 2](https://www.reddit.com/r/GeminiAI/comments/1q69y88/gemini_surpassed_20_traffic_share_threshold_among/)｜[性能被“nerf”吐槽](https://www.reddit.com/r/GeminiAI/comments/1q6ecwy/gemini_30_has_been_nerfed_big_time/)  

##### **NVFP4 / MXFP4 与新一轮 FP4 量化实验**  
Hugging Face 社区已在 PyTorch 中跑通 NVFP4 前向，通过在 layernorm 间不停在 nvfp4 与 bf16 间转换，暂未做核融合，当前 TPS 反而偏低。NVIDIA 同时在博客里宣传 Blackwell 上 MXFP4 支持，实际 FP4 到底能不能明显提速，还得等更成熟的 kernel 路径。  
 > 相关链接：[NVFP4 讨论（HF Discord）](https://discord.com/channels/879548962464493619/879548962464493622)｜[NVIDIA RTX FP4 优化介绍](https://developer.nvidia.com/blog/open-source-ai-tool-upgrades-speed-up-llm-and-diffusion-models-on-nvidia-rtx-pcs/)  

##### **Fuzzy-Pattern Tsetlin Machine 重写：32M 推理/秒还能生成文本**  
有人用底层优化重写 Fuzzy-Pattern Tsetlin Machine，在 Ryzen 7950X3D 上 MNIST 可达 32M+ 预测/秒，训练提速 10 倍、推理提速 34 倍，准确率约 98%。还做了字符级 Shakespeare 文本生成，展示非 Transformer 路线在特定任务上的可行性。  
 > 相关链接：[Tsetlin.jl GitHub](https://github.com/BooBSD/Tsetlin.jl)｜[Reddit 讨论](https://www.reddit.com/r/MachineLearning/comments/1q6igw3/p_reengineered_the_fuzzypattern_tsetlin_machine/)  

 

---  


#### **Agent 与工具链**  
##### **LangChain DeepAgents 上线“Ralph 模式”，主打循环式长程 Agent**  
LangChain 在 DeepAgents 上加了 Ralph Mode：不再把所有上下文塞进 prompt，而是让 Agent 在循环中刷新上下文、把状态写入文件系统，可“无限跑，满意再 Ctrl+C”。不少人把这类轻量“agent harness”视作新范式，比重 IDE 更灵活。  
 > 相关链接：[LangChain OSS 推文](https://twitter.com/langchain_oss/status/2008942888810631518)｜[“agent harness 时代”评论](https://twitter.com/omarsar0/status/2009061265864262111)  

##### **Cursor 重写上下文系统：少打 47% token，不再全仓库硬塞**  
Cursor 宣布重构 Agent 上下文管理：通过扫描文件、工具和历史，对话中“动态发现”相关上下文，而不是简单全局 embed+检索，据称 token 用量减少 46.9%。结合把对话转录写盘，实现接近“无限长”会话，也在往桌面 Agent 中枢而不是纯 IDE 方向走。  
 > 相关链接：[设计说明 1](https://twitter.com/mntruell/status/2008793943472062807)｜[设计说明 2](https://twitter.com/mntruell/status/2008993971826249986)｜[长会话存盘讨论](https://twitter.com/amanrsanger/status/2008985132523495847)  

##### **MCP 变成“集成底座”：论文助手到机器人都在用**  
Model Context Protocol 正在变成通用工具层：HF 把论文页面接入 HuggingChat + HF MCP server 做“聊论文”，有人用 Claude Code 通过 MCP 控 Reachy Mini 机器人。官方 MCP 社区也在完善指令文档和 mTLS 方案，准备进企业环境。  
 > 相关链接：[HF 论文助手示例](https://twitter.com/AdinaYakup/status/2008863050355675152)｜[机器人实验](https://twitter.com/Trtd6Trtd/status/2008933816073846810)｜[MCP 指令说明博客](https://blog.modelcontextprotocol.io/posts/2025-11-03-using-server-instructions/)  

##### **安全壳：为 Coding Agent 设计命令允许/黑名单**  
随着“YOLO 模式”写 shell 命令越来越常见，社区开始认真给 Agent 做操作黑白名单。典型做法是禁止 git push/reset、发布命令等高风险操作，只对低风险命令自动执行，其他都要人工批准。  
 > 相关链接：[命令白/黑名单示例](https://twitter.com/_philschmid/status/2008975389415354491)  

##### **Supertonic：Fine-tune 只发 Delta，模型分发更省空间**  
Unsloth 社区发布 Supertonic CLI，只保存微调模型相对基座的“差分”，有点像 LoRA 但对训练后全模型做无损压缩。适合一个基座上挂一堆小任务模型，既方便版本管理，也大幅减小上传/存储体积。  
 > 相关链接：[Supertonic HF 页面](https://huggingface.co/Supertone/supertonic-2)｜[CLI 源码](https://github.com/gagansuie/sparse)  

##### **本地 IDE 工具链：VS Code for Local LLMs & LM Studio 组合**  
有人做了一个专门给本地 LLM 用的 VS Code 变体，内置 LM Studio/Ollama 支持，重写了上下文管理，声称在本地代码索引和检索上比主流 AI IDE 更快。适合不想把代码传云端的团队。  
 > 相关链接：[VS Code-LMStudio 发行版](https://github.com/bdrazn/codeOSS-LMStudio-Ollama/releases/tag/First-Light)  

 

---  


#### **基础设施与硬件**  
##### **GPU 成本继续飙：RTX 5090 或涨到 5000 美元**  
TrendForce 报告称 2026 年起 NVIDIA、AMD 都要涨价，RTX 5090 可能到 5000 美元级别。Discord 里一片吐槽：大显卡买不起，本地玩大模型更难，只能多用共享集群、spot 实例和混搭消费级+数据中心卡。  
 > 相关链接：[价格预测报道](https://www.trendforce.com/news/2026/01/05/news-nvidia-amd-reportedly-plan-price-hikes-starting-1q26-geforce-rtx-5090-may-reach-5000/)  

##### **NVIDIA 公布 RTX 端一堆开源加速：采样、QKV 并发、MXFP4**  
NVIDIA 发文总结在 RTX PC 上给 LLM/扩散模型做的开源优化：GPU 端采样、QKV 并发、MMVQ kernel、更快加载，以及 Blackwell 上原生 MXFP4。实际能省多少时延，要看框架集成得有多深。  
 > 相关链接：[官方博客](https://developer.nvidia.com/blog/open-source-ai-tool-upgrades-speed-up-llm-and-diffusion-models-on-nvidia-rtx-pcs/)  

##### **CuTeDSL / FlashAttention：Blackwell/H100 上又抠出 30%**  
有工程师用 CuTeDSL 把 GEMM 主循环拆成 TMA+MMA 做 warp specialization，在 Blackwell 上拿到可观提速；另有人在 flash-attention 里集成 CuTeDSL flex attention，在 H100 前向比原版快约 30%，正在补齐不同 SM 架构的反向支持。  
 > 相关链接：[Warp specialization 博客](https://veitner.bearblog.dev/warp-specialisation-in-cutedsl/)｜[FlashAttention PR 讨论](https://github.com/Dao-AILab/flash-attention/pull/2137)  

##### **AMD 阵营动作：Helion 上 ROCm、Iris Triton 多卡框架招人**  
AMD 工程师在 GPU MODE 表示正在让 Helion 编译栈跑在 ROCm 上，并排查 GEMM 性能瓶颈；同时 Iris 项目（基于 Triton 的多 GPU 框架）在招实习，重点是多卡编程、RDMA 和底层通信。整体看是想把 AMD + Triton/Helion 打造成 CUDA 之外的认真选项。  
 > 相关链接：[Iris 项目](https://github.com/ROCm/iris/)  

##### **OpenRouter/Qwen TPS 暴跌：便宜路由=变相“降速”**  
大量用户反馈 12 月 28 日后 OpenRouter 上 Qwen3-Next-80B 等开源模型 TPS 明显变慢，官方称是路由到最便宜的 GMICloud 所致。建议在控制台 Activity 里看每家延迟，必要时手动锁定更快的提供商。  
 > 相关链接：[OpenRouter 状态更新](https://x.com/openrouterai/status/2005707622020964412)｜[提供商/IP 政策列表](https://openrouter.ai/providers)  

 

---  


#### **研究与方法**  
##### **Karpathy“nanochat”小规模 Scaling Law 实验：4 小时 100 美元版 Chinchilla**  
Karpathy 写了一套低成本做 scaling law 的流程：训练一串小模型，拟合出类似 Chinchilla 的参数/数据指数，估算“计算无关常数”，还用 CORE 分数对比 GPT2/3，总成本约 100 美元、8×H100 跑 4 小时。适合团队在上大规模训练前先用小实验把盘算做清楚。  
 > 相关链接：[nanochat 系列推文](https://twitter.com/karpathy/status/2009037707918626874)  

##### **社区对 LM Arena 这类“对战榜单”的信任度越来越低**  
Teknium 直言 LM Arena 变成“氪金上分”，为了榜单分数反而牺牲模型质量；SurgeHQ 也发文叫它“瘟疫”。不少人表示现在几乎不看这类榜单，更在乎按任务分场景的可复现实验，特别是长程推理和 Agent 性能。  
 > 相关链接：[批评 LM Arena 的博客](https://surgehq.ai/blog/lmarena-is-a-plague-on-ai)｜[Teknium 吐槽（X）](https://twitter.com/Teknium/status/2008828875355443634)  

##### **CodeClash：面向长程 Agent 的迭代对抗编码基准**  
新基准 CodeClash 把编码评测从单次“写函数”升级为多轮、对抗式、长程 SWE 场景，并放出了训练集。方向很明确：未来评测不再是单轮回答，而是多步调用工具+运行代码环路下的真实表现。  
 > 相关链接：[CodeClash 介绍](https://twitter.com/OfirPress/status/2008986204088545423)  

##### **检索 vs 长上下文：RAG 不会被“RLM”杀死，只是换了架构**  
lateinteraction 指出，哪怕大模型上下文再长，面对海量语料还是离不开子线性索引用检索；真正过时的是“先检索一把再一次性读完”的旧式 RAG，现在更像多轮“搜-读-再搜”流水线（比如 Baleen）。长上下文更像一次性插入更多候选，而不是替代检索系统。  
 > 相关链接：[检索观点 1](https://twitter.com/lateinteraction/status/2008766087752511718)｜[检索观点 2](https://twitter.com/lateinteraction/status/2008768325908918328)  

 

---  


#### **产品与应用落地**  
##### **ChatGPT Health 上线：接入病历和健康 App 的“健康分栏”**  
OpenAI 推出 ChatGPT Health，在 ChatGPT 里单独开了个“看病”空间，可安全接入医疗记录和 Apple Health、Peloton 等，回答会基于你个人数据。官方强调：健康对话不会进训练，单独加密、单独隔离，也不替代医生。目前走候补名单，计划逐步放给免费用户。  
 > 相关链接：[官方博客](https://openai.com/index/introducing-chatgpt-health/)｜[Reddit 讨论](https://www.reddit.com/r/OpenAI/comments/1q6ouuf/openai_releases_chatgpt_health_on_mobile_and_web/)  

##### **LLM 诊断能力两极结论：90% vs 52.1% 准确率的背后**  
两篇 Nature 系列论文给 ChatGPT 医疗诊断截然不同的分数：一篇称 90% 准确率，另一篇只有 52.1%。Perplexity 社区讨论认为，这是任务设定和数据集差异导致的，用单一数字宣传“医生级”很危险，真要落地必须有细粒度任务、门限和安全监控。  
 > 相关链接：[90% 准确率论文](https://www.nature.com/articles/s41746-025-01543-z)｜[52.1% 准确率论文](https://www.nature.com/articles/s41591-024-03097-1)  

##### **Liquid AI × AMD：2.6B 本地会议摘要模型只吃不到 3GB 内存**  
Liquid AI 联合 AMD 推出 LFM2-2.6B-Transcript，专门做长会议记录摘要，目标是在 CPU/GPU/NPU 上本地跑，峰值内存 <3GB，号称“云端质量、本地隐私”。这是小模型针对垂直场景抢占地盘的典型例子。  
 > 相关链接：[发布线程](https://twitter.com/liquidai/status/2008954886659166371)  

##### **Tolan 与 Razer：语音 AI 伴侣开始真正在 C 端跑起来**  
Tolan 宣布语音优先 AI 伴侣月活已到 20 万，背后是多模态+本地/云混合+记忆系统；Razer 预告 2026 CES 将发布 5.5 寸屏的 AI 伴侣设备 Project AVA，可换人设皮肤。从“demo 玩具”走向真正日用，延迟、稳定和人格设计都成了核心问题。  
 > 相关链接：[Tolan 用户里程碑](https://x.com/paularambles/status/2008964509810278413)｜[Razer AVA 预告](https://xcancel.com/razer/status/2008543615916666928)  

##### **本地音乐生成 ACE-Step：4 分钟歌 20 秒出，摆脱 Suno 限流**  
有用户在 8GB 显存机器上本地跑 ACE-Step，4 分钟音乐约 20 秒生成，通过 CPU offload 和 8bit 量化把显存压到 7.5–9GB，质量接近 Suno，且无 30 美元/月订阅和限流。适合想自控素材的音乐人和视频博主。  
 > 相关链接：[Reddit 使用教程](https://www.reddit.com/r/LocalLLaMA/comments/1q64qpx/running_acestep_locally_4minute_music_generation/)  

##### **本地 16GB 显卡也能“写代码”：Dyad + Oobabooga 的自托管方案**  
有人分享在 16GB 显存卡上用 Oobabooga 做后端，驱动 Dyad 实现本地自动写代码，主打零云依赖、零 API 费。对想要代码隐私、但预算有限的个人开发者和小团队是条可行路线。  
 > 相关链接：[Reddit 经验贴](https://www.reddit.com/r/Oobabooga/comments/1q6bed6/vibe_coding_local_with_16gb_vram_dyad_oobabooga/)｜[配套视频](https://youtube.com/watch?v=DhKYjtCyD7U)  

 

---  


#### **行业与公司动态**  
##### **Gemini 份额破 20%，ChatGPT 仍在 60%+ 但被实打实分流**  
Similarweb 图显示，2025 一年里 Gemini 从边缘爬到 AI 聊天流量超 20%，ChatGPT 则从 80%+ 掉到 65% 以下，Grok 和 DeepSeek 也有 3% 左右。Google 靠生态捆绑（Drive、Docs、YouTube、2TB 云盘+家庭共享）在吃掉纯聊天产品的市场。  
 > 相关链接：[市场份额 Reddit 讨论 1](https://www.reddit.com/r/singularity/comments/1q6a3lp/gemini_surpassed_20_traffic_share_threshold_among/)｜[市场份额 Reddit 讨论 2](https://www.reddit.com/r/GeminiAI/comments/1q6skak/chatgpt_is_losing_market_share_as_google_gemini/)  

##### **xAI 和 Anthropic 融资传闻：资金军备竞赛继续加码**  
Yuchen Jiang 在 X 上称 xAI 已融资约 200 亿美元，成为资金第二充足的实验室；另一边，有报道说 Anthropic 计划以 3500 亿估值再融 100 亿。钱大量砸进来意味着下一代 GPT/Grok 级别训练不会放缓，只会更贵。  
 > 相关链接：[xAI 融资讨论](https://twitter.com/Yuchenj_UW/status/2008774688382599520)｜[Anthropic 融资传闻](https://twitter.com/SawyerMerritt/status/2008964178204295429)  

##### **Discord 机密递交 IPO 申请，2 亿月活聊天基础设施要上市**  
Bloomberg 称 Discord 已机密提交 IPO，投行有高盛和摩根大通。对 AI 圈的意义是：大部分模型社区和开发者交流都在这个平台上，上市后在数据、插件和商业化上大概率会有新动作。  
 > 相关链接：[Bloomberg 报道](https://www.bloomberg.com/news/articles/2026-01-06/chat-platform-discord-is-said-to-file-confidentially-for-ipo)  

##### **全球开源权力版图：Qwen、DeepSeek、韩国模型在 HF 上猛增**  
Nat Lambert 更新了一版“开源模型生态”图，显示中国系模型在使用量上已明显领先，Stanford NLP 点名阿里 Qwen 是开源权重里的“压倒性赢家”。HF CEO 也提到韩国在政府支持下正在产出一批热度很高的开源模型。  
 > 相关链接：[Nat Lambert 生态图](https://twitter.com/natolambert/status/2008920674442637635)｜[Stanford NLP 关于 Qwen](https://twitter.com/stanfordnlp/status/2008953208907927601)｜[韩国开源模型讨论](https://twitter.com/ClementDelangue/status/2008954270411051465)  

 

---  


#### **政策、治理与安全**  
##### **ChatGPT Health 引发隐私争议：医疗数据能不能用来“改进服务”？**  
ChatGPT Health 一上线，隐私条款就被放大镜审视：OpenAI 说不会用健康对话训练基础模型，但允许用于改进服务和研究。Discord 里不少人担心这会把医疗记录锁进一个“AI 超级应用”，也有人拿 Google 开源 MedGemma 做对比，讨论合适的监管边界。  
 > 相关链接：[官方政策说明](https://openai.com/index/introducing-chatgpt-health/)｜[Yannick 服务器讨论节选](https://discord.com/channels/714501525455634453/853983317044756510)  

##### **Sora 滥用与儿童安全：社区呼吁更强年龄与内容审核机制**  
有帖子指控有人用 Sora 的 cameo 功能，将儿童照片合成进虐待视频，引发极大担忧。评论普遍要求平台增加更强的滥用检测、年龄识别和快速下架流程，也提醒不要轻易认定发布者必然是施害者，可能本身也是受害者。  
 > 相关链接：[Reddit 讨论](https://www.reddit.com/r/OpenAI/comments/1q6521z/pedophiles_are_using_sora_to_depict_themselves/)  

##### **OpenRouter 账号被盗事件：API 网关的安全与 IP 暴露问题**  
有用户报告 OpenRouter 账号被盗、邮箱被改、信用卡被刷、历史数据清空。结合之前有人挖出部分模型提供商能拿到真实用户 IP（不是 Cloudflare IP），社区开始建议：尽量用一次性卡、开 2FA、定期查账单，并在选供应商前看清 IP/日志策略。  
 > 相关链接：[提供商与 IP 政策](https://openrouter.ai/providers)  

##### **BASI 社区：多语言 Jailbreak 与 Guardrail“短板效应”**  
越狱圈有人提醒：很多安全策略只在英语上调得比较紧，换成斯瓦希里语、纳瓦霍语甚至俄语时，模型更容易露出破绽，Guardrail 明显变弱。这也说明红队和对齐工作不能只盯英文，否则实际风险会从语言长尾溢出。  
 > 相关链接：[Redteaming 讨论节选](https://discord.com/channels/1105891499641684019/1204553141354504193)  

##### **LLM 医疗应用：研究者提醒不要被漂亮的准确率数字骗了**  
在 Perplexity 和 Yannick 等社区里，大家把两篇 ChatGPT 医疗诊断论文对比着看：90% vs 52.1%。结论基本一致：这些数字高度依赖任务设计，一旦换成真实医院场景、非结构化病历和责任分配，安全性完全是另一回事，必须有临床试验和事后风控。  
 > 相关链接：[高准确率论文](https://www.nature.com/articles/s41746-025-01543-z)｜[低准确率论文](https://www.nature.com/articles/s41591-024-03097-1)  

 

---  

  
