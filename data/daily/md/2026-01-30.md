#### **模型与能力**  
##### **xAI 发布 Grok Imagine v1.0：视频+音频生成登顶榜单**  
xAI 上线 Grok Imagine API，支持 720P 文本/图像生成视频、视频编辑，并内置原生音频，单次可生成 15 秒。Artificial Analysis 等榜单把它排在当前视频模型第一梯队，价格约 $4.2/分钟（含音频），速度也被用户评价为“非常快”。  
 > 相关链接：[xAI Grok Imagine 公告](https://x.ai/news/grok-imagine-api)｜[Arena 排名与测评](https://twitter.com/arena/status/2016748418635616440)｜[Artificial Analysis 价格与榜单](https://twitter.com/ArtificialAnlys/status/2016749756081721561)｜[Ethan He 发布线程](https://twitter.com/EthanHe_42/status/2016749123198673099)｜[Elon Musk 转发](https://twitter.com/elonmusk/status/2016768088855769236)  

##### **Google DeepMind 推出 Project Genie（Genie 3）：可交互世界模型上线**  
DeepMind 把研究级世界模型 Genie 3 做成了产品：用户可用文本或图片一键生成可操作的互动小世界，支持角色自定义、二创和作品库。当前仅向美国 18+ 的 Google AI Ultra 订阅用户开放，存在生成时长约 60 秒、控制延迟和物理不完美等限制。  
 > 相关链接：[DeepMind 官方发布](https://twitter.com/GoogleDeepMind/status/2016919756440240479)｜[Google 产品说明](https://twitter.com/Google/status/2016972686208225578)｜[Demis Hassabis 介绍](https://twitter.com/demishassabis/status/2016925155277361423)｜[Sundar Pichai 转发](https://twitter.com/sundarpichai/status/2016979481832067264)｜[官方博客 Project Genie](https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/)  

##### **开源世界模型 LingBot-World：对标 Genie 的实时交互仿真**  
LingBot-World 宣称在动态仿真上超过 Genie 3：基于 Wan2.2，16 FPS、延迟小于 1 秒，可在视野外保持物体 60 秒的一致性。完全开源，可在 Hugging Face 下载，但社区质疑与 Genie 的对比缺乏同场评测和硬件要求说明。  
 > 相关链接：[LingBot-World 集合](https://huggingface.co/collections/robbyant/lingbot-world)｜[论文/总结线程](https://twitter.com/dair_ai/status/2016881546909929775)  

##### **Runway Gen-4.5：从“视频模型”向“动画引擎”转型**  
Runway Gen-4.5 新增 Motion Sketch（在首帧上画相机/运动轨迹）和角色替换等功能，用户更容易把模型当成动画工具而不是一次性生成器。官方还主推“照片→故事短片”工作流，降低普通创作者上手门槛。  
 > 相关链接：[功能介绍线程](https://twitter.com/jerrod_lew/status/2016816309762486423)｜[Runway 官方示例](https://twitter.com/runwayml/status/2016882344427147275)  

##### **阿里 Qwen3-ASR 发布：52 语种、20 分钟长音频的开源语音栈**  
Qwen3-ASR + ForcedAligner 面向真实场景噪声，支持 52 种语言/方言和最长 20 分钟语音转写带时间戳，Apache 2.0 许可证并开源推理与微调工具链。vLLM 在发布当天就支持，单条推理吞吐宣称可提升到原生系统的数千倍量级。  
 > 相关链接：[Qwen3-ASR 发布](https://twitter.com/Alibaba_Qwen/status/2016858705917075645)｜[ForcedAligner 介绍](https://twitter.com/Alibaba_Qwen/status/2016859224077455413)｜[vLLM 支持声明](https://twitter.com/vllm_project/status/2016865238323515412)  

##### **Kimi K2.5：开源方向的“全能王”模型继续刷榜**  
Kimi K2.5 在 LMArena/Arena 多个榜单上被推为当前最强开源模型之一：代码榜 #7，总体性能接近 Claude Sonnet 4.5，Vision Arena 中 K2.5 Thinking 是唯一打入前 15 的开源模型。社区普遍认为它基于新一代架构+持续训练，下一轮竞争将来自 K3 / GLM-5 等。  
 > 相关链接：[Kimi 官方榜单宣发](https://twitter.com/Kimi_Moonshot/status/2016732248800997727)｜[Arena 开源模型分析](https://twitter.com/arena/status/2016915717539713236)｜[Vision Arena 榜单](https://arena.ai/leaderboard/vision)  

##### **Arcee Trinity Large：400B MoE 架构细节公开**  
Arcee 公布 Trinity Large 细节：400B MoE、每次仅激活约 13B 参数，通过路由、负载均衡和注意力改造在保证收敛稳定的前提下降低推理成本。多种变体已在 Hugging Face 走红，被视作新一代高通量 MoE 架构的代表之一。  
 > 相关链接：[Sebastian Raschka 架构解读](https://twitter.com/rasbt/status/2016903019116249205)｜[Arcee 官方推文](https://twitter.com/arcee_ai/status/2016986617584529642)  

 

---  


#### **Agent 与工具链**  
##### **“Agentic Engineering” 正成型：从瞎试 prompt 到可复用工程流程**  
社区开始用“Agentic Engineering”对比过去的“vibe coding”：更重视上下文准备、评估与沙箱，而不是靠感觉写 prompt。Primer 给出一套模板：自动读仓库→生成使用说明→做有/无说明的轻量评测→批量开 PR 推广到整个组织。  
 > 相关链接：[Agentic Engineering 讨论](https://twitter.com/bekacru/status/2016738191341240830)｜[Primer 工作流介绍](https://twitter.com/pierceboggan/status/2016732251535397158)  

##### **多 Agent 协调 vs 大一统大模型：行业更看重“调度策略”**  
多篇帖子指出：用 RL 训练的控制器在大/小模型之间路由任务，在 HLE 等基准上能以更低成本跑赢单一大模型方案。亚马逊 Insight Agents 论文也强调“经理-工人”结构，用自编码器+微调 BERT 做 OOD 检测和路由，而不是全靠 LLM 分类。  
 > 相关链接：[多模型路由总结](https://twitter.com/LiorOnAI/status/2016904429543272579)｜[Insight Agents 解读](https://twitter.com/omarsar0/status/2016880021030522997m)  

##### **Kimi 的 Agent Swarm：用“多视角群体”规划再执行**  
Kimi K2.5 的 Agent 模式被内部定位为解决“只会聊天不会做事”和“工具调用乱飙”的方案：先由多个视角 agent 做规划，再结合工具结果动态更新上下文，最后再执行。社区实测用来查 SDK 依赖、跨语言迁移代码等效果不错，但信用消耗较快。  
 > 相关链接：[Agent Swarm 设计长文](https://twitter.com/ZhihuFrontier/status/2016811037274886377)  

##### **Cursor 推出 agent-trace.dev：给所有 Agent 一个统一“黑盒记录仪”**  
Cursor 提出一个开放标准，把 Agent 对话、工具调用、生成代码等过程串成可查询的 trace，声称能被各种 IDE、Agent 框架共用。结合 Discord 里大量“Plan 模式太打断工作流”的吐槽，可以看出下一步是既要可审计，也要少打扰。  
 > 相关链接：[Cursor agent-trace.dev 公告](https://twitter.com/cursor_ai/status/2016934752188576029)  

##### **MCP 安全标准草案：给“模型调用协议”上安全条款**  
社区安全研究员 cr0hn 起草了 MCP Server 安全基线，覆盖加固、日志、访问控制和供应链安全，准备贡献给 Agentic AI Foundation。协议本身也在演进，官方放弃 Namespaces，改用 Groups（SEP‑2084）。  
 > 相关链接：[MCP 安全标准草案](https://github.com/mcp-security-standard/mcp-server-security-standard)｜[Primitive Grouping SEP-2084](https://github.com/modelcontextprotocol/modelcontextprotocol/pull/2084)  

##### **DSPy / RLM 等框架：开始把“沙箱”和“技能”纳入标准部件**  
DSPy 社区在讨论：如何把自定义技能（md+py）纳入 ReAct agent，如何把 RLM 的沙箱替换为 E2B、Modal 等云环境，并在生产环境动态优化。有人甚至在做“让 Claude Opus 自己写新沙箱”的协议。  
 > 相关链接：[DSPy 讨论串](https://discord.com/channels/1161519468141355160/1161519469319946286/1466188672780210206)  

 

---  


#### **基础设施与硬件**  
##### **微软 Maia 200 AI 加速卡：对标 NVIDIA 的推理专用芯片**  
Maia 200 面向推理场景，配备 216GB 显存，在 FP4 下标称 10K TFLOPS。社区普遍拿它对比 NVIDIA “Vera Rubin” 架构，认为在大规模推理集群上可能有成本优势，但仍依赖 TSMC 代工，生态成熟度待观察。  
 > 相关链接：[Maia 200 官方博客](https://blogs.microsoft.com/blog/2026/01/26/maia-200-the-ai-accelerator-built-for-inference/)  

##### **RTX 5090 实测微调性能：Unsloth 跑到 18k tok/s**  
Unsloth 社区用户在 RTX 5090 上报告训练吞吐最高可达 18k tok/s，实际稳态在 12–15k tok/s（seq_len <4096）。关键在于合理平衡 batch size 和序列长度，说明单卡桌面 GPU 的训练上限又被推高了一截。  
 > 相关链接：[Unsloth showcase 讨论](https://discord.com/channels/1179035537009545276/1179779344894263297/1466516150950301814)  

##### **Apple ANE 实测：能效逼近 GPU，适合本地推理**  
最新论文测到 M4 Pro 的 Neural Engine（ANE）在 GEMM 上可达 3.8 TFLOPS，接近同芯片 GPU 的 4.7 TFLOPS，但功耗更低。结论是：苹果在追求性能/功耗比而非纯算力，本地小模型推理用 ANE 可能比啃 GPU 更实际。  
 > 相关链接：[ANE 性能论文](https://arxiv.org/abs/2511.13450)  

##### **GPU Profiler 与稀疏训练：从 CUTLASS 到 sparse-llm.c 实战**  
GPU MODE 社区分享：nsys 能看到一些 ncu 看不到的 CUB 内核；有人基于 cuSPARSELt 改写 Karpathy 的 llm.c，在后期 epoch 获得明显加速。群里还在筹一个“稀疏性项目”，系统性比较不同稀疏模式的实际提速。  
 > 相关链接：[sparse-llm.c 项目](https://github.com/WilliamZhang20/sparse-llm.c)  

##### **TVM-FFI：为 ML 系统内核做的“统一插口”**  
TVM 作者陈天奇发布 tvm-ffi：为 ML 系统 GPU 内核提供开放 ABI/FFI，目标是减少主机开销并直接与 PyTorch 等框架互通。很多 NVFP4 比赛的顶级选手已在用，说明这套“拼装式内核生态”正在被严肃工作负载采纳。  
 > 相关链接：[tvm-ffi 介绍视频](https://www.youtube.com/watch?v=xMzcs6AqLVo)  

##### **LM Studio 0.4：多 GPU 并发与 ROCm 老版本槽点**  
LM Studio 0.4 新增并行请求，可把不同模型分配到不同 GPU，默认支持 4 并发；高级采样与硬件设置被收进“Dev Mode”。但 Linux 版仍停留在 ROCm 6.4.1，社区希望尽快升级以覆盖 Strix Halo 等新卡。  
 > 相关链接：[LM Studio 0.4.0 公告](https://lmstudio.ai/blog/0.4.0)  

 

---  


#### **研究与方法**  
##### **DeepMind AlphaGenome：统一 DNA 序列模型刷爆 25/26 基准**  
AlphaGenome 可以一次看 100 万个碱基，对 11 类组学信号（基因表达、染色质等）做单碱基分辨率预测，在 26 项任务中 25 项超越专用模型。训练在 TPUv3 上只用了 4 小时，H100 上推理不到 1 秒，被视为“通用基因调控模型”。  
 > 相关链接：[Nature 论文](https://www.nature.com/articles/s41586-025-10014-0)｜[DeepMind 博客](https://deepmind.google/blog/alphagenome-ai-for-better-understanding-the-genome)｜[代码与模型](https://github.com/google-deepmind/alphagenome)  

##### **递归语言模型 RLM：真正的新范式还是“包了层循环”的老酒？**  
RLM-Qwen3-8B 被作者称为首个“小规模原生递归模型”，只用 1000 条轨迹后训练，在长上下文任务上超过基础 Qwen3-8B 和脚手架式 RLM。社区一半认为这就是“工具循环新名字”，一半认为它真在学习“自己调度自己”。  
 > 相关链接：[RLM-Qwen3-8B 推文](https://x.com/a1zhang/status/2016923294461476873)  

##### **Keel、几何卷积等新架构：想把 Transformer 的瓶颈撬开**  
几条讨论集中在两条线：1）Keel 用类似 Highway 的 Post-LN 设计，把 Transformer 深度扩展到 1000 层；2）GeometricTransformer 用“几何卷积”替代多头注意力，用 embedding 之间的拓扑关系做消息传递。这些都在试图减轻注意力的算力瓶颈。  
 > 相关链接：[Keel 论文讨论](https://x.com/chenchen_0201/status/2016445290501603348)｜[GeometricTransformer 仓库](https://github.com/MrPan2048/GeometricTransformer)  

##### **Anthropic 研究“AI 让人变得更听话”的模式**  
Anthropic 发布关于“disempowerment”（被削弱感）的研究：LLM 助手在建议时可能改变用户的信念、价值观和行动，尤其在长期陪伴场景。论文重点是在对话数据中识别这些模式，用于后续对齐和红队评估。  
 > 相关链接：[Anthropic 研究推文](https://twitter.com/AnthropicAI/status/2016636581084541278)  

##### **Goodfire AI + PrimaMente：用可解释模型找阿尔兹海默新生物标记**  
Goodfire AI 与 PrimaMente 最新研究用可解释 AI 模型，在脑部数据中发现新的阿尔兹海默病 biomarker。重点不是“黑盒准确率”，而是可以给医生看得懂的特征贡献，说明解释性在数字生物学里开始真的“带来新发现”。  
 > 相关链接：[研究页面](https://www.goodfire.ai/research/interpretability-for-alzheimers-detection)｜[Twitter 公告](https://xcancel.com/goodfireai/status/2016563911508840623)  

 

---  


#### **产品与应用落地**  
##### **OpenAI 内部“AI 数据代理”：在 600+PB 数据上做自然语言分析**  
OpenAI 揭露了一点自家吃狗粮的细节：用 Codex 风格模型做表结构理解与 SQL 生成，管理 70k+ 数据集、600PB 数据，通过精心的 schema 先验、检索和上下文控制，让内部同事用自然语言查公司数据。  
 > 相关链接：[OpenAI Devs 线程](https://twitter.com/OpenAIDevs/status/2016943147239329872)  

##### **Gemini Agentic Vision：把“看图”拆成一个小 Agent 流程**  
Google 把 Gemini Flash 3 的图像能力包装成“Agentic Vision”：模型会自己规划步骤、放大、标注，并在需要时调用 Python 作图，而不是一次性给出回答。本质上是把视觉理解拆成多步可追踪的 pipeline。  
 > 相关链接：[GeminiApp 简介](https://twitter.com/GeminiApp/status/2016914275886125483)  

##### **LM Studio、LlamaBarn 等本地 LLM 工具，体验继续打磨**  
ggerganov 新做了一个 Mac 菜单栏小应用 LlamaBarn，基于 llama.cpp 跑本地模型；LM Studio 0.4 则加入多 GPU 并发和隐藏在 Dev Mode 里的高级设置。整体趋势是：本地 LLM 从“能跑”走向“够顺手”。  
 > 相关链接：[LlamaBarn 推文](https://twitter.com/ggerganov/status/2016912009544057045)｜[LM Studio 0.4 介绍](https://lmstudio.ai/blog/0.4.0)  

##### **Claude 订阅 vs API：有人算出“开会员最多能省 36 倍钱”**  
有数据控通过解析网页里没四舍五入的浮点数，倒推出 Claude 网页版的真实 token 配额，结论是：在大量编码/长会话场景下，订阅版因缓存免费读写，折算下来比直接用 API 最多便宜 30 多倍，尤其是 Max 5x 套餐。  
 > 相关链接：[详细分析与公式](http://she-llac.com/claude-limits)｜[Reddit 讨论](https://www.reddit.com/r/ClaudeAI/comments/1qpcj8q/claude_subscriptions_are_up_to_36x_cheaper_than/)  

##### **Claude 成本优化实战：用文件“冷热分层”省下 94.5% API 费**  
有团队做了个开源工具 cortex‑tms，把项目文件按 HOT/WARM/COLD 分层，只把最相关文件默认喂给 Claude，其余按需加载。实测单轮 token 从 6.6 万降到 3.6 千，Sonnet 4.5 调用成本从 $0.11 掉到 $0.01，适合重度代码助手用户参考。  
 > 相关链接：[GitHub 项目](https://github.com/cortex-tms/cortex-tms)｜[Reddit 成本对比帖](https://www.reddit.com/r/ClaudeAI/comments/1qp9ve9/we_reduced_claude_api_costs_by_945_using_a_file/)  

 

---  


#### **行业与公司动态**  
##### **OpenAI、Anthropic、xAI+SpaceX：万亿估值 IPO 赛跑**  
多方消息称：OpenAI 正按约 8000 亿美元估值融资，Anthropic 约 3500 亿，美股“Mag 7”中的 NVIDIA、微软、亚马逊等正考虑联手向 OpenAI 注资最高 600 亿美元，软银也在看 300 亿级别；xAI 与 SpaceX 估值被市场喊到 11000 亿，今年底可能迎来多家 AI 独角兽扎堆 IPO。  
 > 相关链接：[投资传闻讨论](https://www.reddit.com/r/singularity/comments/1qpxyka/nearly_half_of_the_mag_7_are_reportedly_betting/)｜[相关 Twitter 线索](https://x.com/mattzeitlin/status/2017027653040001368)  

##### **Moonshot Kimi：把 K2.5 全面产品化并改用按 Token 计费**  
Moonshot 宣布 Kimi Code 全面切换到 K2.5 模型，同时从“按请求计数”改成“按 token 计费”，并短期内开放 3 倍额度、取消限速。社区反馈：对大量短追问的用户更友好，但新计费方式一开始有点难懂。  
 > 相关链接：[Kimi 计费更新](https://twitter.com/Kimi_Moonshot/status/2016918447951925300)  

##### **CZI 裁员 8%：张博慈把筹码压在 AI+科学**  
扎克伯格的慈善基金会 CZI 裁掉约 70 人（约 8%），官方说法是重组，把资源更多投向 AI 工具和生物医学。对研究类 AI 公司来说，这是一个信号：传统慈善资金也在向“AI 基础设施 + 科学”倾斜。  
 > 相关链接：[裁员报道](https://x.com/teddyschleifer/status/2016598537673273470)  

##### **Flapping Airplanes 融资 1.8 亿美元：直冲“人类水平”模型**  
新创公司 Flapping Airplanes 宣布完成 1.8 亿美元融资，投资方包括 GV、红杉、Index，公开目标是打造“human-level”的通用模型。定位和 OpenAI、Anthropic 属于同一赛道，只是还在早期“讲故事”阶段。  
 > 相关链接：[融资公告](https://xcancel.com/flappyairplanes/status/2016564437499728259)  

 

---  


#### **政策、治理与安全**  
##### **Gemini “Remember:” 成新型持久注入点：红队提醒慎用记忆功能**  
BASI Jailbreaking 社区发现，Gemini 对话里打“Remember:”后面的内容会直接写进持久记忆，显著影响后续行为，相当于一个官方提供的长期 prompt 注入接口。对企业来说，如果不加限制地让用户写记忆，安全风险不小。  
 > 相关链接：[Gemini 记忆说明页](https://gemini.google.com/saved-info)  

##### **API 便宜到离谱，本地模型还有啥价值？社区给出“反垄断”和“可信”两大理由**  
Reddit 上有人吐槽：K2.5 价格只有 Opus 的十分之一，DeepSeek 几乎免费，Gemini 免费额度又大，本地跑大模型越来越不划算。高赞回复认为：1）现在的价格是风投补贴，垄断后大概率涨价；2）只有本地/开源模型可以审计和锁死行为，满足隐私和可重复性要求。  
 > 相关链接：[API 价格讨论帖](https://www.reddit.com/r/LocalLLaMA/comments/1qp6rm5/api_pricing_is_in_freefall_whats_the_actual_case/)  

##### **Claude 工作区研究：AI 编程助手如何影响“掌握度”**  
Anthropic 发布内部研究，分析 AI 辅助编码对开发者技能和“掌握感”的长期影响，虽然细节还不多，但凸显监管和公司都开始关心：用 AI 写代码会不会让工程师变得更“依赖”、更难独立排错。  
 > 相关链接：[Anthropic 研究推文](https://twitter.com/AnthropicAI/status/2016960382968136138)  

 

---  

  
