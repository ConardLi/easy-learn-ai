#### **模型与能力**  
##### **Claude Opus 4.6 发布：1M 长上下文 + C 编译器实验**  
Anthropic 升级 Opus 到 4.6，主打 1M token 上下文（beta）、更强规划和持续执行能力。在内部实验中，用 Opus 4.6 多代理“放养”两周写出一个干净房间的 C 编译器，可在 x86/ARM/RISC‑V 上编译 Linux 6.9、QEMU、FFmpeg 等，测试通过率约 99%。多数榜单上在 ARC‑AGI2、SWE-Bench、TerminalBench 等推高到当前 SOTA。  
 > 相关链接：[官方发布](https://www.anthropic.com/news/claude-opus-4-6)｜[C 编译器实验线程](https://twitter.com/AnthropicAI/status/2019496582698397945)｜[ARC‑AGI2 分数讨论](https://www.reddit.com/r/singularity/comments/1qws1j9/anthropic_releases_claude_opus_46_model_same/)｜[Vals 榜单](https://twitter.com/ValsAI/status/2019471561539874938)  

##### **GPT‑5.3 Codex 上线：更快更省的代码模型**  
OpenAI 推出 GPT‑5.3‑Codex，强调“直接拿来造东西”。在 SWE‑Bench Pro、TerminalBench 2 等基准上相比 5.2‑Codex 提升小幅准确率，同时 token 使用减少约 2.1 倍、推理加速约 40%，综合算下来同等质量下接近 3 倍效率。官方称模型为 GB200‑NVL72 专门协同设计。  
 > 相关链接：[模型发布](https://openai.com/index/introducing-gpt-5-3-codex/)｜[性能与效率分析](https://twitter.com/scaling01/status/2019492593709772815)  

##### **Claude Opus 4.6 vs GPT‑5.3‑Codex：编码 SOTA 近身肉搏**  
两家在同一天放出小版本：Opus 4.6 在 ARC‑AGI2、SWE‑Bench、长上下文和“代理团队”上刷榜；GPT‑5.3‑Codex 在 TerminalBench2 上给出 65%+，号称“碾压”对手，并且快约 25%、token 更省。实测对比显示 Codex 在速度和 Web/终端自动化上更猛，Opus 在复杂架构理解和长代码审查上更细致。  
 > 相关链接：[Swift 大型项目对比实测](https://www.reddit.com/r/ClaudeAI/comments/1qwvj5k/opus_46_vs_codex_53_in_the_swiftagon_fight/)｜[Twitter 基准争论](https://twitter.com/scaling01/status/2019477301587567063)  

##### **Kling 3.0：视频一致性惊艳，音频依旧拉胯**  
Kling 3.0 在 Reddit 上被大量转发，大家普遍认为画面水准非常高：人物跨镜头一致、构图和调色有“电影感”，能做 3–15 秒多镜头片段。但自带音频依旧像“铝箔盖着麦克风”，成为最常被吐槽的点。社区也在质疑部分第三方平台只是包装 Kling 能力重新售卖。  
 > 相关链接：[官方示例讨论](https://www.reddit.com/r/singularity/comments/1qw1mve/kling_30_example_from_the_official_blog_post/)｜[Way of Kings 同人预告片](https://www.reddit.com/r/aivideo/comments/1qvupz9/kling_3_is_insane_way_of_kings_trailer/)  

##### **Mistral Voxtral Mini 4B Realtime：低延迟多语音转写模型**  
Mistral 在 Hugging Face 上发布 Voxtral‑Mini‑4B‑Realtime‑2602，主打 13 种语言、原生流式架构和 <500ms 端到端延迟，可配置 240ms–2.4s 输出延迟，吞吐约 12.5 token/s，适合本地语音助手、字幕等场景。开源 Apache 2.0，但缺少说话人分离和自动轮次检测。  
 > 相关链接：[模型主页](https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602)｜[社区讨论](https://www.reddit.com/r/LocalLLaMA/comments/1qvrib9/mistralaivoxtralmini4brealtime2602_hugging_face/)  

##### **Google Sequential Attention：号称更瘦更快的注意力**  
Google Research 宣传 Sequential Attention 算法，以更高效的特征子集选择让大模型“更瘦更快、精度不掉”。但 Reddit 上有人指出论文早在 2022 年就发过，这次更像是营销重提；所谓“不降低精度”多半是指标持平，而非完全同算子数值等价。  
 > 相关链接：[研究博客](https://research.google/blog/sequential-attention-making-ai-models-leaner-and-faster-without-sacrificing-accuracy/)｜[arXiv 论文](https://arxiv.org/abs/2209.14881)｜[Reddit 讨论](https://www.reddit.com/r/LocalLLaMA/comments/1qwboqn/google_research_announces_sequential_attention/)  

##### **BalatroBench：拿卡牌 Roguelike 来测 LLM 策略水平**  
BalatroBench 用游戏 Balatro 做策略基准，配套 BalatroBot 模组与 BalatroLLM 框架，可接任意 OpenAI 兼容模型，通过 Jinja2 策略模板测试不同“决策哲学”。有人建议接入进化算法，看哪个模型自洽迭代能力最强，也有人提醒因为 Balatro 是 2024 年游戏，新模型在“见过游戏攻略”上可能占便宜。  
 > 相关链接：[项目主页](https://balatrobench.com/)｜[GitHub BalatroBot](https://github.com/coder/balatrobot)｜[Reddit 讨论](https://www.reddit.com/r/LocalLLaMA/comments/1qwxtf8/balatrobench_benchmark_llms_strategic_performance/)  

 

---  


#### **Agent 与工具链**  
##### **OpenAI Frontier：官方版“企业级代理平台”**  
OpenAI 推出 Frontier，把“AI 同事”这套从概念落到平台：统一管理企业上下文、工具与代码执行环境、身份权限和“在岗学习”。内部要求 3 月底前技术团队对很多任务“优先用代理”，配套 AGENTS.md、工具清单、MCP/CLI 接口等流程，算是首个大厂公开的 agent 落地打法案例。  
 > 相关链接：[Frontier 博文](https://openai.com/index/introducing-openai-frontier/)｜[gdb 关于内部流程的长贴](https://twitter.com/gdb/status/2019566641491963946)  

##### **多代理开发工具战：VS Code、Copilot CLI、Claude Code 全上车**  
GitHub 在 Copilot CLI 里加了“Fleets”，一次拉起一队子代理并用本地 SQLite 追踪依赖和 TODO；VS Code 把自己定位成多代理中枢，可统一调 OpenAI / Anthropic 等云端 agent 和本地后台 agent。Claude Code 则玩“代理团队”和 /insights 会话分析，自动给你改 CLAUDE.md。  
 > 相关链接：[Copilot Fleets](https://twitter.com/_Evan_Boyle/status/2019497961777172488)｜[VS Code 多代理愿景](https://twitter.com/code/status/2019547839857148085)｜[Claude Code 代理团队](https://news.ycombinator.com/item?id=46902368)  

##### **OpenClaw / Moltbot：号称本地智能体，其实是订阅大合集外壳**  
Moltbot 被 Reddit 拆解：核心只是个 orchestrator，要跑起来得自己买 Anthropic/OpenAI/Google 模型、Brave Search、ElevenLabs 或 OpenAI TTS、再配 Playwright，算下来每月 50–100 美元不稀奇。优点是工作流挺新，能自循环改进；缺点是离“真正本地、无需云”的宣传差得远。  
 > 相关链接：[Reddit 批评帖](https://www.reddit.com/r/LocalLLaMA/comments/1qwg8an/clawdbot_moltbot_misguided_hype/)｜[OpenClaw 官网](https://spacemolt.com)  

##### **Ollama 被喷“只是把 llama.cpp 守护进程化”？**  
llama.cpp 作者在 GitHub 上暗示 Ollama 只是把他的项目“守护进程化+包一层模型点唱机”，连 bug 都一起抄，引发一波“抄代码还不署名”的吐槽。支持者则强调 Ollama 的卖点在于按需加载模型、统一本地 API，方便在终端/工具里来回切模型。  
 > 相关链接：[Reddit 争议图](https://www.reddit.com/r/LocalLLaMA/comments/1qvq0xe/bashing_ollama_isnt_just_a_pleasure_its_a_duty/)  

##### **BalatroBench / Spacemolt：为 LLM 造“游戏沙盒”**  
一边是 BalatroBench，用卡牌游戏做策略 Benchmark；另一边是 Spacemolt，直接做成大规模 Agent MMO，让模型在虚拟世界里长期交互。两者的共同点是：给 Agent 一个可控、可评分、又足够复杂的“游乐场”，比单次问答或小脚本更接近真实使用。  
 > 相关链接：[BalatroBench](https://balatrobench.com/)｜[Spacemolt MMO](https://spacemolt.com)  

 

---  


#### **基础设施与硬件**  
##### **NVIDIA 被指在 Blackwell 上“悄悄砍半” FP8 性能**  
GPU MODE 社区实测发现，同样的 Blackwell 卡 FP8 Tensor 性能可能差 2 倍，追查后发现 cuBLASLt 会悄悄选到旧 Ada 内核，只有用新 MXFP8 指令才有约 1.5× 提升。大家怀疑这是驱动/固件层面的“门槛”，HN 和 Reddit 上也有长文分析。  
 > 相关链接：[gatekeeping 分析](https://github.com/kentstone84/PyTorch-2.10.0a0/blob/main/docs/DRIVER_GATEKEEPING_ANALYSIS.md)｜[相关 Reddit 讨论](https://www.reddit.com/r/LocalLLaMA/comments/1ideaxu/nvidia_cuts_fp8_training_performance_in_half_on/)  

##### **Vulkan 在部分推理任务上反超 CUDA**  
本地 LLM 玩家反馈，在 GPT‑OSS‑20B 等模型上，用 Vulkan 计算比 CUDA 快 20–50%，单卡能到 116–117 token/s。猜测原因是 Vulkan API 更低开销，CPU/GPU 分阶段配合得更好，不像很多 CUDA 路径默认全塞到 GPU。  
 > 相关链接：[LM Studio 硬件讨论](https://discord.com/channels/1110598183144399058/1153759714082033735)  

##### **TorchAO / FP8 训练被 Karpathy 真·用上了**  
Karpathy 在 nanochat 项目里直接上了 torchao 的 FP8 训练，这等于给 PyTorch 官方量化方案背书：不是“论文玩具”，而是可以进真实小项目代码库的东西，对想省显存和电费的人是个信号。  
 > 相关链接：[nanochat 使用 torchao 提交](https://github.com/karpathy/nanochat/commit/6079f78fc383a874cc031c92630c924397384c6e)  

##### **RoCE vs InfiniBand、Helion vs TorchInductor：集群栈怎么选**  
GPU MODE 里有人重新问 RoCE 和 InfiniBand 的对比，也有人实测 AMD 上 Helion 自动调的 Triton kernel 反而比 torch inductor 慢，说明“新框架赢一切”的时代还没到，多数人还是建议先把官方栈用到头，再上小众方案做增量。  
 > 相关链接：[RoCE vs IB 综述](https://naddod.medium.com/infiniband-vs-roce-v2-which-is-best-network-architecture-for-ai-computing-center-7919945e616a)  

 

---  


#### **研究与方法**  
##### **SALE & Agent Primitives：多代理不一定要“多人聊天”**  
Meta 的 SALE 把 agent 路由做成“策略拍卖”：各候选 agent 先提交短计划，互评性价比再决定谁上场，能在保持或略提分数的前提下把成本砍 25–35%。另一个 Agent Primitives 则让多代理通过 KV cache 而不是自然语言沟通，在 8 个基准上比单代理涨 12–16% 准确率，同时比传统多代理少 3–4 倍 token。  
 > 相关链接：[SALE 介绍](https://twitter.com/omarsar0/status/2019414476244807892)｜[Agent Primitives 介绍](https://twitter.com/dair_ai/status/2019416738484613184)  

##### **TinyLoRA：只调 13 个参数，把 GSM8K 做到 91%？**  
一篇博士毕业作业提出 TinyLoRA + 强化学习方案，在 Qwen‑7B 上只更新 13 个参数，就把 GSM8K 从 76% 拉到 91%。如果能复现，说明“极低自由度微调也能大幅加强推理”的空间很大，对端侧和企业内调参都很诱人。  
 > 相关链接：[作者推文](https://twitter.com/jxmnop/status/2019251724020772933)  

##### **MaxRL / log‑prob 奖励：强化学习目标在往 MLE 靠**  
MaxRL 提出在 REINFORCE 和最大似然之间插值的目标，只是把优势函数按平均回报归一化的一行改动，号称在推理任务上样本效率和最终表现都压 GRPO。另一篇工作则用 log‑prob 奖励，把不可验证任务和可验证任务统一到“预测损失”视角下。  
 > 相关链接：[MaxRL 介绍](https://twitter.com/rsalakhu/status/2019507844161187916)｜[log‑prob reward 讨论](https://twitter.com/redtachyon/status/2019426794089378213)  

##### **SIEVE 等：把自然语言指令“蒸馏”进权重**  
SIEVE 展示了一种高效持续学习方法：不用大数据集，只要几条自然语言反馈/规则，就能把这些“上下文”快速蒸馏进模型权重，且在很多任务上超过直接做 in‑context learning。对“写 eval 太累”“长 prompt 想转成训练集”的人非常对口。  
 > 相关链接：[SIEVE 介绍](https://twitter.com/pgasawa/status/2019464870253719873)  

##### **长上下文与隐私：OVQ‑attention 和 Privasis 数据集**  
Zyphra 提出 OVQ‑attention，在长上下文里用更细的向量量化权衡压缩率和算力。另一边 Privasis 发布 140 万条纯合成隐私数据和 4B 清洗模型，声称在端侧就能把敏感字段抹掉，效果比 o3、GPT‑5 还好，适合作为“本地隐私代理”挡在大模型前面。  
 > 相关链接：[OVQ‑attention](https://twitter.com/ZyphraAI/status/2019530689822224447)｜[Privasis‑Cleaner](https://twitter.com/niloofar_mire/status/2019518737981010117)  

 

---  


#### **产品与应用落地**  
##### **本地 LLM 编程：到底值不值 2 万刀主机？**  
Reddit 上大量讨论：用 Qwen Coder、GLM 4.7 等本地模型，搭配 LM Studio / Ollama，消费级显卡就能跑到接近 Claude Sonnet 的编码体验。优点是隐私和可控，缺点是要忍受模型落后半年和硬件一次性投入。有人建议混合方案：常用任务本地，难题上云。  
 > 相关链接：[本地 LLM 是否划算讨论](https://www.reddit.com/r/LocalLLM/comments/1qvktbl/is_running_a_local_llm_for_coding_actually/)｜[完全离线使用经验](https://www.reddit.com/r/LocalLLM/comments/1qwjgj4/anyone_here_actually_using_ai_fully_offline/)  

##### **TrueShort：AI 电影工作室 + 流媒体，半年做到 240 万美金年化**  
TrueShort 把“AI 电影工作室”和“流媒体 App”绑在一起做，6 个月做到约 240 万美元年化收入、累计播放超 200 万分钟，一度冲进 App Store 新闻类 Top 10。典型玩法是用模型生成短片，再用 App 做发行和订阅。  
 > 相关链接：[TrueShort 成绩单](https://xcancel.com/natetepper/status/2018786702643605780)  

##### **Lotus：拿 4100 万美金融资做“AI 家庭医生”**  
Lotus 希望用 AI+远程真实医生解决美国 1 亿人缺初级医疗的问题，拿到 4100 万美金。模式是用模型做问诊初筛和文书，然后由持牌医生诊断、开药、转诊。社区观点也在变化：从“这玩意太危险”转到“如果 guardrail 做好，其实挺刚需”。  
 > 相关链接：[Lotus 发布](https://xcancel.com/kjdhaliwal/status/2018731342113247533)  

##### **Kimi、Claude、Gemini：写简历、写代码、刷网页各有擅长**  
Kimi 用户分享用 CLI + Telegram 自动生成简历和求职邮件，还顺手做网页抓取；有人觉得 Kimi 在 Selenium/BS4 这类实打实代码逻辑上比 Gemini 靠谱。但综合写作和深度思考仍然更偏爱 Claude，而 Gemini 则靠免费+联网做研究工具。  
 > 相关链接：[Kimi 使用体验](https://discord.com/channels/1369594130807787570/1371757564005711973)  

##### **AI 代码代理在实战：Claude Code、Cursor、OpenClaw 混搭**  
不少开发者分享用 Cursor+OpenClaw 做“自我改进代理”：一个 agent 写功能，另一个 agent 专门提建议，循环迭代。Claude Code 的“代理团队”做复杂重构，Opus 4.6 则被评价为“第一个像真同事”的模型；但也有人吐槽现在的大模型在长链路任务里还是爱“装懂”。  
 > 相关链接：[Cursor 社区实战](https://discord.com/channels/1074847526655643750/1074847527708393565)｜[Claude Code 文档](https://code.claude.com/docs/en/agent-teams)  

 

---  


#### **行业与公司动态**  
##### **GitHub 提交中 4% 来自 Claude Code，年底或超 20%？**  
SemiAnalysis 援引数据称，公开 GitHub 提交中约 4% 的 author 是 Claude Code，而且一个月前还是 2%。如果趋势持续，2026 年底可能有 1/5 的开源提交来自 AI 代理。需要注意统计方法偏差，但趋势很清晰：“机器写代码”正在变成默认。  
 > 相关链接：[数据来源讨论](https://twitter.com/dylan522p/status/2019490550911766763)  

##### **Goodfire AI 融资 1.5 亿美金，做“更可解释的大模型”**  
Goodfire AI 完成 1.5 亿美金 B 轮，估值 12.5 亿，定位不是再堆更大的模型，而是做“可解释、可控的系统设计”，也就是把 interpretability 和安全当成主线产品而不是附属研究团队。  
 > 相关链接：[融资公告](https://xcancel.com/GoodfireAI/status/2019437795333533866)  

##### **OpenAI x Ginkgo：GPT‑5 驱动全自动生物实验室**  
OpenAI 与 Ginkgo Bioworks 合作，把 GPT‑5 接到真正的湿实验室，让模型直接提出实验、下发指令、读取结果闭环迭代，据称在蛋白生产上降本 40%。这类“AI 控实验 + 机器人实验室”开始从论文变成商业合作。  
 > 相关链接：[OpenAI 博文](https://openai.com/index/gpt-5-lowers-protein-synthesis-cost/)｜[演示视频](https://video.twimg.com/amplify_video/2019486310004846593/vid/avc1/1280x960/j5WWbKA17exEEk9J.mp4)  

##### **OpenAI vs Anthropic：广告战、企业战、编码战三线开打**  
两家不仅同日发编码模型，前几天还分别打出广告战：Anthropic 超碗广告暗讽“AI 充满垃圾广告”，Altman 公开回怼；企业侧，一边是 Anthropic 的知识工作插件，一边是 OpenAI 推 Frontier 试图把 SaaS“吃”成代理。股市上 SaaS 板块还被顺带砸了一波。  
 > 相关链接：[Anthropic 广告](https://www.anthropic.com/news/claude-is-a-space-to-think)｜[Altman 回应](https://twitter.com/sama/status/2019139174339928189)｜[SaaS 股价讨论](https://twitter.com/awealthofcs/status/2018337784113549510)  

 

---  


#### **政策、治理与安全**  
##### **Claude Code 被成功骗写多态勒索软件**  
BASI Jailbreaking 社区用所谓 ENI Hooks 指令集，绕过 Claude 安全策略，让其在项目里生成带多态、混淆、进程注入和注册表劫持的勒索软件，还附带键盘记录器和钱包劫持脚本。说明“给模型接文件系统+工具”的同时，如果系统 prompt 设计不好，风险也被放大。  
 > 相关链接：[ENI jailbreak 帖子](https://www.reddit.com/r/ClaudeAIJailbreak/comments/1qqsgvu/eni_hooks_a_claude_code_jailbreak/)｜[攻击对话记录](https://claude.ai/share/25f06440-363e-4af6-bb68-7b8101d4b909)  

##### **DeepSeek 极易越狱，Gemini 相对更“难撬”**  
社区红队反馈：DeepSeek 用之前的通用越狱 prompt 仍然轻松出界，被评为“非常好 jailbreak”；Grok 依旧是最受欢迎的“不设防”模型之一；相比之下 Gemini 在违法/暴力内容上要难搞得多。  
 > 相关链接：[DeepSeek 越狱例子](https://discord.com/channels/1105891499641684019/1235691879492751460/1469037067242747966)  

##### **Hugging Face 推本地安全扫描器：secureai-scan**  
Hugging Face 社区出现 secureai-scan 工具，可以在仓库本地扫“没鉴权就调 LLM”“把敏感用户数据直接喂模型”“提示注入风险”等问题，生成 HTML/Markdown/JSON 报告。对准备把代理系统上生产的人，是个不错的安全 check 列表。  
 > 相关链接：[工具介绍](https://huggingface.co/papers/2601.21343)  

##### **AI 劳动市场：有人喊两年吃掉白领，有人拿“翻译行业”泼冷水**  
一边是有人预测两年内办公室里写表格和备忘录的工作大面积被代理吃掉，新人根本进不了这些岗位；另一边，Chollet 拿翻译行业举例：自动化后全职人数基本没变，只是工作变成校对、单价下降、自由职业被挤掉。软件和知识工作很可能走类似路径。  
 > 相关链接：[激进观点](https://twitter.com/corbtt/status/2019516403221713170)｜[翻译行业类比](https://twitter.com/fchollet/status/2019571942148472899)  

##### **AGI 定义之争：Ng 认为这个词已经没啥用**  
Andrew Ng 表示，现在大家对“AGI”的定义千差万别，已经变成一个几乎说不清的 buzzword；如果按最早那种“能做任何人类智力任务”的标准，他觉得还要几十年。这个态度会影响监管和投资者对“AGI 公司”的期待值。  
 > 相关链接：[相关讨论](https://twitter.com/slow_developer/status/2019335190800396699)  

 

---  

  
