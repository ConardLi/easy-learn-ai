#### **产品与应用落地**  
##### **OpenAI 上线 ChatGPT Go，开始在免费与低价档测试广告**  
OpenAI 在全球推出低价档 **ChatGPT Go**（8 美元/月），比免费版多 10 倍消息、支持文件上传、画图、更长记忆和上下文，并可不限量使用 GPT‑5.2 instant。同时宣布将在 Free 和 Go 档测试广告，付费 Plus/Pro/Business/Enterprise 仍无广告。  
 > 相关链接：[ChatGPT Go 介绍](https://openai.com/index/introducing-chatgpt-go/)｜[OpenAI 广告原则说明](https://openai.com/index/our-approach-to-advertising-and-expanding-access/)｜[OpenAI Ads 公告推文](https://twitter.com/OpenAI/status/2012223373489614951)｜[Go 计划公告推文](https://twitter.com/OpenAI/status/2012223323812270219)  

##### **Claude Cowork 向 Pro 用户开放，实际用量压力不小**  
Anthropic 宣布 Claude Cowork 面向 Pro 用户开放（仍是研究预览），支持会话重命名、连接器优化等。但有用户反馈，用 Cowork 批量整理 400 多个文件就耗尽 97% 会话额度，认为当前用量上限对复杂任务仍偏紧。  
 > 相关链接：[Reddit 讨论贴](https://www.reddit.com/r/ClaudeAI/comments/1qeo736/official_claude_cowork_is_now_available_to_pro/)  

##### **Gemini 3 Pro 被开发者吐槽“用不动了”，疑似缩小上下文窗口**  
不少 Pro 用户称 Gemini 3 Pro 近期性能明显变差：长项目里频繁答非所问、代码乱串，有人怀疑 Google 私下缩短了上下文窗口导致幻觉增加。部分重度用户开始转向 GPT‑5.2 Thinking、Claude 等替代方案。  
 > 相关链接：[Reddit 反馈](https://www.reddit.com/r/GeminiAI/comments/1qemf0h/today_gemini_3_pro_became_unusable_to_me_as_a_pro/)  

##### **Perplexity Pro 每日 100 次高级对话被嫌太少**  
Perplexity Pro 把高级模型请求限制在每天 100 条，不少重度用户反映几小时就打满配额，之后一整天基本废掉，开始考虑退订或换到 OpenAI 等按 token 计费方案。  
 > 相关链接：[Perplexity Discord 讨论](https://discord.com/channels/1047197230748151888/1047649527299055688)  

##### **Cursor、Qoder、Gemini CLI 等“智能 IDE/CLI”被指烧钱严重**  
多名用户分享账单：Cursor Ultra 单次 orchestrator 运行就吃掉 20% 配额，Qoder 月账单接近 400 美元，Gemini CLI 一天跑掉 1000 万 token 约 120 美元。大家呼吁 IDE 和平台提供更清晰的用量统计、上限控制和“子代理用小模型、主代理用大模型”的配置能力。  
 > 相关链接：[Cursor 社区讨论](https://discord.com/channels/1074847526655643750/1074847527708393565)｜[Perplexity / Gemini CLI 讨论](https://discord.com/channels/1047197230748151888/1047649527299055688)  

##### **LMArena 新增 PDF 对话与图像模型榜单更新**  
LMArena 正测试上传 PDF 后直接聊天的功能，部分模型已支持。图像编辑与文生图榜单也更新，FLUX.2 klein 系列在中高名次区间占位，显示小模型图像质量在快速追赶。  
 > 相关链接：[Image Edit 排行](https://lmarena.ai/leaderboard/image-edit)｜[Text-to-Image 排行](https://lmarena.ai/leaderboard/text-to-image)｜[Leaderboard 更新日志](https://lmarena.ai/blog/leaderboard-changelog/)  

##### **Hawk Ultra 被社区吹成“Opus 杀手”的代码喷射机**  
Movement Labs 的 Hawk Ultra 在 LMArena 等社区被疯狂安利：单次 prompt 就能生成 9k–2 万行代码，适合一口气搭出工程骨架。大家关心它和 Gemini 3 Pro、Claude Opus 对比如何，以及是否有开源计划。  
 > 相关链接：[Movement Labs X 介绍](https://x.com/movementlabsAI/status/2011964766533632380)  

 

---  


#### **模型与能力**  
##### **OpenAI 预告“Very fast Codex”，强调记忆升级与速度/智能权衡**  
Sam Altman 提到 ChatGPT 记忆有改进，并多次暗示“Very fast Codex 要来了”。开发者讨论：当模型足够快时，工作流会从“慢模型一步到位”转向“高速模型+人类牧羊式多轮调度”。  
 > 相关链接：[Altman 关于记忆与 Codex 的推文](https://twitter.com/sama/status/2012243893744443706)  

##### **Codex CLI 支持接入开源权重和更长上下文**  
Ollama 宣布开源模型可以通过 Codex CLI 以 `codex --oss` 使用，并建议把上下文上限调到 32K 以上提升体验。Codex 还在试验新交互：支持在模型思考中途“插话”调整方向，而不强制中断回复。  
 > 相关链接：[Ollama 关于 Codex OSS 支持](https://twitter.com/ollama/status/2012046176267440177)｜[上下文长度说明](https://twitter.com/ollama/status/2012049822484750426)  

##### **SWE-rebench 最新榜：Claude 4.5 继续领先，GLM‑4.7 成最强开源**  
SWE‑rebench 2025 年 12 月榜单测了 48 个新 GitHub PR 任务：Claude Opus 4.5 解决率 63.3% 第一，GPT‑5.2 xhigh 61.5% 紧随其后。Gemini 3 Flash Preview 以更小更便宜的体量，跑赢自家 Pro。GLM‑4.7 是榜单最强开源模型，接近 GPT‑5.1‑codex 水平。  
 > 相关链接：[Reddit 榜单总结](https://www.reddit.com/r/LocalLLaMA/comments/1qefa7q/gpt52_xhigh_glm47_kimi_k2_thinking_deepseek_v32/)｜[SWE‑rebench 官网](https://swe-rebench.com/?insight=dec_2025)  

##### **长上下文训练：Unsloth 把 RL 上下文做到了几十万 tokens**  
Unsloth 宣称通过数据迁移和新批处理算法，可在 24GB 显存上用 RL 训练到 20K 上下文，在 192GB B200 上最高到 380K，上下文扩展 7–12 倍且不降精度。社区一边关心数据是否真的有这么长，一边在问这些技巧能否迁移到 Qwen3 30B 等模型。  
 > 相关链接：[Reddit 讨论贴](https://www.reddit.com/r/LocalLLaMA/comments/1qdna3t/7x_longer_context_reinforcement_learning_in/)｜[Unsloth 上下文文档](https://unsloth.ai/docs/basics/continued-pretraining)  

##### **Zhipu & 华为发布 GLM‑Image：在国产 Ascend 910 上训练的多模态模型**  
Zhipu 与华为联合推出多模态模型 GLM‑Image，全程在昇腾 910 上训练，支持 1024–2048 分辨率无需额外训练，主打中文文字渲染和图文生成，声称在“每焦耳 token 数”上比 NVIDIA H200 高约 60%。API 定价约 0.1 元一张图。  
 > 相关链接：[Reddit 讨论](https://www.reddit.com/r/MachineLearning/comments/1qeakhz/r_china_just_released_first_sota_multimodal_model/)  

##### **VoxCPM：开源“无 token 化”实时语音克隆 TTS**  
OpenBMB 开源 VoxCPM 语音模型，宣称直接生成连续语音波形而不是离散音频 token，减少格子感和延迟。支持 LoRA 微调，在一张 4090 上流式推理实时系数约 0.15，对想做语音智能体的人很有吸引力。  
 > 相关链接：[VoxCPM 推文与仓库链接](https://twitter.com/LiorOnAI/status/2012133013967044755)  

##### **Translate Gemma 正式上线，多语翻译模型可在 Hugging Face 直接拉**  
Google 的 Translate Gemma 因支持包括马拉雅拉姆语在内的多语种而被广泛讨论。官方在 Hugging Face 上发布了完整集合，Ollama 也已接入并给出推荐提示格式，方便直接塞进翻译流水线。  
 > 相关链接：[Translate Gemma 集合](https://huggingface.co/collections/google/translategemma)｜[Jeff Dean 点评](https://twitter.com/JeffDean/status/2012178747076591820)｜[Ollama 集成](https://twitter.com/ollama/status/2012307436284395692)  

##### **OpenBMB AIR：把偏好数据拆成 A/I/R 三块来做对齐**  
OpenBMB 提出 AIR 框架，把偏好数据拆成 Annotation / Instruction / Response，主张用简单打分、过滤方差大的指令、控制样本差距，称用 1.4 万条精炼样本在 6 个基准上平均提升 5.3 分。  
 > 相关链接：[AIR 框架推文](https://twitter.com/OpenBMB/status/2012179938388926679)  

 

---  


#### **Agent 与工具链**  
##### **“人类在环”再次被证明是可靠性倍增器**  
多位工程师复盘后发现：同样的模型，完全自动跑经常翻车，而拉一个人做“保姆”把不确定结果拦下来，整体体验好很多。有人用两条曲线之间的差解释：这部分就是人类在环带来的价值。  
 > 相关链接：[关于 human-in-the-loop 的讨论](https://twitter.com/lateinteraction/status/2012030585926189148)｜[价值曲线解读](https://twitter.com/dbreunig/status/2012200587211821410)  

##### **“chunk 已死”？Jerry Liu 主张文件工具优先于传统 RAG**  
LlamaIndex 创始人 Jerry Liu 认为 RAG 本身没死，但死的是固定切块+向量库那套；在几百份文档规模内，让 agent 直接打开文件、用 ls/grep 搜索并按需展开上下文，往往比提前切块嵌入更稳更简单。规模再大才需要数据库。  
 > 相关链接：[文件优先检索长帖](https://twitter.com/jerryjliu0/status/2012273236042559802)  

##### **Claude、OpenRouter 等支持一次请求并行多工具调用**  
Anthropic 文档显示 Claude 已能在一次 API 调用中调多工具，并支持并行 tool use 控制。OpenRouter 社区认为这会显著减少多轮来回，降低延迟和费用，是 agent 编排层的一个重要能力点。  
 > 相关链接：[Claude 工具调用文档](https://platform.claude.com/docs/en/agents-and-tools/tool-use/implement-tool-use#controlling-claudes-output)  

##### **各种 Agent 编排 UI/CLI 快速冒头**  
Anthropic Cowork、SpecStory CLI、sled UI、OpenWork 本地电脑代理等纷纷上线：有人做统一记录 agent 会话与合同的 CLI，有人做“把 Claude Code/Codex 瞬移到手机”的 UI，还有人集成 Ollama，在 Mac 上跑全本地电脑控制 agent。  
 > 相关链接：[SpecStory CLI 介绍](https://twitter.com/doesdatmaksense/status/2012209297380544940)｜[sled / Agent Control Protocol](https://twitter.com/dctanner/status/2012212217677070796)｜[OpenWork 本地 agent](https://twitter.com/_orcaman/status/2012210613712281646)  

##### **Claude Flow v3 自称能把 Claude Max 用量“榨出 2.5 倍”，社区半信半疑**  
社区项目 Claude Flow v3 号称用 TypeScript+WASM 重写，做多代理 swarm、共享记忆、离线执行，把 Claude Max token 消耗降 75–80%，等于订阅容量提升 2.5 倍。评论区有人直指营销词堆砌严重，缺乏清晰基准和复现实验。  
 > 相关链接：[Claude Flow v3 介绍](https://www.reddit.com/r/ClaudeAI/comments/1qegsta/announcing_claude_flow_v3_a_full_rebuild_with_a/)｜[GitHub 仓库](https://github.com/ruvnet/claude-flow)  

 

---  


#### **基础设施与硬件**  
##### **“训练已过巅峰，真正痛点在推理”：一年被称为“推理爆炸年”**  
一篇被广转的知乎长帖认为：agent 提高了 I/O 比例，prefill 成为主成本；上下文缓存会变成标配；prefill/decoding 分离把设备利用率搞得更差，必须重做调度和内存层级。整体观点：现在优化重点已从训练转向推理系统工程。  
 > 相关链接：[推理爆炸讨论摘要](https://twitter.com/ZhihuFrontier/status/2012080310981374428)  

##### **SambaNova SN40L 跑 DeepSeek R1，在吞吐和延迟上压了一头 NVIDIA 集群**  
Artificial Analysis 把 DeepSeek R1 跑上 SambaNova SN40L，对比多种 NVIDIA 配置后发现：在高并发时 SN40L 吞吐更高，单用户 token/s 峰值约 269。因为官方没给按小时价格，性价比暂时不好直接算，但说明非 NVIDIA 方案在推理侧已有竞争力。  
 > 相关链接：[DeepSeek R1 on SN40L 基准](https://twitter.com/ArtificialAnlys/status/2012233319891824943)  

##### **Epoch AI：全球 AI 数据中心总装机功率已接近 30GW**  
Epoch AI 粗算：按 GPU 销量乘额定功率再乘 2.5 倍机房系数，当前 AI 数据中心装机容量约 30GW，和纽约州夏季用电峰值差不多。注意这算的是“能耗上限”，不代表长期实际负载。  
 > 相关链接：[Epoch AI 估算贴](https://twitter.com/EpochAIResearch/status/2012303496465498490)  

##### **CUDA/ROCm 内核工程师：从 CuTe tiling 到 gfx942 一致性坑**  
工程圈在热聊新一代 tiling 抽象：NVIDIA 的 CuTe/cuTile 能用更简洁的 block 级代码逼近 cuBLAS 性能，还改进了 swizzling。AMD 这边则在研究 gfx942 的多 L2 一致性，需要用 `buffer_inv sc1` 手动清非本地 L2，否则多 XCD+HBM 会出现鬼一样的缓存错误。  
 > 相关链接：[CuTe/CUDA Tile 讨论](https://twitter.com/TheTuringPost/status/2012288767894360215)｜[ROCm gfx942 内存模型文档](https://rocm.docs.amd.com/projects/llvm-project/en/latest/LLVM/llvm/html/AMDGPUUsage.html#memory-model-gfx942)  

##### **PCIe 与电源管理对推理性能影响远比很多人以为的大**  
LM Studio 用户发现 3090 插在 Gen3 x1 槽上推理从 120t/s 掉到 90t/s；GPU MODE 指出 benchmark 中 `sleep(2s)` 会导致 GPU 降频，测到的时延全是“热身成本”。结论：测性能前先检查主板走线和功耗策略，不然白优化模型。  
 > 相关链接：[LM Studio 带宽案例](https://discord.com/channels/1110598183144399058/1153759714082033735)｜[GPU MODE benchmark 讨论](https://discord.com/channels/1189498204333543425/1189607726595194971)  

##### **消费级/二手机 GPU 市场：A100 捡垃圾、RTX 5060Ti 16GB 宣布停产**  
LocalLLaMA 社区有人 500 美元淘到“坏卡”A100 40GB 结果完好，用来跑大模型但被提醒要加主动散热；另一边传出 RTX 5070Ti 停产、5060Ti 16GB 大幅减产，导致 16GB 版本涨价，这块原本是便宜堆显存、跑 70B 模型的选择。  
 > 相关链接：[A100 升级晒机](https://www.reddit.com/r/LocalLLaMA/comments/1qe0cxc/latest_upgradea100_40_gb/)｜[5060Ti 16GB 供应缩减](https://www.reddit.com/r/LocalLLaMA/comments/1qdh28f/rtx_5070_ti_and_rtx_5060_ti_16_gb_no_longer/)  

 

---  


#### **研究与方法**  
##### **Mamba‑2 为吃满 Tensor Core 重写核心算法，RetNet 被微软“弃坑”**  
一篇长文分析：Mamba‑2 把原先并行 scan 改成 block 对角 GEMM，把 Tensor Core 利用率从 10–20% 拉到 60–70%，算是向 NVIDIA 硬件妥协。相对地，微软 2023 发的 RetNet 很快被自家 Phi 系列的密集 Transformer 取代，显示“架构+硬件+公司资源”共同形成强力锁定，想脱离 Transformer 阵营很难。  
 > 相关链接：[Transformer Attractor 长文](https://open.substack.com/pub/lambpetros/p/the-transformer-attractor)｜[Reddit 讨论](https://www.reddit.com/r/MachineLearning/comments/1qehwlu/d_why_mamba_rewrote_its_core_algorithm_and/)  

##### **多向量检索回潮：小模型 + 多向量能打大模型**  
多位检索研究者分享实验：用 ColBERT/ColPali 一类的多向量检索，一个 3200 万参数模型配多向量，就能逼近 8B 模型的效果。有人甚至放话“multi‑vector 是唯一出路”，理由是把复杂性放到索引结构上，比盲目放大模型更划算。  
 > 相关链接：[aaxsh 多向量实验](https://twitter.com/aaxsh18/status/2012124348392583584)  

##### **信息引力 + 滞回防火墙：有人试图从物理隐喻来治理幻觉**  
GPU MODE 社区有人提出“Information Gravity”理论：把 token 选择过程看成激发流，激发度 S>45 时系统进入线性爆炸导致幻觉循环，于是在 S=1.0 处加“滞回防火墙”，以 2.2×gamma flush 强制重置状态。暂时更像思想实验，但代表大家在尝试新角度理解稳定性问题。  
 > 相关链接：[Information Gravity GitHub](https://github.com/brayo003/Substrate-X-Theory-of-Information-Gravity)  

##### **MMLU‑Pro 数据集和评测框架修复，提醒大家别再拿旧分数比较**  
Eleuther 发布补丁修正 TIGER‑Lab/MMLU‑Pro 的问题，并在 lm‑evaluation‑harness 中更新。之前用旧 harness 跑的 MMLU‑Pro 分数可能有偏差，想做横向对比的需要重跑一遍。  
 > 相关链接：[lm‑evaluation‑harness PR](https://github.com/EleutherAI/lm-evaluation-harness/pull/3500)｜[MMLU‑Pro 数据集讨论](https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro/discussions/41)  

 

---  


#### **行业与公司动态**  
##### **OpenAI 把 9 亿周活用户货币化：广告 + 更多订阅档成主线**  
在外界长期吐槽“迟早要上广告”后，OpenAI 终于宣布在 ChatGPT 免费与 Go 档测试广告，并推出更细分的订阅梯度。有评论把这视作从“研究公司”向传统互联网广告/订阅混合模式的彻底转身。  
 > 相关链接：[Ads 公告](https://twitter.com/OpenAI/status/2012223373489614951)｜[外界评论示例](https://twitter.com/tomwarren/status/2012295849678602610)  

##### **Higgsfield AI 9 个月做到 2 亿美金年化收入，融资 1.3 亿美金**  
视频生成创业公司 Higgsfield 宣布完成 1.3 亿美元 A 轮，估值 13 亿美元，自称上线不到 9 个月就做到 2 亿美元年化收入，属于少见的“早期即高营收” AI 公司。  
 > 相关链接：[Higgsfield X 公告](https://x.com/higgsfield_ai/status/2011866396784017848)  

##### **税务自动化创业公司获 350 万美元种子轮，想“干掉报税季”**  
Saket Kumar 创立的新公司获得 General Catalyst 等 350 万美元种子融资，目标是让美国个人报税变成“免费且一键完成”。他们计划大量使用 AI 自动读取和生成报税表，直接挑战现有报税软件和代报税行业。  
 > 相关链接：[创始人推文](https://xcancel.com/saketrkumar/status/2011836460400591330)  

##### **Anthropic 发布第 4 期《经济指数》，尝试用“经济原语”量化 AI 影响**  
Anthropic 新报告把 AI 使用拆成任务复杂度、教育水平、自治程度、成功率等“经济原语”，试图比简单的“多少岗位可被自动化”更细地描述 AI 对劳动市场的冲击和替代/增强关系。  
 > 相关链接：[Economic Index 原文](https://www.anthropic.com/research/economic-index-primitives)  

 

---  


#### **政策、治理与安全**  
##### **OpenAI 广告原则：不改回答、不泄露对话，但大家更担心长期激励漂移**  
OpenAI 承诺 ChatGPT 的回答不会被广告商影响，广告会清晰标注，对话内容不会给广告主用。社区一边表示这套说法“现在看起来是对的”，一边担心，随着营收压力增大，未来会不会在推荐顺序、默认工具等细节上慢慢向广告倾斜。  
 > 相关链接：[广告与隐私原则](https://openai.com/index/our-approach-to-advertising-and-expanding-access/)｜[Sam Altman 关于广告的补充推文](https://twitter.com/sama/status/2012253252771824074)  

##### **BASI 社区疯狂研究主流模型越狱与安全绕过，新技巧每天都在被封堵**  
BASI Jailbreaking Discord 汇总了一堆越狱方法：Gemini 的 NSFW 越狱“免费但活不久”，Grok 被称为最野的模型之一；有人对 Meta Llama3 做拒绝反转，让它从“我不能”变成“我可以”；还分享通过“冷链接”和 OCR 注入绕过 URL/文本过滤的办法。模型厂商则在持续封堵这些洞。  
 > 相关链接：[BASI Jailbreaking 服务器](https://discord.com/channels/1105891499641684019)  

##### **利用 ZKP 做“隐私友好型”AI 内容审查的设想**  
Yannick Kilcher 服务器有人提出，用零知识证明做 AI 治理：先用统一的内容分类模型判断是否违规，再用 ZKP 证明“这段内容已经过审核且结果安全”，但不透露内容本身。这样平台可以强制只运行通过审核的模型/应用，同时不窥探用户具体说了什么。  
 > 相关链接：[治理思路讨论](https://discord.com/channels/714501525455634453/986699377257119794)  

##### **机器意识被搬上 AAAI 正式议程：2026 年将办专门研讨会**  
Nous 社区转发：AAAI 2026 将由 CIMC 主办“机器意识”专题研讨会，讨论怎么定义与检测 AI 意识、如何区分行为表象和内部状态，以及伦理后果。投稿截止 1 月 23 日，主办方强调希望看到具体可操作的方法，而不是哲学空谈。  
 > 相关链接：[研讨会说明](https://cimcai.substack.com/p/essay-the-machine-consciousness-hypothesis)  

 

---  

  
