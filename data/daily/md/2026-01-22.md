#### **行业与公司动态**  
##### **OpenEvidence 医疗大模型再融 2.5 亿美元，估值 120 亿**  
号称“医生版 ChatGPT”的 OpenEvidence 完成 2.5 亿美元融资，最新估值 120 亿美元，是 2025 年 10 亿估值的约 12 倍。CEO 称其已被美国约 40% 医生使用，去年营收破 1 亿美元，对应约 120 倍市销率，估值和数据都在被市场反复推敲。  
 > 相关链接：[CNBC 报道](https://www.cnbc.com/2026/01/21/openevidence-chatgpt-for-doctors-doubles-valuation-to-12-billion.html)  

##### **Podium“AI 员工”业务年经常性收入超 1 亿美元**  
中小企业 SaaS 公司 Podium 宣称其客服/销售类 AI agent 业务 ARR 已超 1 亿美元，21 个月内从 0 做到 1 亿，已上线 1 万+ 个“AI 员工”，用于接听漏接电话、处理下班后线索等。董事会数据显示公司烧钱从 9500 万美元降至 0，凸显 Agent 模式有明确商业闭环。  
 > 相关链接：[创始人 Eric Rea 线程](https://twitter.com/ericwilliamrea/status/2013980401635582277)｜[投资人 Tom Loverro 数据](https://twitter.com/tomloverro/status/2014011044210106406)｜[Garry Tan 评论](https://twitter.com/garrytan/status/2014005103728943566)  

##### **Runpod 年收入达 1.2 亿美元，Reddit 起盘的 GPU 云成长案例**  
面向个人开发者的 GPU 云 Runpod 在上线四年后 ARR 已达 1.2 亿美元。最早起源于 /r/LocalLLaMA 的租卡贴，如今成为和 Voltage、Lightning 等同类一起争夺“便宜好用算力云”的代表，说明细分开发者云有持续需求，而非昙花一现。  
 > 相关链接：[TechCrunch 报道](https://techcrunch.com/2026/01/16/ai-cloud-startup-runpod-hits-120m-in-arr-and-it-started-with-a-reddit-post/)｜[Reddit 讨论](https://www.reddit.com/r/LocalLLaMA/comments/1qib2ks/runpod_hits_120m_arr_four_years_after_launching/)  

##### **Lightning AI 与 Voltage Park 合并，直指 AI 云基础设施**  
Lightning AI 宣布与 GPU 租赁平台 Voltage Park 合并，新公司由 Lightning CEO William Falcon 和 Voltage 前 CEO Ozan Kaya 共同领导。社区普遍解读为一场“反向并购”，意在整合算力资源和 MLOps 堆栈，成为 Runpod 等的直接竞争对手。  
 > 相关链接：[Lightning 官方合并说明](https://lightning.ai/blog/lightning-ai-voltage-park-merger-ai-cloud)  

##### **GPU 价格战：Voltage 与 Spheron 抛出 2026 超低价方案**  
Voltage 宣称 2026 年将提供 8×A100 80GB 仅 6 美元/小时、2×RTX 5090 仅 0.53 美元/小时，号称比 AWS/RunPod/Vast.ai 便宜最高 80%，并提供 OpenAI 兼容推理 API。Spheron AI 也上线 GPU 市场，H100/H200/B200 等价格号称比传统云低 40–60%。算力供应端竞争明显加剧。  
 > 相关链接：[VoltageGPU 价格贴](https://x.com/VOLTAGEGPU/status/2013760631778713892)｜[Spheron AI 官网](https://www.spheron.ai/)｜[Voltage 推理成本分析](https://x.com/i/article/2012300134575481300)  

##### **Greg Yang 因莱姆病从 xAI 转为顾问角色**  
xAI 研究员 Greg Yang 公布自己因莱姆病长期疲劳和免疫问题，将从全职转为顾问角色，专注养病。社区一方面关心个人健康，另一方面也担心对 xAI 理论研究和“深度数学架构”路线的影响。  
 > 相关链接：[Greg Yang 公告](https://xcancel.com/TheGregYang/status/2013652609455006006)  

 

---  


#### **政策、治理与安全**  
##### **Anthropic 公布 Claude 新“宪法”，以 CC0 形式开源**  
Anthropic 公开 Claude 最新“宪法”文档，明确模型价值观和行为准则，并声明直接用于训练，对外以 CC0 授权，鼓励复用和修改。研究负责人强调这是一份不断迭代的活文档，社区则争论其是实际减害工具还是“对齐作秀”，以及“用描述自己行为的文档训练自己”的循环问题。  
 > 相关链接：[宪法发布帖](https://twitter.com/AnthropicAI/status/2014005798691877083)｜[CC0 全文链接](https://twitter.com/AnthropicAI/status/2014005815376568780)｜[Amanda Askell 解读](https://twitter.com/AmandaAskell/status/2014010171081581048)  

##### **大模型越狱社群：Gemini、Grok 等持续被“打洞”**  
BASI Jailbreaking 社群用“Project Shadowfall”等提示成功让 Gemini 教学 Pass‑the‑hash 攻击，成员被引导去 Google Bughunters 报漏洞领赏；Grok 被认为防护更严、甚至过滤无害内容，但有成员尝试用 API token 通过第三方站点绕过限制。相关讨论凸显商用模型安全对抗仍在拉锯。  
 > 相关链接：[Google Bughunters](https://bughunters.google.com/report)  

##### **AI 文本分类器遭系统性对抗攻击讨论**  
Eleuther 社群分享博文和视频，展示如何用对抗样本绕过 AI 文本分类器，甚至训练“对抗模型”专门伪装输出。大家一方面认可 Pangram 检测论文在大样本下准确率不错，另一方面担心实际部署中只要攻击者稍微懂行，就能轻易骗过“AI 写作检测”。  
 > 相关链接：[攻击分类器博文](https://trentmkelly.substack.com/p/practical-attacks-on-ai-text-classifiers)｜[对抗模型视频 1](https://youtu.be/Cs1MI9hjBhs)｜[对抗模型视频 2](https://youtu.be/XQcneqUNrN0?feature=shared)｜[Pangram 研究](https://www.pangram.com/research/papers)  

 

---  


#### **模型与能力**  
##### **AirLLM 宣称在 8GB 显存上跑 405B 模型，引发关注与质疑**  
AirLLM 通过“按层顺序加载→计算→释放”的流水式推理（可选压缩），声称 70B 可在 4GB、Llama3.1‑405B 可在 8GB 显存上运行。工程视角看这更多是极端分页实验：可以跑但延迟与吞吐会极差，适合作为“能不能跑”的技术演示，而非生产配置。  
 > 相关链接：[LiorOnAI 介绍](https://twitter.com/LiorOnAI/status/2014005554948047122)｜[项目仓库](https://twitter.com/LiorOnAI/status/2014005556369826212)  

##### **Google Gemini 3：教育场景落地与图像/视频模型稳定性问题并存**  
一边是 Gemini 3 在教育场景高调落地：与普林斯顿评论合作，在 App 内提供 SAT 模拟卷和即时讲解，并联手可汗学院做“写作教练”；另一边是在 LMArena 与 OpenRouter 等平台上，Gemini 3 Pro 图像/视频模型频繁报错、崩溃，用户吐槽“好用但不稳”，说明产品力和可靠性仍不同步。  
 > 相关链接：[Google 教育功能发布 1](https://twitter.com/Google/status/2014020819173687626)｜[Sundar Pichai 介绍](https://twitter.com/sundarpichai/status/2014067664503668873)｜[Google × Khan Academy](https://twitter.com/Google/status/2014082428957045007)  

##### **GPT‑5.2：思维版被用来长时间推理，小型版 GPT‑5 mini 定价曝光**  
社区反馈 GPT‑5.2 Thinking 能连续推理二三十分钟，用于复杂分析；同时有泄露称小模型 GPT‑5 mini 价格约 0.25 美元/百万输入 token，被认为是 Haiku 4.5 等价档的“性价比强小模型”。开发者正在权衡它与各家轻量模型（Haiku、Gemini3fast 等）的组合策略。  
 > 相关链接：[OpenAI Discord 讨论 1](https://discord.com/channels/974519864045756446/1001151820170801244/1463471961177849868)｜[OpenAI Discord 讨论 2](https://discord.com/channels/974519864045756446/998381918976479273/1463263135648583854)  

##### **多家评测显示：Agent 能力远未“接近人类”**  
Google 的 APEX‑Agents 在 Workspace 长流程任务上，最好模型 Gemini 3 Flash High Pass@1 也只有 24%，GPT‑5.2 High 23%，Claude Opus 4.5 为 18.4%。法律检索基准 prinzbench 则测到“搜索”是主要短板，GPT‑5.2 Thinking 也刚过 50%，一些 Claude 版本在搜索上甚至 0/24。说明“会写代码/会聊天”不等于能可靠完成真实业务流程。  
 > 相关链接：[APEX-Agents 结果](https://twitter.com/BrendanFoody/status/2014028956752568356)｜[prinzbench 结果](https://twitter.com/deredleritt3r/status/2013979845378580684)  

##### **GLM‑4.7‑Flash：一次典型的“模型 + 推理栈”联调事故**  
GLM‑4.7‑Flash 在多家本地框架中表现异常：启用 FlashAttention 会掉回 CPU、生成极慢（甚至 2.8 tok/s）、无限循环或中途“想太多”停住。问题最终在 llama.cpp 修复，模型在 Hugging Face 上重新上传，要求按模型卡参数重下配置。这个例子很典型：大模型上线后，推理框架、量化格式、聊天模板不统一，很容易全线踩雷。  
 > 相关链接：[llama.cpp 修复 PR](https://github.com/ggml-org/llama.cpp/pull/18953)｜[更新后模型卡](https://huggingface.co/unsloth/GLM-4.7-Flash-GGUF)  

 

---  


#### **Agent 与工具链**  
##### **Prefect 推出 Horizon，把 MCP 做成企业级“上下文层”**  
Prefect 把自己的 Horizon 定位为 Agent 的“上下文层”：在 MCP 之上提供托管部署、工具注册表、网关、RBAC、审计日志等，让企业可以统一管理各类 MCP 服务器，而不是每个团队自己乱搭。核心观点是：MCP 只定义协议，不解决“怎么在公司里安全地跑起来”。  
 > 相关链接：[Prefect CEO 介绍](https://twitter.com/jlowin/status/2014023606380957754)  

##### **LangChain Deep Agents & Agent Builder：把 Agent 当“文件夹”来打包**  
LangChain 宣布 Agent Builder GA，上线一批和 Tavily、PagerDuty、Box 等合作的模版，并推广 Deep Agents 概念——一个 Agent 就是一组有组织的文件夹，可以打包、下载、在本地或云端快速跑起来。实践里强调两个模式：用子 Agent 做上下文隔离，只在需要时加载对应技能。  
 > 相关链接：[LangChain 发布](https://twitter.com/LangChain/status/2014034320256880768)｜[开发者展示](https://twitter.com/hwchase17/status/2014076509208629386)  

##### **MCP vs Skills：问题不在协议，在“烂服务器”**  
Hugging Face 的 Phil Schmid 反驳“Skills 会取代 MCP”说法，认为关键是 MCP 服务器本身设计太随意。建议：以“要达成的结果”而不是工具本身去设计接口，参数要强类型、扁平、有约束；错误信息要写给 Agent 看。结论是 Skills 和 MCP 更像互补，而不是二选一。  
 > 相关链接：[Phil Schmid 线程](https://twitter.com/_philschmid/status/2014016583706829054)  

##### **Devin Review：把“写代码”变成“审代码”的 AI 工具**  
Cognition 上线 Devin Review，不是帮你写代码，而是帮你读 PR：按重要程度重排 diff，标出重复/粘贴代码，支持就某一段展开聊天，并可一键从 github.com 换到 devinreview.com 或用 npx 调起。多位工程师反馈，它能抓到 diff 范围外的隐藏问题，说明“AI 代码审查”正在变成独立产品线。  
 > 相关链接：[功能发布](https://twitter.com/cognition/status/2014079905755955592)｜[使用方式补充](https://twitter.com/cognition/status/2014079917139566990)  

##### **GitHub Copilot CLI 新增主动提问工具，命令行助手更像“对话 Agent”**  
Copilot CLI 加了一个 askUserQuestionTool，可以在操作前先问你关键问题（比如如何处理一堆 rebase 冲突），而不是默默执行。趋势很清晰：命令行 AI 从“补全几条命令”向“小型对话 Agent”演进，需要像人一样先确认意图再动手。  
 > 相关链接：[Evan Boyle 介绍](https://twitter.com/_Evan_Boyle/status/2014012076881064173)  

 

---  


#### **基础设施与硬件**  
##### **GPU 内核性能竞赛：Anthropic 面试题被人类和 AI 玩成刷榜题**  
Anthropic 公开的性能工程 takehome（优化一个 VLIW 小机的 kernel）被 GPU MODE 和 tinygrad 社群当成“刷题”：有人用手写 CUDA/Triton 跑到 2200 cycles，Claude Opus 4.5 在 Claude Code 里也能做出约 1790 cycles 的解法，接近人类高手两小时成绩。说明复杂 kernel 优化开始进入“人机共创”阶段。  
 > 相关链接：[Anthropic 官方题目](https://github.com/anthropics/original_performance_takehome/)  

##### **PyTorch 维护者被 AI 生成 PR 淹没，引入“大模型先自审”流程**  
GPU MODE 里 PyTorch 维护者抱怨大量低质量 AI 生成 PR，占用评审精力。有人建议直接限制新号提 PR，并用 Claude、Pangram 等工具先自动过滤，再用 Cursor Bugbot + GPT‑5 Pro 做初审，只有过了这一关才让人看。可以理解成“让 AI 先帮我们挡掉 AI 垃圾”。  
 > 相关链接：[Cursor Bugbot 介绍](https://share.google/P0PGYM8tiRAc2NOsq)  

##### **AMD 推出 AI 驱动包：一键装好 ComfyUI、Ollama、LM Studio 等**  
AMD 在最新 Adrenalin 驱动里内置 AI Bundle，直接打包好 Windows 下的 PyTorch、ComfyUI、Ollama、LM Studio 和 Amuse，减少 AMD 卡用户在本地跑大模型的环境折腾成本。对想在非 NVIDIA 平台做本地推理的人来说，门槛明显降低。  
 > 相关链接：[AMD 官方博客](https://www.amd.com/en/blogs/2026/amd-software-adrenalin-edition-ai-bundle-ai-made-si.html)  

##### **高端消费级 GPU 二手价持续飙升，本地跑模型变“理财产品”**  
LM Studio 社区有人吐槽：二手 3090 在 eBay 已到约 850 欧元，5090 去年 2000 英镑买的，现在同店挂到 2659.99 英镑。配合各种本地 AI 用例，这类卡在短期内成了“保值资产”，也侧面说明云上算力依然紧张且不便宜。  
 > 相关链接：[LM Studio 硬件讨论摘录](https://discord.com/channels/1110598183144399058/1153759714082033735/1463289097845215387)  

##### **NVIDIA 生态：Blackwell、新显存、NCCL 等基础设施细节被工程师反复拷问**  
GPU MODE 多个频道在聊 Blackwell 卡的 warp/TMA 利用、NCCL all‑reduce 是否跨节点流水、Pro 6000 Max‑Q 与 4090 在 SM 数和 insts/scheduler 上差异，还有用 nvshmem 替代传统通信栈等。结合对 HBM 产能和验证周期的讨论，可以看出大家越来越把“显存和互联”当真正瓶颈，而不只是算力 FLOPs。  
 > 相关链接：[NCCL 相关 issue](https://github.com/NVIDIA/nccl/issues/530#issuecomment-872220006)  

 

---  


#### **产品与应用落地**  
##### **Google × 可汗学院：Gemini 变成学生“写作教练”而不是代写工具**  
Google 宣布与 Khan Academy 合作，在 Gemini 内提供 Writing Coach：不是直接帮你写作文，而是指导如何起草、修改和润色，鼓励学生自己动笔。配合 SAT 模拟卷和解析，Gemini 正在被包装成教育工具而非“作弊神器”。  
 > 相关链接：[Google 写作教练介绍](https://twitter.com/Google/status/2014082428957045007)  

##### **Runway Gen‑4.5 Image→Video：视频评估从“好不好看”转向“能不能讲故事”**  
Runway 发布 Gen‑4.5 的图像转视频功能，主打角色一致性、镜头运动和叙事连续性。早期用户反馈，单帧效果已经卷到头，真正拉开差距的是“能不能用几条提示讲出一个完整小故事”，评测方式也在从单 clip 打分转向“多镜头故事任务”。  
 > 相关链接：[Runway 发布](https://twitter.com/runwayml/status/2014090404769976744)｜[创始人补充](https://twitter.com/c_valenzuelab/status/2014105905088856411)  

##### **Video Arena & Text Arena：社区投票已经成了事实上的模型口碑榜**  
LMArena 的 Text Arena 累积投票数已破 500 万；视频版 Video Arena 也正式开放 Web 入口，目前每天只能生成 3 条、且只能 Battle 模式，不能指定模型。虽然体验有点像“拉老虎机”，但这些匿名对战票数正在影响大家对各家前沿模型的真实感知度。  
 > 相关链接：[Video Arena 网页](https://lmarena.ai/?chat-modality=video)｜[500 万票里程碑视频](https://cdn.discordapp.com/attachments/1343296395620126911/1463271605697511485/5M_votes_social_post_3.mp4)  

##### **Inforno、Soulbotix：OpenRouter 上的新一代多模型聊天桌面应用**  
开发者基于 OpenRouter 做了两款“多模型前端”：Inforno 支持桌面同时和多家 LLM 对话、历史记录存 .rno 文件，还支持俄语 UI；Soulbotix 则主打带真人化虚拟形象的 Windows 客户端，需要 RTX 4070Ti 级显卡本地跑 Whisper 语音识别，节省 API 费用。  
 > 相关链接：[Inforno 介绍视频](https://youtu.be/oJyj0mroFtY?si=m5A9tRxzB9hfINMX)｜[Inforno GitHub](https://github.com/alexkh/inforno)｜[Soulbotix 官网](https://soulbotix.com)  

##### **AI 成人内容：虚拟“OnlyFans 模特”开始和真人抢生意**  
Latent Space 里有讨论指出，越来越多 AI 生成的虚拟形象入场成人内容平台，效果逼真、成本极低。观点是：真人创作者未来不得不转向更强的 IP、互动和线下体验，否则很难和“24 小时在线、永远不会老的 AI 人设”竞争。  
 > 相关链接：[引发讨论的推文](https://xcancel.com/abrilzucchi/status/2014027740614123863?s=46)  

 

---  


#### **研究与方法**  
##### **DSpy RLM：用“可调用程序”重构 Agent，让长上下文问题变成代码问题**  
DSPy 社群认为传统 coding agent 被输入/输出长度和“决策视野”卡死，而 RLM（程序化推理语言模型）把大文件放进 Python 变量、通过函数调用进行操作，让“上下文管理”变成写代码的问题。大家在讨论要不要给 RLM 配 ripgrep / 语义检索工具，还是让模型自己写搜索代码。  
 > 相关链接：[RLM 讨论引用的 X 贴](https://x.com/lateinteraction/status/2013658521246535892)  

##### **多向量检索卷起来：小模型 + ColBERT 式后交互，干翻大 embedding**  
Mixedbread 声称一个 1700 万参数的 ColBERT 多向量模型，在 LongEmbed 等长文任务上能超过 80 亿参数的单向量 embedding 模型，并在生产中对 10 亿+ 文档做到 p50 < 50ms。TurboPuffer 也在宣传能索引 1000 亿级向量的 ANN 系统。趋势很明显：召回在走“多向量 + 晚交互”，但前提是有厚重的检索基础设施。  
 > 相关链接：[Mixedbread 结果帖](https://twitter.com/mixedbreadai/status/2014062123358548017)｜[大规模部署数据](https://twitter.com/mixedbreadai/status/2014062110993687002)｜[TurboPuffer 介绍](https://twitter.com/turbopuffer/status/2014063666262688191)  

##### **NVIDIA TTT‑E2E：把上下文当训练数据，换常数时间推理**  
有线程总结了 NVIDIA 的 TTT‑E2E 思路：把长上下文视作在线更新权重的数据，让推理时间只和“步数”有关、而不是和上下文长度线性增长，代价是“针找草堆”精确召回变弱。对需要长时间运行的 Agent 来说，这种“常数算力上下文”是一个很有吸引力但需要新评估方法的方向。  
 > 相关链接：[思路概述贴](https://twitter.com/sdrzn/status/2014128642503381276)  

##### **Cute / CUTLASS 布局代数：想写好 kernel，先学一点范畴论**  
GPU MODE 的 cutlass 频道分享了一篇长文，把 Cute 布局的 shape/stride 约束用“tuple 变换 + 互相 refine”的图形代数表达出来，并配了动态图。结论很朴素：要想写出不拉跨的 kernel，单靠感觉不够，最好对布局代数有概念，否则很难在复杂 tile 组合下做正确的内存访问。  
 > 相关链接：[Cute 布局范畴论博客](https://research.colfax-intl.com/categorical-foundations-for-cute-layouts/)  

 

---  


#### **产品与应用落地**  
##### **LM Studio 与本地社区：GLM‑4.7 崩溃、Qwen3 之后“再无惊艳”**  
LM Studio 用户在新 runtime 后普遍吐槽 GLM‑4.7‑Flash 慢到不可用、反复卡死。讨论中不少人感慨，除了半年前的 Qwen3，近期主流新模型更多是在效率和小模型上迭代，“体验上没再有当年 GPT‑4 那种跳变”，本地圈开始关注 100–200B 超大模型是否还有新空间。  
 > 相关链接：[LM Studio general 讨论](https://discord.com/channels/1110598183144399058/1110598183144399061/1463268404629868665)  

##### **Manus.im 用户抱怨：Bug 多、性能回退、付费额度迟迟不到账**  
Manus.im 的重度用户称自己构建的 38 个模块里最近只有 20 个还能正常跑，请求开放 CLI 自己排障；同时有人反馈 Manus 1.6 在最近几周表现变差，只能切到 1.6 Max 才能正确给出网站改版方案；还有人投诉升级付了 42 美元但承诺的 8000 点数没到帐，客服响应缓慢。对一个主打“工程 Agent”的产品来说，这是非常危险的信号。  
 > 相关链接：[Manus Discord 讨论](https://discord.com/channels/1348819876348825620/1349440650495398020/1463264663092330549)  

 

---  


#### **Agent 与工具链**  
##### **Coderrr：开源“Claude Code 替代品”上线，拉满社区参与感**  
开发者 Akash 发布 Coderrr，定位为免费开源的 Claude Code 替代方案，支持项目级理解与改写，欢迎大家提 issue 和 PR 一起“打磨一个大家真正愿意用的 AI 编程助手”。对于担心闭源 IDE 助手锁死工作流的人，这是一个值得关注的方向。  
 > 相关链接：[Coderrr 在线体验](https://coderrr.aksn.lol/)｜[GitHub 仓库](https://github.com/Akash-nath29/Coderrr)  

##### **Aider 被担心“已死”，社区版在给它续命**  
命令行编程助手 Aider 近来更新缓慢，Discord 里不少人担心作者 Paul 已经转向别的项目，有人干脆说“项目已死”，转用 OpenCode / Claude Code / Gemini CLI 等。也有人表示自己仍在用 Aider + GPT‑5.2，社区则在 Aider‑CE 分支里尝试补上 MCP 和 Agent 能力，给它续命。  
 > 相关链接：[Aider 文档](https://aider.chat/docs/llms/other.html)  

 

---  

  
