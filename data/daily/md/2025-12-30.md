#### **模型与框架更新**  
##### vLLM推出官方社区网站vllm.ai  
vLLM团队推出官方社区网站vllm.ai，包含交互式安装选择器、活动日历、集中式文档hub，承认文档 gaps并提供搜索和办公时间playlist。  
 > 相关链接：[vLLM发布 tweet](https://twitter.com/vllm_project/status/2005461211656155153)｜[文档说明 tweet](https://twitter.com/vllm_project/status/2005640089133830371)  

##### Tencent发布WeDLM 8B Instruct开源模型  
Tencent在Hugging Face发布WeDLM 8B Instruct扩散语言模型，比vLLM优化的Qwen3-8B快3-6倍，Apache 2.0许可，基准测试表现优秀。  
 > 相关链接：[Hugging Face地址](https://huggingface.co/tencent/WeDLM-8B-Instruct)｜[Reddit讨论](https://www.reddit.com/r/LocalLLaMA/comments/1pyg4yt/tencent_just_released_wedlm_8b_instruct_on/)  

##### fal开源FLUX.2 Turbo图像模型  
fal开源FLUX.2 Turbo图像模型，基于DMD2蒸馏，声称在Artificial Analysis排名开源第一，社区快速推出Hugging Face Spaces demo。  
 > 相关链接：[fal发布 tweet](https://twitter.com/fal/status/2005690257979707496)｜[demo链接](https://twitter.com/multimodalart/status/2005752030669987989)  

##### MiniMax-M2.1成为开源Agentic编码模型  
MiniMax-M2.1在Code Arena排名开源WebDev第一，Chutes测试显示82.83%工具调用准确率，强调大代码库实用性，迭代向M2.2/M2.5推进。  
 > 相关链接：[Code Arena tweet](https://twitter.com/arena/status/2005779347182084585)｜[Chutes测试 tweet](https://twitter.com/chutes_ai/status/2005539785923072424)  

 

---  


#### **推理与性能优化**  
##### AMD MI300X FP8性能不及bf16  
多数据显示MiniMax-M2.1在MI300X上bf16性能优于FP8：vLLM中bf16达55.7 TPS（FP8 42 TPS），sglang中bf16 71 TPS（FP8 55 TPS）。  
 > 相关链接：[QuixiAI测试 tweet1](https://twitter.com/QuixiAI/status/2005481942712811695)｜[QuixiAI测试 tweet2](https://twitter.com/QuixiAI/status/2005724765928210655)  

##### Weaviate新增Object TTL等功能  
Weaviate发布新版本，包含Object TTL、Java v6客户端GA、Flat Index RQ量化、zstd备份、多模态文档嵌入等功能。  
 > 相关链接：[Weaviate发布 tweet](https://twitter.com/weaviate_io/status/2005673260344877186)  

##### Baseten优化GLM-4.7推理速度  
Baseten报告GLM-4.7成为内部默认编码模型，在Baseten上推理速度快20%（tok/s和TTFT），并提供托管试用端点。  
 > 相关链接：[Baseten tweet1](https://twitter.com/amiruci/status/2005697292326797740)｜[Baseten tweet2](https://twitter.com/basetenco/status/2005699615379841325)  

 

---  


#### **开源模型与数据集**  
##### GLM-4.7成为开源编码默认模型  
GLM-4.7因Interleaved/Preserved/Turn-level Thinking成为开源编码默认，AlphaXiv称其在Artificial Analysis排名第一，Baseten内部广泛使用。  
 > 相关链接：[AlphaXiv tweet](https://twitter.com/askalphaxiv/status/2005622173214335476)｜[Baseten tweet](https://twitter.com/amiruci/status/2005697292326797740)  

##### pokeart Pokémon数据集发布  
pokeart数据集包含Gen1-Gen9共1224只 Pokémon的 splash art、战斗精灵等，提供6种Gemini 3 Pro caption和1种Qwen3 caption，用于基准测试。  
 > 相关链接：[Hugging Face地址](https://huggingface.co/datasets/OJ-1/pokeart)  

##### 韩国32B VLM模型发布  
韩国发布32B VLM模型，调整架构（移除muP和sandwich norm），使用0.006初始化，英韩基准表现优秀，等待技术报告。  
 > 相关链接：[Elie Bakouch tweet](https://twitter.com/eliebakouch/status/2005549508063559876)  

 

---  


#### **AI代理与工作流**  
##### Spotify编码代理的生产经验  
Spotify分享编码代理生产经验：指定可验证终态、包含代码示例、最小化工具（verify/git/bash）、用AGENTS.md文档化工作流。  
 > 相关链接：[Phil Schmid tweet1](https://twitter.com/_philschmid/status/2005537262390349899)｜[Phil Schmid tweet2](https://twitter.com/_philschmid/status/2005537264953430487)  

##### 文档适配AI代理的双受众模式  
社区讨论双受众文档模式：既供开发者阅读，又结构化供代理提取上下文，如AGENTS.md/CLAUDE.md惯例，LlamaIndex提供模板。  
 > 相关链接：[LlamaIndex tweet](https://twitter.com/llama_index/status/2005686055253729587)  

##### Amazing Z-Image Workflow v3.0发布  
Amazing Z-Image Workflow v3.0更新，包含Style Selector（15种风格）、Sampler Switch、Landscape Switch、Z-Image Enhancer等，支持GGUF/SAFETENSORS。  
 > 相关链接：[Reddit讨论](https://www.reddit.com/r/StableDiffusion/comments/1pympur/amazing_zimage_workflow_v30_released/)｜[GitHub地址](https://github.com/martin-rizzo/AmazingZImageWorkflow)  

##### OpenEnv标准化代理环境  
Meta×Hugging Face推出OpenEnv，标准化代理环境，支持TRL/TorchForge等框架，集成MCP工具，旨在统一训练与部署。  
 > 相关链接：[Ben Burtenshaw tweet1](https://twitter.com/ben_burtenshaw/status/2005655406522085482)｜[Ben Burtenshaw tweet2](https://twitter.com/ben_burtenshaw/status/2005655407725809875)  

 

---  


#### **研究与技术突破**  
##### Transformers存储全局结构而非仅关联  
Google研究显示Transformers学习隐式多跳推理，在50k节点图上达100%准确率，挑战知识编辑假设，认为其存储全局结构。  
 > 相关链接：[dair.ai tweet](https://twitter.com/dair_ai/status/2005480659209400789)  

##### URM递归推理优于静态深度  
URM（Universal Recurrent Model）在ARC-AGI上表现优于静态深度模型，ARC-AGI 1达53.8% pass@1，关键在于递归归纳偏置和强非线性。  
 > 相关链接：[Omar Sanseviero tweet](https://twitter.com/omarsar0/status/2005640015964250267)  

##### TTT-E2E实现长上下文测试时训练  
TTT-E2E在推理时继续训练以压缩上下文，将3B模型上下文从8K扩展到128K，比全注意力快2.7倍，性能更优。  
 > 相关链接：[Karan Dalal tweet](https://twitter.com/karansdalal/status/2005704608996540887)  

##### AgentReuse加速代理延迟  
AgentReuse缓存并参数化代理计划，在2664请求中实现93%复用率，延迟降低93%，内存开销小。  
 > 相关链接：[Omar Sanseviero tweet](https://twitter.com/omarsar0/status/2005799762252136537)  

 

---  


#### **行业与收购动态**  
##### Meta以约40亿美元收购Manus AI  
Meta Superintelligence Labs收购Manus AI，后者成立9个月ARR达1亿美元，Alex Wang宣布加入，称Manus在Remote Labor Index表现SOTA。  
 > 相关链接：[Alex Wang tweet1](https://twitter.com/alexandr_wang/status/2005766469771223106)｜[Alex Wang tweet2](https://twitter.com/alexandr_wang/status/2005766471516053736)｜[scaling01 tweet](https://twitter.com/scaling01/status/2005768491740360722)  

##### xAI招聘RL后训练与安全职位  
xAI招聘专注RL后训练、对齐/行为、灾难性风险 reduction的角色，Stewart Slocum发布职位信息。  
 > 相关链接：[Stewart Slocum tweet](https://twitter.com/StewartSlocum1/status/2005710683623809440)  

##### Perplexity Pro的使用限制与Max tier  
用户报告Perplexity Pro存在高级模型使用限制（如1-2次/小时），而Max tier宣称无限制，部分用户遇订阅问题（如7个月后终止）。  
 > 相关链接：[Perplexity Reddit讨论1](https://www.reddit.com/r/PerplexityAI/comments/1pypit3/holy_shit_its_real/)｜[Perplexity Reddit讨论2](https://www.reddit.com/r/ChatGPT/comments/1pypieu/holy_shit_its_real/)  

 

---  


#### **Reddit热门讨论**  
##### AI图像生成的异常特征识别  
用户讨论AI生成图像的异常，如“脚代替手”的托盘、扭曲的酒杯，指出这些是AI生成的常见指标，幽默评论称“正确脚趾数”反成疑点。  
 > 相关链接：[GeminiAI讨论](https://www.reddit.com/r/GeminiAI/comments/1pyi6ax/how_to_tell_if_an_image_is_ai_generated/)｜[StableDiffusion讨论](https://www.reddit.com/r/StableDiffusion/comments/1pyi706/how_to_tell_if_an_image_is_ai_generated/)  

##### OpenAI Killswitch工程师职位的梗  
用户讨论OpenAI“Killswitch Engineer”梗图，称其为营销噱头，幽默质疑30万-50万美元年薪的“拔插头”职位资格。  
 > 相关链接：[OpenAI Reddit讨论1](https://www.reddit.com/r/OpenAI/comments/1pypit3/holy_shit_its_real/)｜[ChatGPT Reddit讨论2](https://www.reddit.com/r/ChatGPT/comments/1pypieu/holy_shit_its_real/)  

##### 学生Perplexity Pro订阅问题  
学生用户报告Perplexity Pro订阅异常：使用12个月Revolut Metal voucher后仅7个月就终止，支持响应慢，部分用户仍正常。  
 > 相关链接：[Perplexity Reddit讨论](https://www.reddit.com/r/ChatGPT/comments/1pypieu/holy_shit_its_real/)  

 

---  


#### **Discord社区动态**  
##### BASI Jailbreaking发现vibe coded app XSS漏洞  
BASI Jailbreaking成员发现vibe coded app的JavaScript存在XSS漏洞，若LLM生成XSS payload会触发，讨论输入验证和安全实践。  
 > 相关链接：[BASI Jailbreaking #general](https://discord.com/channels/1105891499641684019/1235691879492751460/1455047763472416851)  

##### Unsloth AI讨论多头部注意力机制  
Unsloth AI用户讨论多头部注意力：头部学习不同子空间，最终投影层混合信息以捕捉复杂关系，解决“dogness”分裂问题。  
 > 相关链接：[Unsloth AI #general](https://discord.com/channels/1179035537009545276/1179035537529643040/1455076629683376365)  

##### Perplexity用户寻求开源替代方案  
Perplexity Discord用户讨论开源替代方案，如Perplexica（GitHub），希望复制实时搜索+回答UX，称“Opencode是手，Perplexity是眼”。  
 > 相关链接：[Perplexity #general](https://discord.com/channels/1047197230748151888/1047649527299055688/1455062155958157445)｜[Perplexica GitHub](https://github.com/ItzCrazyKns/Perplexica)  

##### Unsloth AI讨论训练数据的重要性  
Unsloth AI用户意识到训练数据是LLM的概率压缩，需在训练中覆盖所有边缘案例，否则推理会脆弱，链接HarryR/z80ai的训练数据示例。  
 > 相关链接：[Unsloth AI #general](https://discord.com/channels/1179035537009545276/1179035537529643040/1455076629683376365)｜[HarryR/z80ai GitHub](https://github.com/HarryR/z80ai/blob/main/examples/tinychat/training-data.txt.gz)  

 

---  

  
