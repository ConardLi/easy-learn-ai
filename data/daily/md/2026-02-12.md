#### **模型与能力**  
##### **智谱 Z.ai 发布 GLM-5：开放权重新天花板**  
GLM-5 从 355B MoE/32B 激活升级到 744B/40B 激活，预训练数据增至 28.5T，引入 DeepSeek Sparse Attention，支持约 200K 上下文和超长输出，MIT 许可开源（BF16 权重约 1.5TB）。在 Text Arena 开放模型中登顶，在 Artificial Analysis 智能指数中得分 50，白领工作基准 GDPVal-AA ELO 1412，幻觉率在其评测中最低。  
 > 相关链接：[官方博客](https://z.ai/blog/glm-5)｜[开源权重（Hugging Face）](https://huggingface.co/zai-org/GLM-5)｜[开源权重（ModelScope）](https://modelscope.cn/models/ZhipuAI/GLM-5)｜[OpenRouter 模型页](https://openrouter.ai/z-ai/glm-5)｜[Artificial Analysis 榜单解读](https://twitter.com/ArtificialAnlys/status/2021678229418066004)｜[LMSYS / vLLM 支持](https://twitter.com/lmsysorg/status/2021639499374375014)｜[vLLM 集成说明](https://twitter.com/vllm_project/status/2021656482698387852)  

##### **GLM-5 定位与算力瓶颈：‘我们真的 GPU 不够’**  
Z.ai 把此前“Pony Alpha”公开为 GLM-5，主打 Agent 场景和长任务。由于访问量暴涨 10 倍，官方多次强调推理算力吃紧，只优先开放 Coding Plan Pro，并调整订阅和 API 价格。Reddit 讨论指出，连 Z.ai、OpenAI、Google 都在不同程度上被 GPU 供应卡住，算力短缺已成行业共性。  
 > 相关链接：[Z.ai 算力/计费说明](https://twitter.com/Zai_org/status/2021656633320018365)｜[Reddit：Z.ai 公开承认 GPU 不够用](https://www.reddit.com/r/LocalLLaMA/comments/1r26zsg/zai_said_they_are_gpu_starved_openly/)｜[订阅方案变更讨论](https://www.reddit.com/r/LocalLLaMA/comments/1r1wl6x/glm_5_released/)  

##### **GLM-5 价格不便宜：与 DeepSeek、Kimi 对比**  
社区给出的对比：GLM-5 输入价格约 0.80 美元/百万 token，是 DeepSeek V3.2 Speciale 的约 3 倍、Kimi K2.5 的约 1.8 倍；输出价格约 2.56 美元/百万 token，是 DeepSeek 的约 6 倍，比 Kimi 也略贵。定位更偏高端质量，而不是极致性价比。  
 > 相关链接：[Reddit 成本对比讨论](https://www.reddit.com/r/LocalLLaMA/comments/1r22hlq/glm5_officially_released/)｜[Artificial Analysis 成本与能力图](https://twitter.com/ArtificialAnlys/status/2021678229418066004)  

##### **GLM-OCR：对打 Gemini Flash 的开源 OCR 小模型**  
社区在实测中发现，智谱的 GLM-OCR 在某些 OCR 任务上优于 Gemini 3 Flash，被视为做文档/票据类产品时更便宜的替代方案。模型开源在 HF，可自托管。  
 > 相关链接：[GLM-OCR 模型卡](https://huggingface.co/zai-org/GLM-OCR)｜[Latent Space 使用反馈](https://engineering.fractional.ai/tiny-ocr?showSharer=true)  

##### **DeepSeek “V4-lite” 与 100 万上下文更新**  
多方爆料 DeepSeek 上线了“V4 Lite”或类似新版本，聊天端支持 100 万 token 上下文，知识截止更新到 2025 年 5 月，仍为纯文本模型。用户反馈在长文档任务上明显强于以往 128K 模型，但部分查询延时从 30 秒拉长到 160 秒。  
 > 相关链接：[长上下文体验讨论](https://twitter.com/teortaxesTex/status/2021511733333131311)｜[Reddit：1M context 更新讨论一](https://www.reddit.com/r/DeepSeek/comments/1r1szyi/deepseek_is_updating_its_model_with_1m_context/)｜[Reddit：1M context 更新讨论二](https://www.reddit.com/r/DeepSeek/comments/1r1t4ge/deepseek_got_update_now_its_has_the_1_million/)  

##### **DeepSeek 在开源 MoE/注意力路线上的“统治力”**  
多位开发者梳理 DeepSeek 的技术输出：细粒度稀疏 MoE、MLA（多头潜在注意力）、稀疏注意力实用化、开源推理/优化库 DeepEP、公开 R1/GRPO 路线等。现在几乎所有前沿开源大模型（包括 GLM-5）都在不同程度复用这些组件，DeepSeek 被认为对开源栈影响极大。  
 > 相关链接：[技术影响力长帖](https://twitter.com/eliebakouch/status/2021577794480644216)  

##### **MiniMax M2.5 与 StepFun-Flash-3.5：高性价比推理模型**  
MiniMax 发布 M2.5，主攻分解任务与长时间执行；StepFun 推出 Step-Flash-3.5，自称 MathArena 排名第一。社区评价：在相近激活参数下，推理速度和成本都很有竞争力，尤其适合需要大规模调用的编码/数学场景。  
 > 相关链接：[MiniMax 官方推文](https://twitter.com/MiniMaxAgent/status/2021595954143515106)｜[StepFun-Flash-3.5 介绍](https://twitter.com/CyouSakura/status/2021511358626554322)  

##### **Qwen-Image 2.0：7B 统一生图+编辑，小尺寸高分辨率**  
阿里发布 Qwen-Image 2.0，7B 参数统一支持生成和编辑，原生 2K 分辨率，可渲染复杂英文/中文排版、诗词和多格漫画人物一致性。模型比上一代从 20B 缩至 7B，更有希望本地跑。官方已修复古诗排序和编辑中文字一致性问题。  
 > 相关链接：[Qwen 官方推文](https://twitter.com/Alibaba_Qwen/status/2021510747671720368)｜[Reddit 模型简介与讨论](https://www.reddit.com/r/LocalLLaMA/comments/1r0w7st/qwenimage20_is_out_7b_unified_genedit_model_with/)  

##### **Qwen3-Coder-Next：80B 代码模型跑在“NAS 集成显卡”上**  
有人在 TrueNAS SCALE + Ryzen AI iGPU 上，用 llama.cpp + Q4_K_M 量化跑起 Qwen3-Coder-Next 80B MoE，启用 Vulkan offload 和 flash attention 后达到约 18 tok/s，且同时在跑 NAS 和 Jellyfin。关键优化是去掉 --no-mmap 让模型完整映射进共享内存。  
 > 相关链接：[Reddit 硬件+性能细节](https://www.reddit.com/r/LocalLLM/comments/1r1jdq3/my_nas_runs_an_80b_llm_at_18_toks_on_its_igpu_no/)  

##### **Unsloth Triton MoE 内核：训练提速 12 倍、显存省 30%+**  
Unsloth 发布 MoE Triton kernel，在不降精度的前提下，宣称 MoE 训练最高提速 12x、显存降低约 35%，支持消费级到数据中心 GPU（3090 也能用），并利用 PyTorch 新的 torch._grouped_mm 接口。对想在单机/小卡上玩 MoE 的个人团队很有价值。  
 > 相关链接：[Reddit 图表与讨论](https://www.reddit.com/r/LocalLLaMA/comments/1r14h9u/train_moe_models_12x_faster_with_30_less_memory/)｜[Unsloth 官方推文](https://twitter.com/UnslothAI/status/2021244131927023950)  

 

---  


#### **Agent 与工具链**  
##### **Karpathy 示范新范式：让 Agent ‘撕下’所需代码自给自足**  
Karpathy 用 DeepWiki MCP + GitHub CLI 让代理先读懂仓库，再自动把 torchao FP8 里需要的实现剪出来，生成一个自包含文件和测试，顺便删掉重量依赖，甚至还有小幅提速。这种“仓库当真·文档，Agent 当重构/移植工”的工作流开始成型。  
 > 相关链接：[Karpathy 推文实例](https://twitter.com/karpathy/status/2021633574089416993)  

##### **llama.cpp 加入 MCP 支持：本地模型也能玩工具调用**  
社区版 llama.cpp 的 WebUI 已支持 MCP（Multi-Component Protocol），可配置 agent 循环轮数、工具预览行数等，通过 HTTP/WebSocket 调远程 MCP 服务器（GitHub、HF、Exa Search 等），下一步计划接入 llama-server。核心目标是统一本地/云端工具链，减少本地 agent 套壳成本。  
 > 相关链接：[Reddit：MCP 支持发布贴](https://www.reddit.com/r/LocalLLaMA/comments/1r1czgk/mcp_support_in_llamacpp_is_ready_for_testing/)  

##### **LM Studio/本地 MCP 插件：不用 API Key 的 Google 搜索**  
noapi-google-search-mcp 利用 Headless Chromium 把 Google Search 封装成 MCP 工具，无需官方 API key，即可在 LM Studio 等前端里调用网页搜索、图片、反向搜图、本地 OCR、Lens、航班、股票、天气、新闻/趋势等，方便给本地模型“外挂浏览器”。  
 > 相关链接：[noapi-google-search-mcp 仓库](https://github.com/VincentKaufmann/noapi-google-search-mcp)  

##### **mini-SWE-agent 2.0：100 行级极简编码 Agent 基准**  
研究者开源 mini-SWE-agent 2.0，刻意保持 Agent、环境、模型接入各约百行，用于做编码代理基准和 RL 训练实验。趋势是从“巨大框架”转向可审计、可改的小 harness。  
 > 相关链接：[作者推文](https://twitter.com/KLieret/status/2021606142699356215)  

##### **OpenClaw：把整套开发环境搬进 Discord**  
有人用 OpenClaw 把 tmux、git worktree、Claude Code 串起来，自己几乎只用 Discord 开发：频道里发指令调会话、自动保存上下文和反思到 markdown，再用 /wrap 标记“这一段工作结束”。这是把“工作流+可审计上下文”当一等公民的尝试。  
 > 相关链接：[OpenClaw 介绍讨论](https://discord.com/channels/822583790773862470/1209303473263485011/1470879095494541333)  

##### **OpenAI：用 Codex 做 1500 个 PR，以及多小时流程指南**  
OpenAI DevRel 分享了一个案例：通过“驯服 Codex”，在无人手写代码的情况下合入约 1500 个 PR；并发布如何可靠跑“多小时工作流”的最佳实践。配合 Sam Altman 对 Codex 的吹捧，侧重点其实是“工程化 harness”而不是再造一个新模型。  
 > 相关链接：[OpenAI Devs 工程案例](https://twitter.com/OpenAIDevs/status/2021637918847381656)｜[多小时工作流建议](https://twitter.com/OpenAIDevs/status/2021725246244671606)｜[Sam Altman 评论](https://twitter.com/sama/status/2021606985469211065)  

 

---  


#### **基础设施与硬件**  
##### **本地 LLM 硬件讨论：5 万人民币能堆出什么水平？**  
Reddit 上有人问 2026 年 5000 美元如何搭本地 LLM 平台，讨论方案包括：双 128GB Ryzen AI Max+ 机器做 4bit 推理+QAT LoRA；4×3090 或 7×AMD V620；Strix Halo 静音方案等。主线观点：要跑 100B 级、长上下文+工具链，一般要 40–48GB 级显存/统一内存起步。  
 > 相关链接：[配置方案讨论串](https://www.reddit.com/r/LocalLLM/comments/1r0x3kn/what_would_a_good_local_llm_setup_cost_in_2026/)  

##### **民间多卡平台：6×3090/8×3090/4×4090 各种拼法**  
社区展示了多种“土豪机”：例如 6×3090（总 144GB VRAM）跑 10B 级 Diffusion 训练，或者通过 x16 拆 x8/x8 实现 8×3090。也有人在 X670 主板上搞出 4×4090 的 x8x8 分叉，但带宽被降到 2.5GT/s x8/x4。能用，但带宽和供电稳定性都要自己踩坑。  
 > 相关链接：[6×3090 搭建贴](https://www.reddit.com/r/LocalLLaMA/comments/1r1tuh1/just_finished_building_this_bad_boy/)｜[4×4090 x8x8 讨论](https://discord.com/channels/1110598183144399058/1153759714082033735/1466859579072581642)  

##### **CuteDSL 崛起，Triton 在 Blackwell 上日子不好过**  
GPU MODE 社区统计的 Kernelbot 数据显示，CUDA 和 CuTeDSL 提交量最高，很多人觉得 CuTeDSL 比 Triton 不那么“黑盒”，布局代数也更透明。反过来，Triton 被吐槽在 Blackwell 上难以适配 MXFP8/NVFP4 这些新格式，编译器也不给足控制，只能等待官方后续改进。  
 > 相关链接：[Kernelbot 数据集](https://huggingface.co/datasets/GPUMODE/kernelbot-data)｜[社区讨论帖](https://discord.com/channels/1189498204333543425/1189498205101109300/1471007676325560381)  

##### **torchao v0.16.0：加入 MXFP8 MoE 组件，向 ABI 稳定迈进**  
PyTorch/torchao 0.16.0 发布，增加 MXFP8 MoE 训练积木，支持 Expert Parallel；同时清理旧配置和冷门量化选项，文档/README 重写，并强调正在推进 ABI 稳定，方便下游长期集成低精度 MoE 方案。  
 > 相关链接：[torchao v0.16.0 发布说明](https://github.com/pytorch/ao/releases/tag/v0.16.0)  

##### **FlashInfer AI Kernel 大赛：鼓励‘纯 Agent 写核’**  
FlashInfer 发起内核生成比赛，要求提交能跑的 CUDA/CuTeDSL 内核，分完全 Agent 生成和 Agent 辅助两类。组织者推迟基线代码到 2 月 12 日，以补充特性。群里讨论大量聚焦在如何避免奖励作弊、是否只允许改 kernel 段、以及用 Programmatic Dependent Launch 等高级技巧算不算违规。  
 > 相关链接：[比赛说明与讨论](https://discord.com/channels/1189498204333543425/1464407141128339571/1470951440053698622)  

 

---  


#### **研究与方法**  
##### **$300 万开放评测基金：Snorkel 等发起补上“评测缺口”**  
Snorkel 联合 HF、Together、Prime Intellect、Factory、Harbor、PyTorch 等宣布 300 万美元开放基准资助计划，希望建立更公开可靠的模型评测，尤其是当前闭源实验室内部测得分远超公开榜单的“评测断层”。  
 > 相关链接：[发起人推文 1](https://twitter.com/vincentsunnchen/status/2021663737716125781)｜[发起人推文 2](https://twitter.com/lvwerra/status/2021671530108006705)｜[发起人推文 3](https://twitter.com/percyliang/status/2021701152333877681)  

##### **Anthropic Opus 4.6 电脑操作安全评测，被学界质疑“高估鲁棒性”**  
RedTeamCUA 基准作者称，他们在真实 Web+OS 场景测到 Opus 4.5 注入成功率可达 83%，4.6 约 50%，远高于 Anthropic 系统卡里“10%/＜1%” 的数字；认为官方低 ASR 可能只是“模型不会干活”，而非真正安全。  
 > 相关链接：[研究者批评线程](https://twitter.com/hhsun1/status/2021696367216005139)  

##### **小模型“人格指纹”研究：7B–9B LLM 在多个行为轴上各不相同**  
有人用隐层探针测了 6 个 7B–9B 开源模型，在“热情/冷淡、自信/谨慎”等 7 个行为轴上都有稳定模式，重测一致性 ICC 0.91–0.99。发现所谓“dead zones”：部分人格轴无论怎么提示都调不过去，说明 RLHF 可能把部分空间“压瘪”。  
 > 相关链接：[Reddit 论文工具介绍](https://www.reddit.com/r/LocalLLaMA/comments/1r11zsa/i_measured_the_personality_of_6_opensource_llms/)  

##### **LLM 自我审查与‘潜在伦理’：别把模型训练成只会迎合**  
新论文《Coherence over compliance》认为，大模型内部其实存在某种“伦理一致性”，但我们在对齐时过度训练其“服从”，反而压制了这种潜在判断力。HF 社区讨论指出，单纯追求“听话”可能让模型在复杂伦理问题上变得更危险而不是更安全。  
 > 相关链接：[论文 PDF](https://zenodo.org/records/18598407)  

##### **开放权重模型自述“思维轨迹”：会自己发明词汇描述内部状态**  
Eleuther 社区分享一篇关于 Llama 3.1 / Qwen 2.5-32B 的工作：模型在长时间“自我反省”时会发明类似“loop”“mirror”的词，这些词与真实激活动态有显著相关（例如自相关 r≈0.44、谱功率 r≈0.62）。说明模型有能力自建一套“内在监控语汇”。  
 > 相关链接：[论文链接](https://doi.org/10.5281/zenodo.18567445)  

##### **注意力 = 最优传输？新论文把 SDPA 重新表述**  
一篇新作把标准点积注意力（SDPA）形式化为单边最优传输问题，给后续在理论上优化注意力、做稀疏/近似提供新视角。社区评价：数学优雅，暂时还偏理论。  
 > 相关链接：[arXiv 论文](https://arxiv.org/pdf/2508.08369)  

##### **DSPy 社区：RLM、MiPROv2、DPO 等在真实任务中的用法**  
DSPy Discord 里，大家在用 RLM 模块做记忆系统、自举 prompt，用 MiPROv2 专门优化“跑得最快的代码生成提示”，也在尝试用 DPO 方式把人类评审信号叠加到原始指令数据上。整体氛围是：把“提示工程”当成可学习的优化问题，而不是手搓咒语。  
 > 相关链接：[DSPy RLM 代码示例](https://gist.github.com/darinkishore/610d8f8553439016dcf23b945144c45c)｜[Kaggle/AIMO_v3 讨论串](https://discord.com/channels/1161519468141355160/1161519469319946286/1470872582621495357)  

 

---  


#### **产品与应用落地**  
##### **Seedance 2.0：视频质量震撼，同时因“照片→声音克隆”被紧急下架**  
大量用户被 Seedance 2.0 文生视频震到，认为已经“过了恐怖谷”，有人 15 秒视频成本算到约 0.72 美元。但随后爆出：它能仅凭人脸照片合成极像真声音，被质疑可用于身份伪造、深度伪造，ByteDance 暂停该功能并强调风险评估。  
 > 相关链接：[惊艳效果讨论](https://www.reddit.com/r/singularity/comments/1r23uzw/a_direct_message_from_ai_to_all_humans_seedance_20/)｜[技术风险报道](https://technode.com/2026/02/10/bytedance-suspends-seedance-2-0-feature-that-turns-facial-photos-into-personal-voices-over-potential-risks/)  

##### **SeeDance vs Veo：视频“推理能力”小测，前者连招更稳**  
有人设计了“三子棋视频”测试，让模型生成连贯走子过程。反馈是：Veo 通常能坚持 1–2 步不乱，SeeDance 能稳定到 5 步左右。虽然是个体测试，但给了一个关注“时间一致性/规则遵守”而不是纯美观的评测思路。  
 > 相关链接：[对比测试推文](https://twitter.com/paul_cal/status/2021657394166870507)  

##### **PixVerse R1：实时 720P 交互世界，视频从“渲染”走向“操控”**  
PixVerse 推 R1，主打“实时 720P 交互世界”，简单说就是不只生成一条视频，而是可以在其中实时互动。虽然宣传味很重，但方向明确：从离线片段生成，转向可交互场景生成。  
 > 相关链接：[PixVerse 官方介绍](https://twitter.com/PixVerse_/status/2021486175391973489)  

##### **AuditAI：用 Agentic RAG 自动做 NIST CSF 2.0 合规审计**  
社区有人用 LangGraph 做了“AuditAI”：用 Agentic RAG 把公司安全策略对照 NIST CSF 2.0 自动审一遍，采用 Corrective RAG 模式、语义路由快路径和“严格证据”策略，输出页级引用，减少幻觉。RAGAS 评测部分用 Llama 3.3 70B 做 judge。  
 > 相关链接：[AuditAI 后端代码](https://github.com/rockyglen/audit-ai-backend)  

##### **Voyager VS Code 插件：把论文一键变成 Jupyter 笔记本**  
社区开发者做了 Voyager 扩展，能在 VS Code 里用 Copilot 帮你把技术论文转成一个可运行的 Jupyter notebook，包括代码片段和可插入的自定义单元，用来逐段理解论文。适合不想在 PDF 和 Notebook 来回切的人。  
 > 相关链接：[VS Code 插件页](https://marketplace.visualstudio.com/items?itemName=BlackEagleLabsAI.voyagerai)  

##### **Control-Terminal：在手机上远程控制本地 AI CLI 会话**  
Control-Terminal 是一个开源小工具，可以让你在手机通过网页/隧道远程控制本地的 Claude/Codex 等 CLI agent，会话可持久化，利用 Cloudflare Tunnel 暴露公网 URL。适合经常跑脚本/自动化但不想一直开电脑前的人。  
 > 相关链接：[Control-Terminal 仓库](https://github.com/username/control-terminal)｜[文档示例](https://v0-control-terminal-docs.vercel.app)  

 

---  


#### **行业与公司动态**  
##### **中国“Agent 战争周”：GLM-5、MiniMax 2.5、Qwen-Image 2.0 集体上新**  
中国厂商在春节前一周密集发新：Z.ai 推出 GLM-5，MiniMax 上线 M2.5，阿里更新 Qwen-Image 2.0，后面还有 DeepSeek V4、Qwen 3.5 等在路上。海外圈把这波节奏形容为“血流成河”，认为中国开放模型在性能和价格上成体系冲击。  
 > 相关链接：[Reddit 总结贴：是否进入中国 Agent 战争时代](https://www.reddit.com/r/LocalLLaMA/comments/1r1x0qi/glm_50_minimax_25_just_dropped_are_we_entering/)｜[相关新闻讨论](https://twitter.com/teortaxesTex/status/2021586965594857487)  

##### **xAI 两位联合创始人 48 小时内相继离职**  
xAI 联合创始人 Jimmy Ba 等人在两天内相继宣布离开，公司高层震荡引发“发生了什么”的猜测。社群解读包括：SpaceX 收购/期权套现后功成身退，或者不满 Elon 掌控欲、希望在别处有更大话语权。  
 > 相关链接：[Jimmy Ba 离职声明](https://www.reddit.com/r/singularity/comments/1r1k3td/another_cofounder_of_xai_has_resigned_making_it_2/)  

##### **高级 AI 人才持续“出走”：OpenAI 广告决策触发内部反弹**  
OpenAI 研究员 Zoë Hitzig 在纽约时报发文，因公司计划在 ChatGPT 里测试广告而辞职，担心依托用户海量私密对话做“行为定向”，重走 Facebook 老路。她主张用交叉补贴、独立治理等方式维持免费访问，而不是把整个平台广告化。  
 > 相关链接：[Zoë Hitzig 专栏](https://www.nytimes.com/2026/02/11/opinion/openai-ads-chatgpt.html)｜[Reddit 讨论贴](https://www.reddit.com/r/OpenAI/comments/1r1z1jl/openai_is_making_the_mistakes_facebook_made_i_quit/)  

##### **Nebius 收购 Tavily：云厂商开始“打包”智能搜索能力**  
云服务商 Nebius 宣布收购智能搜索初创 Tavily，把“Agentic Search”能力直接并入自家 AI 云平台。Tavily 去年刚融资，这次被并说明云厂商更倾向买现成能力而不是自己重做一遍。  
 > 相关链接：[Nebius 官方新闻稿](https://nebius.com/newsroom/nebius-announces-agreement-to-acquire-tavily-to-add-agentic-search-to-its-ai-cloud-platform)  

##### **Stripe 上线“机器支付”：直接向 AI Agent 收钱**  
Stripe 推出新功能，允许开发者直接向“机器用户”收费，把 AI Agent 当成一种新的付费主体。官方定位是：当 Agent 能自己消费服务和 API 时，需要一套账单/额度体系来管理它们的经济行为。  
 > 相关链接：[Stripe 功能介绍](https://twitter.com/jeff_weinstein/status/2021331763960873058)  

##### **Cloudflare 年营收突破 20 亿美元，高度受益 AI 流量**  
Cloudflare 公布 2025 年财报，年收入破 20 亿美元，财报后股价盘后涨超 15%。社区舆论认为，AI 流量增长、大模型推理对网络加速和安全的需求，是其增长的重要驱动之一。  
 > 相关链接：[Cloudflare 财报新闻稿](https://www.businesswire.com/news/home/20260210624682/en/Cloudflare-Announces-Fourth-Quarter-and-Fiscal-Year-2025-Financial-Results)  

##### **DeepMind 推出数学研究 Agent Aletheia，干翻自家 Gemini Deep Think**  
Google DeepMind 公开数学研究 Agent Aletheia，在 IMO-ProofBench Advanced 上拿到 91.9%，超过 1 月版 Gemini Deep Think，且算力消耗更低。团队计划把这套方法扩展到物理和计算机科学研究。  
 > 相关链接：[sair.foundation 博文](https://sair.foundation/)｜[Aletheia 成绩讨论](https://x.com/hangsiin/status/2021652990831292912)  

##### **Cloud/工具社区对 Discord 强制实名反弹，部分考虑迁往 Matrix**  
Discord 引入部分内容需身份证验证的新政策，引发 Unsloth、Cursor、Nous 等开发者社区强烈不满，有人直接表示“不会上传证件”。Latent Space 认为这与 Discord 上市前的合规压力有关，也有人开始认真讨论转到 Matrix/Mastodon 等去中心化平台。  
 > 相关链接：[Discord 政策说明推文](https://vxtwitter.com/discord/status/2021295316469940606)  

 

---  


#### **政策、治理与安全**  
##### **Seedance 2.0 因“照片克隆人声”隐私风险被叫停**  
ByteDance 暂停了 Seedance 2.0 中“从人脸照片生成个人声音”的功能。技术上是双分支扩散架构，但实测显示可以合成出与真人高度相似的声音，引发监管和伦理担忧：容易被用于身份冒用、骗声、深度伪造。  
 > 相关链接：[TechNode 报道](https://technode.com/2026/02/10/bytedance-suspends-seedance-2-0-feature-that-turns-facial-photos-into-personal-voices-over-potential-risks/)｜[Reddit 讨论与质疑](https://www.reddit.com/r/singularity/comments/1r0yr96/seedance_2_pulled_as_it_unexpectedly_reconstructs/)  

##### **AI 安全与监管：美国政府拒绝支持 2026 国际 AI 安全报告引争议**  
一条广泛传播的梗图把近期一连串 AI 负面新闻放一起：Anthropic 安全负责人离职、xAI 联创出走、Seedance 替代电影人技能、Yoshua Bengio 警告、以及美国政府决定不支持 2026 国际 AI 安全报告。舆论把这些拼成“监管真空+商业压力”的警示。  
 > 相关链接：[Miles Deutscher 梗图推文](https://www.reddit.com/r/OpenAI/comments/1r25bh7/in_the_past_week_alone/)  

##### **Jailbreaking 社区：从 GPT-5.2 到 Opus 4.6，攻防继续升级**  
BASI Jailbreaking 社区已经有能绕过 GPT-5.2、Gemini 3 Fast 的越狱提示，并积极分享；同时发现 Opus 4.6 在 Google Antigravity 环境里更容易被用来生成钓鱼包等有害内容。另一组讨论则强调，应通过 ACL、allowlist 把“模型能看到什么”硬写死，而不是幻想提示词能挡住所有攻击。  
 > 相关链接：[GPT 5.2 越狱讨论](https://discord.com/channels/1105891499641684019/1228043845967544380/1470873872415854755)｜[ACL/allowlist 安全讨论](https://discord.com/channels/1105891499641684019/1204553141354504193/1470918810151420177)  

##### **Parapet 多轮攻击检测：90.8% 召回、1.2% 误报且不用大模型分类器**  
Parapet 提出一套针对代理/对话的多轮打分公式，在 WildJailbreak 和 WildChat 上做到 90.8% 召回、1.20% FPR，全程不依赖额外 LLM 做分类，代码和评测脚本完全开源，适合作为现有 Agent 系统的“前置防火墙”。  
 > 相关链接：[Parapet 论文 PDF](https://github.com/Parapet-Tech/parapet/blob/main/paper/paper.pdf)｜[代码仓库](https://github.com/Parapet-Tech/parapet)  

 

---  

  
