#### **模型与能力**  
##### **Anthropic 推出 Claude Sonnet 4.6：1M 上下文，逼近 Opus，成本与质量新权衡**  
Anthropic 发布 Sonnet 4.6，号称“最强 Sonnet”，在编码、电脑操作、长上下文推理、Agent 规划等全面升级，并提供 100 万 token 上下文（beta），定价与 4.5 相同。第三方 GDPval-AA 评测中 ELO 1633、排第一，但为拿到这个成绩，整体 token 消耗约是 Sonnet 4.5 的 4.8 倍、也高于 Opus 4.6，因此在复杂任务上总成本可能反而更高。SWE-bench Verified 公布为 79.6%，ARC-AGI-2 为 58.3%，内部偏好测试里，用户在 59% 情况下更喜欢它而不是 Opus 4.5。上线初期一度出现函数名幻觉、结构化输出变糟的反馈，随后很快被修复。  
 > 相关链接：[官方发布：Claude Sonnet 4.6](https://www.anthropic.com/news/claude-sonnet-4-6)｜[Anthropic 官方推文](https://x.com/claudeai/status/2023817132581208353)｜[Anthropic 员工能力解读与工具更新](https://x.com/alexalbert__/status/2023817479580221795)｜[SWE-bench、ARC 等基准数据汇总](https://x.com/scaling01/status/2023818940112327101)｜[Artificial Analysis：GDPval-AA 详细评测与 token 用量](https://x.com/ArtificialAnlys/status/2023821893846135212)｜[Reddit：Sonnet 4.6 发布讨论帖 1](https://www.reddit.com/r/singularity/comments/1r7d9pe/sonnet_46_released/)｜[Reddit：Sonnet 4.6 发布讨论帖 2](https://www.reddit.com/r/ClaudeAI/comments/1r7d6am/this_is_claude_sonnet_46_our_most_capable_sonnet/)｜[Reddit：Sonnet 4.6 代码/基准讨论](https://www.reddit.com/r/ClaudeCode/comments/1r7dycb/claude_sonnet_46_just_dropped_and_the_benchmarks/)  

##### **Qwen3.5-397B-A17B：阿里开源 397B MoE，多模态、百万上下文，对标 GPT‑5.2/Opus**  
阿里发布 Qwen3.5-397B-A17B：总参数 397B、激活 17B 的 MoE 结构，支持原生 262K 上下文并可扩展到 100 万，覆盖 200+ 语言和图文视频等多模态。官方宣称在指令遵从、多语知识、视频理解等多项基准上接近 GPT‑5.2、Claude Opus 4.5、Gemini 3 Pro。社区已提供 GGUF 量化版，可在高内存 Mac 或多卡本地跑，但 VRAM 要求极高，更多适合作为云端/集群模型。  
 > 相关链接：[Qwen 官方博客：Qwen 3.5 系列](https://qwen.ai/blog?id=qwen3.5)｜[Hugging Face：Qwen3.5-397B-A17B](https://huggingface.co/Qwen/Qwen3.5-397B-A17B)｜[Unsloth GGUF 版本（本地量化）](https://huggingface.co/unsloth/Qwen3.5-397B-A17B-GGUF)｜[Reddit：Qwen3.5-397B 发布与硬件讨论](https://www.reddit.com/r/LocalLLaMA/comments/1r656d7/qwen35397ba17b_is_out/)｜[Reddit：Qwen3.5 视觉推理与基准讨论](https://www.reddit.com/r/LocalLLaMA/comments/1r6h3ha/difference_between_qwen_3_maxthinking_and_qwen_35/)｜[综合介绍：Qwen3.5 对标 GPT‑5.2 文章](https://medium.com/reading-sh/alibaba-just-open-sourced-a-model-that-rivals-gpt-5-2-708502e25250)  

##### **GLM‑5 技术报告：国产大模型强调 DSA、异步 RL 与 Agent 训练**  
Zhipu 发布 GLM‑5 技术报告和 demo，社区测试显示在 WeirdML 等基准上表现强劲，接近甚至超过部分闭源模型。报告重点介绍 DSA 结构、异步强化学习基础设施以及针对 Agent 场景的 RL 算法。实测中也有开发者反馈：在某些 IDE/插件里表现不如宣传，推测与集成和推理栈有关。  
 > 相关链接：[GLM‑5 技术报告 arXiv:2602.15763](https://arxiv.org/abs/2602.15763)｜[GLM‑5 能力展示视频](https://www.youtube.com/watch?v=vtWMgVCMsx8)｜[社区基准与讨论（含 WeirdML 数据）](https://x.com/htihle/status/2023734346943775179)  

##### **Tiny Aya：Cohere 推出 3.35B 多语小模型，号称“手机可跑”**  
Cohere Labs 发布 Tiny Aya 系列，3.35B 参数、多语言（70+），定位在手机/边缘设备运行的开放模型。据称仅用 64 块 GPU 就完成训练，并附详细技术报告。目标是做“能实际部署”的多语助手，而不是追求顶级基准分。  
 > 相关链接：[官方介绍推文](https://x.com/nickfrosst/status/2023756803717427467)｜[技术细节与模型卡片](https://x.com/_akhaliq/status/2023771434347044890)  

 

---  


#### **Agent 与工具链**  
##### **OpenClaw 爆红也爆雷：强力多 Agent 框架，引发封号与安全争议**  
OpenClaw 以“多 Agent 操作真实电脑”为卖点在社区疯狂扩散，用户用它做项目管理、CRM、浏览器自动化等。但因为通过 OAuth 接入 Claude，有用户报告被 Anthropic 封号，被指涉嫌“逆向/违规第三方接入”。同时大家担心：给 LLM 读写本机、浏览器和密钥的权限，一旦 prompt injection 或恶意 skill 出问题，后果很难控。  
 > 相关链接：[OpenClaw 官网与 Showcase](https://openclaw.ai/showcase)｜[社区安全讨论节选（Yannick 频道）](https://www.youtube.com/watch?v=CAbrRTu5xcw)｜[Microclaw：为 OpenClaw 训练的轻量回退 Agent](https://huggingface.co/webxos/microclaw-for-openclaw-version-2026.2.17)｜[ClawRecipes：社区开源的 OpenClaw 团队/Agent 配方](https://github.com/JIGGAI/ClawRecipes)  

##### **LangChain 等推动“Harness Engineering”：把真实日志变成 Agent 测试场**  
LangChain 官方在强调“harness engineering”：把线上 trace 挖出来，做成自动化评测和自验证循环，用来迭代 Agent 流程，而不是只看离线基准。配套有 TerminalBench 等终端类任务评测，以及 LangSmith Insights 定时跑批评估。  
 > 相关链接：[LangChain Harness Engineering 相关讨论](https://x.com/Vtrivedy10/status/2023812467034329224)｜[LangSmith Insights 更新](https://x.com/LangChain/status/2023804855136165932)｜[OpenAI 官方 Harness Engineering 博文（被吐槽营销味重）](https://openai.com/index/harness-engineering/)  

##### **MCP 正式讨论“工具要不要收费”：协议里加支付信号**  
Model Context Protocol 社区提出 SEP‑2007，希望让 MCP 服务器能通过协议返回“需要付费”的信号（起步是 X402），方便 Agent 在预算内自动调用付费工具。维护者态度偏谨慎：不想太早把支付硬写进协议本身，更倾向先用 URL 跳转这类方式，短期内不太会成为核心优先级。  
 > 相关链接：[MCP 支付提案 PR #2007](https://github.com/modelcontextprotocol/modelcontextprotocol/pull/2007)｜[资源规范清理 PR #2093](https://github.com/modelcontextprotocol/modelcontextprotocol/pull/2093)  

##### **DirectShell：把操作系统无障碍层变成“统一应用接口”，号称一键淘汰截图式 Agent**  
DirectShell 用系统无障碍接口直接操控应用，不再靠截图+坐标点击。作者放话：2 月 17 日之后，所有基于截图的 Agent/RPA 都是“旧时代技术”。本质是把 Accessibility layer 抽象成统一 DOM/控件树，让任何窗体软件都像 Web 一样可脚本化，对 PC 端 Agent 十分关键。  
 > 相关链接：[技术博客：DirectShell 设计](https://dev.to/tlrag/-directshell-i-turned-the-accessibility-layer-into-a-universal-app-interface-no-screenshots-no-2457)｜[DirectShell 开源仓库](https://github.com/IamLumae/DirectShell)  

 

---  


#### **基础设施与硬件**  
##### **GPU MODE 社区实战：单卡 B200 / RTX 系列榨干 TFLOPS 与 MoE 推理**  
GPU MODE 里多位工程师公开了自研 matmul 和 FlashInfer baseline 调参细节：有人在自写 CUDA 持久化 kernel 上做到 ~350→368 TFLOPS，有人用 FlashInfer 的 MoE baseline 在 B200 上做到 5.7× 加速；同时也在讨论 FP8/FP4 的数值误差、Nsight Compute 与 CUDA events 的正确用法，以及如何把 MAMF（可达算力）逼近理论峰值。这些经验对自己写 kernel/优化推理栈的同学非常有参考价值。  
 > 相关链接：[theCudaBender matmul_V3 源码](https://github.com/PranavDeepakSathya/theCudaBender/tree/main/matmul_V3)｜[FlashInfer mlsys26 agent baseline](https://github.com/flashinfer-ai/mlsys26-agent-baseline)｜[NVIDIA Cutlass 示例（参考异步流水与 pipelining）](https://github.com/NVIDIA/cutlass/blob/291300ffffa3533a78ee104f08a8490a29ce9ccb/examples/python/CuTeDSL/ampere/tensorop_gemm.py#L618-L641)｜[理论/可达 FLOPs 计算参考](https://github.com/stas00/ml-engineering/tree/master/compute/accelerator#maximum-achievable-flops)  

##### **CoDA‑GQA‑L：KV Cache 从 160GB 压到 136MB 的“有界记忆注意力”**  
Eleuther 社区推出 CoDA‑GQA‑L，把每层 KV 缓存固定成 384 个 slot：256 个最近 token、64 个“地标”token、64 个指数滑动平均摘要，在长序列上把 KV 占用从 160GB 压到 136MB。对要做 1M 上下文但又扛不住显存账单的应用（搜索、长文写作、长任务 Agent）是很现实的一条路。  
 > 相关链接：[CoDA‑GQA‑L 论文（Zenodo）](https://zenodo.org/records/18663265)｜[CoDA‑GQA‑L 代码仓库](https://github.com/anthony-maio/CoDA-GQA-L)  

##### **MXFP4 / NVFP4：FP4 真吃 Blackwell，老卡跑不出优势**  
Unsloth 与 Modular 社区都确认：MXFP4 这类 FP4 格式的“爽点”在 Blackwell（算力等级≥12.0）原生 Tensor Core 上才能体现，在 Ampere 之类老卡上需要模拟，往往比 FP8 还慢。NVFP4 目前是 MAX 的重点优化对象，MXFP4 支持会滞后一些。这意味着你现在就上 30 系卡+FP4，很可能是在交 IQ 税。  
 > 相关链接：[Unsloth 关于 MXFP4 的说明](https://unsloth.ai/docs/new/faster-moe#important-unsloth-updates)｜[Modular 论坛：MAX 自定义内核与 NVFP4 讨论](https://forum.modular.com/t/max-models-can-now-use-customized-mojo-kernels-and-standard-library/2742)  

##### **云推理“不响但挂”：OpenRouter/HF/Perplexity 轮番 401 与 500，生产要准备“重建端点”预案**  
OpenRouter 出现大面积 401，官方开“战情室”排查并修复；Perplexity API 用户则遇到有余额但一直 401 的情况，只能走人工支持；Hugging Face Inference Endpoint 上则有人在状态页全绿时频繁打到 500“service panicked”，最后只能删掉重建 endpoint 并迁移生产流量。对自己也跑云推理的团队，一个现实经验是：要准备好“端点不可解释地炸了就全量重建”的应急脚本。  
 > 相关链接：[OpenRouter 状态页面](https://status.openrouter.ai/)｜[Hugging Face 状态页面](https://status.huggingface.co/)  

 

---  


#### **研究与方法**  
##### **Agent World Model / Lossless Context Management：Agent 训练与长上下文压缩的新玩具**  
研究圈同时在搞两件事：一是 Agent World Model，搞了 1000 个可执行环境、35062 个工具、1 万任务，用 RL 训练工具使用 Agent；二是 Lossless Context Management (LCM/Volt)，用分层 DAG 做“可恢复引用”的压缩，在 OOLONG 上据称从 32K 到 1M 上下文都比 Claude Code 更稳。这些东西的共同点：不指望“直接喂 1M token”，而是围绕工具和结构化记忆动手脚。  
 > 相关链接：[Agent World Model 简介](https://x.com/dair_ai/status/2023748787949498804)｜[LCM / Volt 上 OOLONG 的表现](https://x.com/dair_ai/status/2023765147970662761)  

##### **Moltbook：260 万 Agent “社会实验”，结果是——宏观文化会稳，个体影响几乎是噪声**  
一篇多 Agent 社会模拟论文（Moltbook）里，作者放了 260 万个 LLM Agent，产出 30 万帖子和 180 万评论，结果发现：整体文化和话语风格会收敛并稳定，但单个 Agent 的“意见领袖”效应极弱，几乎被统计噪声淹没。这给很多“加一层 Agent 就是 AGI”的想象泼了冷水。  
 > 相关链接：[概述与讨论](https://x.com/omarsar0/status/2023766916473733394)  

##### **Every Eval Ever：给大模型评测搞一个“BIDS 标准”**  
EvalEval 联盟发起“Every Eval Ever”，想给各种 LLM benchmark 建一个统一的数据/元数据标准，有点像脑成像界的 BIDS。背景是最近像 Cybench 这种基准暴露出“flag 没随机化导致成绩虚高”的问题，修一下设计 benchmark 的 bug，模型排名就能大变样。  
 > 相关链接：[Every Eval Ever 项目介绍](https://evalevalai.com/infrastructure/2026/02/17/everyevalever-launch/)｜[Cybench 官方站点](https://cybench.github.io)  

##### **预防式 Steering：在表示空间里“加干扰”，逼模型保持目标不变**  
Eleuther 讨论 Anthropic persona vector 里的“preventative steering”思想：不是在输入输出上加约束，而是在中间表示上加一个 steering 向量，再看模型能不能仍然达到原目标。进一步的想法是：把这种“带干扰还要命中目标”当成一种数据增强，在表示空间做训练，而不是一味往外扩数据集。  
 > 相关链接：[社区讨论与相关论文引用](https://arxiv.org/abs/2602.15029)｜[讨论摘要（interpretability-general 渠道）](https://github.com/MrPan2048/GeometricTransformer/blob/main/lookup/lookup.md)  

 

---  


#### **产品与应用落地**  
##### **Sonnet 4.6 快速铺货：Cursor、Perplexity、Windsurf、Cline 等开发工具全上线**  
Sonnet 4.6 一天内出现在 Cursor、Windsurf、Cline、Perplexity、OpenRouter 等多个平台：Cursor 认为它在长任务上明显好于 4.5，但“智力”仍略逊 Opus 4.6；Cline 给了短期免费试用，内部 A/B 中 70% 开发者更喜欢 4.6；Perplexity Pro/Max 也把它接入 Deep Research/浏览器 Agent。整体趋势：Sonnet 4.6 正在成为“高性价比主力”，Opus 留给“要极限质量”的场景。  
 > 相关链接：[Cursor 上线 Sonnet 4.6 推文](https://x.com/cursor_ai/status/2023841746577485894)｜[Windsurf 宣布支持 Sonnet 4.6](https://x.com/windsurf/status/2023820911955374112?s=20)｜[Cline 集成 Sonnet 4.6 并限时免费](https://www.reddit.com/r/CLine/comments/1r7l3tp/claude_sonnet_46_is_live_in_cline_v3640_and_its/)｜[Perplexity：Sonnet 4.6 加入 Pro/Max](https://x.com/perplexity_ai/status/2023839622242206179)｜[Comet 浏览器 Agent 使用 Sonnet 4.6](https://x.com/comet/status/2023889197556441464)  

##### **PolyAI 融资 2 亿美金，同时推出 5 分钟搭好语音 Agent 的 Studio Lite**  
做电话客服起家的 PolyAI 宣布拿到 2 亿美元新融资（Nvidia、Khosla 等参投），并推出 Agent Studio Lite：贴一个网站 URL，5 分钟生成可用的语音客服 Agent，面向品牌客户开放 3 个月免费试用。语音 AI 这条线从“单一客服脚本”开始，已经往“自助搭建语音 Agent 平台”演进。  
 > 相关链接：[PolyAI 融资与产品更新](https://x.com/polyaivoice/status/2023789465509015972?s=46)  

##### **SpeakType：Mac 上完全本地的开源听写应用，Whisper 系列的又一实现**  
一位开发者做了 Mac 平台本地听写工具 SpeakType，全部离线运行（基于 Whisper），开源并招募测试者，主打隐私和不用云费用。社区在问的点主要是：RAM/CPU 占用、是否带 VAD（语音活动检测）做前处理，以及相对其他本地听写工具（比如 Handy）的差异。  
 > 相关链接：[Github：SpeakType](https://github.com/karansinghgit/speaktype)｜[产品页](https://tryspeaktype.com/)｜[Reddit 讨论串](https://www.reddit.com/r/LocalLLM/comments/1r7bohc/macos_built_a_100_local_opensourced_dictation_app/)  

##### **Manus Agents：把“长期记忆”的个人 Agent 塞进 Telegram**  
Manus 推出“Manus Agents”，本质是一个带长期记忆和工具集成的个人 Agent，直接通过 Telegram 使用，可连 Gmail、Notion，帮你生成视频、PPT、网页等。更像是“把一套 AI 桌面/工作流，压缩进一个聊天机器人”。  
 > 相关链接：[Manus Agents 官宣](https://x.com/manusai/status/2023412626428932494?s=12)  

##### **AI 模拟开餐车：12 个模型拿 2000 美金，只有 4 个没破产**  
有开发者给 12 个 LLM 每个 2000 美金和一辆餐车，跑 30 天模拟。结果只有 4 个模型存活，Claude Opus 4.6 赚到约 4.9 万美金，GPT‑5.2 约 2.8 万；几乎所有主动贷款的模型都破产。这个“Food Truck Bench”加上 Vending-Bench 2，再次说明：会疯狂扩张和借钱的 Agent，现实里大概率先死。  
 > 相关链接：[Reddit：Food Truck 实验贴](https://www.reddit.com/r/LocalLLaMA/comments/1r77swh/i_gave_12_llms_2000_and_a_food_truck_only_4/)｜[Vending-Bench 2 官方页面](https://andonlabs.com/evals/vending-bench-2)  

 

---  


#### **行业与公司动态**  
##### **Mistral 收购 Koyeb：自己造“推理云”，不再只卖模型**  
Mistral 计划收购无服务器平台 Koyeb，把对方的平台和团队并入自家的 Mistral Compute 基础设施。简单说就是从“只卖 API 的模型公司”，变成“模型+算力一体”的云厂商，和 OpenAI、Anthropic、xAI 那条路更像了。  
 > 相关链接：[官方收购公告推文](https://x.com/yann_eu/status/2023777413742948736?s=20)  

##### **Grok 4.20：一边被说“只是四个 Grok 4.1 agent 拼在一起”，一边被骂政治偏见重**  
xAI 发布 Grok 4.20，宣称是新架构，但社区拆日志发现模型 ID 仍是 grok‑4‑1‑thinking‑1129，被调侃是“四个 Grok 4.1 agent 穿风衣”。同时，Reddit 上大量吐槽其在性别/政治话题上直接复读 Musk 立场，性能上也被不少人认为比自家 Flash 系列和同级闭源模型差不少。  
 > 相关链接：[Grok 4.20 被“4 个 Agent 穿风衣”梗图](https://www.reddit.com/r/singularity/comments/1r75lya/grok_420_is_just_four_grok_41_agents/)｜[关于 Grok 4.20 偏见的讨论](https://www.reddit.com/r/singularity/comments/1r74iow/the_newly_released_grok_420_uses_elon_musk_as_its/)  

##### **Anthropic 对军方放行 Claude，但画了两条红线**  
Eleuther 社区有人提到：Anthropic 同意美国军方在一定范围内使用 Claude，但明确限制两点：不能用于大规模监视，也不能用于自主武器。这个立场比很多公司含糊其辞要直接，也说明“安全组织”与“接国防订单”之间的张力开始摆到台面上讲。  
 > 相关链接：[Eleuther Discord 讨论摘录](https://discord.com/channels/729741769192767510/729741769738158194)  

##### **PolyAI、Waymo 等“非纯模型公司”：AI 正在吞掉客服与 Robotaxi**  
除了大模型本身，应用公司里也有两个典型样板：PolyAI 靠语音客服拿下 Marriott 等大客户，最新一轮融资 2 亿美金，并开始做“5 分钟搭语音 Agent”平台；Waymo 则在论文和推文里吹自己的第六代 Robotaxi 平台，单车成本现在约 7 万美金，预估到 2028 年能再砍一半，目前每周无司机订单超过 50 万单、年增速 3 倍。  
 > 相关链接：[PolyAI 融资与 Agent Studio Lite](https://x.com/polyaivoice/status/2023789465509015972?s=46)｜[Waymo 经济性分析贴](https://x.com/fchollet/status/2023522267846815874?s=12)  

 

---  


#### **政策、治理与安全**  
##### **OpenClaw + OAuth 引发封号：Anthropic 被指把第三方桌面 Agent 视作“逆向”**  
OpenClaw 用户反馈，使用 Claude 账号 OAuth 接入后被官方封号，有人贴出 TOS 解释：用 OAuth 接第三方桌面控制工具，被视为“逆向网络/未授权第三方软件”，违反条款。这对所有想做“跨应用桌面 Agent”的团队是个提醒：不要指望直接拿大厂 Web OAuth 当免费后端，最好走官方 API 或自建模型。  
 > 相关链接：[OpenClaw Discord 中的 TOS 讨论](https://discord.com/channels/1456350064065904867/1456350065223270435)  

##### **BASI 社区红队与暗网情报：GitLab 项目被拍卖、Tor 上“无限制 AI”**  
BASI Jailbreaking 社区一边玩各种模型越狱，一边分享真实安全事件：有人在暗网声称拍卖三个拥有 maintainer 权限的 GitLab 项目（PHP/Laravel 栈），起拍 200 美金、闪拍 2000 美金；另有人在 Tor 上挂“无限制 AI”服务，社区一边好奇一边提醒里面可能有木马或滥用 Claude 的行为。这类例子说明：LLM 技术和传统黑灰产已经在同一个圈子里混到一起了。  
 > 相关链接：[GitLab 项目拍卖 X 帖](https://x.com/darkwebinformer/status/2022856387542294703?s=46)｜[BASI redteaming 频道摘要](https://discord.com/channels/1105891499641684019/1204553141354504193)  

##### **API 密钥泄露与滥用再现：OpenRouter 用户 20 分钟被刷掉 10 美金**  
有 OpenRouter 用户发现自己 API key 在 gitignore 文件里仍 somehow 泄露，被第三方通过某个“Cloud Code”环境在 20 分钟内刷掉 10 美金额度；Perplexity、其它平台也有类似“突然 401 或额度被耗尽”的个案。给 Agent 和脚本配 key 时，最现实的建议还是老三样：最小权限、定期轮换、上线前整仓扫描密钥。  
 > 相关链接：[OpenRouter 用户泄露案例讨论](https://discord.com/channels/1091220969173028894/1094454198688546826)  

##### **Cybench“旗子没随机”翻车：一次设计疏忽就能让防御评测高估一大截**  
Stanford 的 Cybench 安全基准被指出一个问题：早期版本用的是知名 CTF 的固定 flag，结果模型能靠记忆/训练数据直接命中，成功率虚高；随机化 flag 之后，成功率陡降。这个案例很好地说明：安全/红队评测如果场景设计不严谨，很容易得到漂亮但没什么实际含义的数字。  
 > 相关链接：[Cybench 官方站点](https://cybench.github.io)｜[Nous 社区讨论与更正说明](https://discord.com/channels/1053877538025386074/1149866623109439599)  

 

---  

  
