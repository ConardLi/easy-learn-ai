#### **模型与能力**  
##### **X 开源 “For You” 推荐算法，基于 Grok Transformer**  
X 工程团队开源首页推荐算法，称其使用与 xAI Grok 相同的 Transformer 架构。社区快速拆图：候选生成与排序分离、几乎不用内容特征、强调站外内容发现。创作者同时抱怨近期“流量被清零”，说明开源架构不等于体验更公平。  
 > 相关链接：[XEng 开源公告](https://twitter.com/XEng/status/2013471689087086804)｜[架构拆解与质疑](https://twitter.com/nearcyan/status/2013527283399545064)｜[创作者流量反馈](https://twitter.com/giffmana/status/2013509540843606156)  

##### **GLM‑4.7‑Flash：30B MoE 本地大模型狂飙**  
zai-org 发布 GLM‑4.7‑Flash（30B‑A3B MoE），支持 20 万上下文，官方强调 MLA 极大压缩 KV cache。社区在 Hugging Face、llama.cpp、Unsloth GGUF 等多处实测，普遍认为推理质量接近更大模型，是当前本地跑通用和 Agent 场景的热门选择。  
 > 相关链接：[官方模型卡](https://huggingface.co/zai-org/GLM-4.7-Flash)｜[Reddit 模型讨论与跑分](https://www.reddit.com/r/LocalLLaMA/comments/1qh5wdq/zaiorgglm47flash_hugging_face/)｜[Arena 图像榜 GLM-Image 排名](https://twitter.com/arena/status/2013783860023062990)  

##### **GLM‑4.7‑Flash 本地生态：llama.cpp / GGUF / 多机并行全上**  
社区已把 GLM‑4.7‑Flash 接入 llama.cpp（含 MoE Lite 版本）、Unsloth GGUF，并在 4090、M3 Ultra、4×Mac mini 等硬件上跑通。有人在 4× M4 Pro Mac mini 上做张量并行，实测 ~100 tok/s，目标 200 tok/s，说明该模型已被当作“本地主力工作马”来调优。  
 > 相关链接：[llama.cpp 支持 PR 及讨论](https://www.reddit.com/r/LocalLLaMA/comments/1qhitrj/glm_47_flash_official_support_merged_in_llamacpp/)｜[Unsloth GLM‑4.7‑Flash GGUF](https://huggingface.co/unsloth/GLM-4.7-Flash-GGUF)｜[多机并行实测推文](https://twitter.com/alexocheema/status/2013694573910937980)  

##### **GLM‑4.7‑Flash 量化翻车：首次出现“高比低更差”的怪现象**  
多位开发者反馈 GLM‑4.7‑Flash 在高比特量化时反而更爱复读、逻辑变差，Q2_KXL 体验优于 Q6_KL，这在以往模型中极少见。问题在 llama.cpp、Ollama 都能复现，被怀疑是量化流水线或 MLA+MoE 组合导致的实现 bug，而不是简单采样参数问题。  
 > 相关链接：[llama.cpp 相关 issue](https://github.com/ggml-org/llama.cpp/pull/18936#issuecomment-3774525719)｜[Unsloth 对循环/复读的参数建议](https://twitter.com/danielhanchen/status/2013496370880008395)  

##### **Liquid AI 推出 LFM2.5‑1.2B “Thinking” 小模型，上 Ollama**  
Liquid 发布 12 亿参数的 LFM2.5‑1.2B‑Thinking，主打本地可跑、带简洁思维链、工具调用和数学能力，内存占用约 900MB，定位手机/轻端设备。Ollama 已第一时间上线该模型，方便直接在本地应用里切换测试。  
 > 相关链接：[Liquid 官方发布](https://twitter.com/liquidai/status/2013633347625324627)｜[模型评测与用法](https://twitter.com/maximelabonne/status/2013631295172084168)｜[Ollama 集成公告](https://twitter.com/ollama/status/2013711111590150590)  

##### **Gemini 3 Pro/Live 传闻升级：思考模式、UI 控制和本机 Agent**  
社区爆料 Gemini 3 Pro GA 模型正在 A/B 测试，被形容为“像 3.5”；同时 Android 端 Gemini Live 准备上线 Thinking Mode、多模态记忆、更强降噪以及“UI 控制”“Deep Research”等功能，目标是让手机端 Agent 直接操作系统完成任务。  
 > 相关链接：[Gemini 3 Pro 传闻帖](https://www.reddit.com/r/singularity/comments/1qh591s/rumors_of_gemini_3_pro_ga_being_far_better_like_35/)｜[Gemini Live 新功能挖掘](https://www.reddit.com/r/Bard/comments/1qhf7zz/gemini_live_preps_big_upgrades_with_thinking_mode/)  

##### **BabyVision：LLM 视觉推理离“12 岁小孩”还差一截**  
BabyVision-Mini 基准对比人类和多模态 LLM 的视觉推理，结果是 12 岁小孩明显胜过目前主流模型，Gemini3-Pro-Preview 在模型中最好但仍有差距。作者认为未来要靠更大规模的多模态预训练 + 强化学习提升，尤其利好机器人场景。  
 > 相关链接：[Reddit 讨论与图表](https://www.reddit.com/r/singularity/comments/1qh1omx/babyvision_a_new_benchmark_for_humanlevel_visual/)｜[论文链接（arXiv）](https://arxiv.org/abs/2512.2460)  

##### **LMArena 文本与图像竞技场达 500 万次对比，GLM‑Image 上榜**  
LMArena 宣布 Text Arena 已收集 500 万次用户两两对比投票，并更新图像榜：GLM‑Image 在开源图像模型中排第 8，总榜第 35（1018 分）。不过社区同时吐槽近期图像模型质量和服务稳定性下滑，经常遇到验证码和报错。  
 > 相关链接：[LMArena 公告](https://discord.com/channels/1340554757349179412/1343296395620126911/1463228800388042773)｜[帮助文档：错误排查](https://help.lmarena.ai/articles/1645798556-lmarena-how-to-something-went-wrong-with-this-response-error-message)  

 

---  


#### **Agent 与工具链**  
##### **Recursive Language Model（RLM）落地：DSPy 发布 dspy.RLM**  
DSPy 3.1.2 悄悄上线 dspy.RLM，用文件系统外置超长上下文，模型按需读写而不是一次性塞进 prompt，被视作更工程化的“递归大模型”。社区已经用它自动写文档、做长流程代码操作，并有 Elixir 版本移植。  
 > 相关链接：[RLM 发布推文](https://x.com/isaacbmiller1/status/2013371005960401327)｜[DSPy 仓库](https://github.com/stanfordnlp/dspy)｜[Elixir RLM 示例](https://github.com/nshkrdotcom/DSPex/tree/main/examples/rlm)  

##### **Claude Code + 本地模型工作流：Ollama/llama.cpp 开始上车**  
Ollama 刚加上对 Claude Code 消息 API 的官方支持，社区已经用 Claude 作前端编排、本地 Qwen/GLM 等作执行。实践发现：本地模型需要更细的指令和 prompt 工程，显存 24GB 以上才适合复杂工具调用和长上下文。  
 > 相关链接：[Claude Code + 本地模型讨论](https://www.reddit.com/r/ClaudeCode/comments/1qhj13v/has_anyone_tried_claude_code_with_local_model/)｜[Anthropic 网关文档（允许接其他 LLM）](https://docs.anthropic.com/en/api/gateways)  

##### **MCP 工具链现实：Inspector 认证 Bug、多家客户端踩坑**  
MCP Inspector 被集中反馈：遇到 401 不会重走授权流程，且 SDK 在重定向时丢失 resourceMetadata。官方已在服务器侧修补，SDK 更新还在路上。LM Studio 进一步吐槽官方 MCP SDK 架构脆弱、安全性差但“现实中还是最好用的一家”。  
 > 相关链接：[Inspector issue 及说明](https://github.com/modelcontextprotocol/inspector/issues/576#issuecomment-3766294454)  

##### **OpenRouter 新客户端：Discord 机器人 OkeyBot 和桌面多模型 Inforno**  
基于 OpenRouter 的 Discord 机器人 OkeyBot 已上线，支持 BYO key、按线程统计用量。桌面应用 Inforno 则支持 OpenRouter + Ollama，多模型并排聊天，并把历史保存为 .rno 文件，适合比较不同模型行为。  
 > 相关链接：[OkeyBot 官网](https://okeybot.ai/)｜[Inforno 简介视频](https://youtu.be/oJyj0mroFtY)｜[Inforno 源码](https://github.com/alexkh/inforno)  

##### **企业 Agent 监控：LangChain 推“Trace 洞察代理”，强调用真日志找问题**  
LangChain 认为每天 10 万+ traces 时，靠手看日志已不现实，发布“Insights Agent”做 trace 聚类和模式发现。作者强调：离线评测更像单元测试，真正的未知问题都在生产日志里，需要专门的 trace 分析工具链配合。  
 > 相关链接：[LangChain 官方推文](https://twitter.com/LangChain/status/2013642970944413905)｜[作者补充说明](https://twitter.com/hwchase17/status/2013662250167652491)  

 

---  


#### **基础设施与硬件**  
##### **17,000 美元“移动 10 卡怪物”：768GB 内存 DeepSeek 专用机**  
玩家自组 10 GPU 移动工作站：3995WX + 512GB 内存 + 8×3090 + 2×5090，塞进 Thermaltake Core W200 双系统机箱，主打 DeepSeek、Kimi K2 等 MoE 大模型和高质量图像/视频生成。Qwen 235B 跑到 ~31.5 tok/s，整机成本约 1.7 万美元。  
 > 相关链接：[LocalLLaMA 帖子 1](https://www.reddit.com/r/LocalLLaMA/comments/1qi4uj2/768gb_fully_enclosed_10x_gpu_mobile_ai_build/)｜[LocalLLM 帖子 2](https://www.reddit.com/r/LocalLLM/comments/1qi5q2v/768gb_fully_enclosed_10x_gpu_mobile_ai_build/)  

##### **本地 LLM “主权三年计划”：1 万刀预算怎么配机**  
有人想花约 1 万美元搭一套未来三年都够用的本地 LLM 环境，担心云端涨价和审查。社区建议：要么上 80 核 GPU + 512GB 内存的 M3 Ultra，要么配 128GB RAM + 高端 RTX（3090/4090），也有人主张买二手工作站 + 多张老卡，走渐进升级路线。  
 > 相关链接：[Reddit 讨论贴](https://www.reddit.com/r/LocalLLM/comments/1qhqf8p/llm_sovereignty_for_3_years/)  

##### **多卡/带宽细节：3090 仍是性价比王，DDR4 成推理瓶颈**  
关于“能否叠加两张显卡 VRAM”问题，大家再次强调：单模型加载无法简单拼显存，多卡主要用来并行或张量/流水并行。讨论普遍认为 3090 以 24GB VRAM 和高带宽近年依然是本地 LLM 香饽饽；另有自托管实测指出 DDR4 单通道约 25GB/s，对纯 CPU 推理的 tok/s 形成硬上限。  
 > 相关链接：[VRAM/多卡讨论](https://www.reddit.com/r/LocalLLM/comments/1qii3h2/can_i_add_a_second_gpu_to_use_its_vram_in/)｜[DDR4 带宽与 Phi-4 速度讨论](https://discord.com/channels/879548962464493619/879548962464493622/1462908479168843991)  

##### **YALI：号称比 NCCL 快 1.2–2.4 倍的 NVLink AllReduce 库**  
GPU MODE 社区有人开源 2 卡 NVLink AllReduce 库 YALI，声称吞吐比 NVIDIA NCCL 快 1.2–2.4 倍，尾延迟稳定度高 50 倍，核心做法是极端重叠计算与通信。也算是社区对官方集体通信库的一次“性能挑战书”。  
 > 相关链接：[YALI GitHub](https://github.com/Venkat2811/yali)  

##### **“B200 serverless” 与 GPU 云：Runpod 年入 1.2 亿美元**  
Runpod 被曝年化收入已到 1.2 亿美元，有人顺手写了在 Runpod 上一键部署 B200 的无服务器模板，用按量计费跑竞赛 kernel。整体趋势是：便宜高端 GPU 出租平台快速长大，开发者愈发依赖这类云端实验环境。  
 > 相关链接：[Runpod 融资报道](https://techcrunch.com/2026/01/16/ai-cloud-startup-runpod-hits-120m-in-arr-and-it-started-with-a-reddit-post/)｜[Runpod 讨论帖](https://www.reddit.com/r/LocalLLaMA/comments/1qib2ks/runpod_hits_120m_arr_four_years_after_launching/)  

##### **AMD Ryzen AI Halo 被吐槽：硬件不错，ROCm 驱动拖后腿**  
讨论认为 Ryzen AI Halo 在纸面上能挑战 NVIDIA，但 ROCm 驱动在 Linux 上问题一堆：FP8 等特性宣传有、实际用不了，用户常常要自己编译源码、修补闭源部分才能跑。唯一比较靠谱的是“最多 128GB 统一内存”这条卖点。  
 > 相关链接：[Reddit 经验帖](https://www.reddit.com/r/LocalLLM/comments/1qgueu7/amd_ryzen_ai_halo_for_ai_developers/)  

 

---  


#### **研究与方法**  
##### **Google“思想社会”与 Multiplex Thinking：推理模型不只是想得更久**  
Google 提出“Societies of Thought”观点：o1、DeepSeek-R1、QwQ 等推理模型的收益，很大一部分来自内部“辩论模式”而非单纯延长思考步数；另有“Multiplex Thinking”方法，用单步采 K 个 token 合并成一 token，不确定时分支探索、确定时收敛，以更短序列达到更好效果。  
 > 相关链接：[Societies of Thought 解读](https://twitter.com/rohanpaul_ai/status/2013431689889095767)｜[Multiplex Thinking 论文摘要](https://twitter.com/HuggingPapers/status/2013524300800627119)  

##### **蒸馏新思路：不用 KL，用“保持 token 排名”的 logistic loss**  
有研究者分享了一种更“工程友好”的知识蒸馏方法：从老师模型的 top‑K logits 中采样 token 对，让学生模型通过 logistic 损失学习 token 排名，而不是直接做 KL 或 SFT。这种做法易于在 PyTorch 里实现，已封装进 DistillKit。  
 > 相关链接：[方法介绍推文 1](https://twitter.com/cwolferesearch/status/2013468452774645876)｜[方法介绍推文 2](https://twitter.com/cwolferesearch/status/2013468538728513634)  

##### **DeepMind：合成推理数据“用小模型多采样”比“用大模型少采样”更值**  
DeepMind 一项实验总结：在相同推理算力预算下，用小一些的模型大量生成候选推理路径，比用大模型少量采样更好。小模型能带来更高覆盖度（+11%）和多样性（+86%），最终下游训练收益最高可达 31.6%。  
 > 相关链接：[结果总结](https://twitter.com/LiorOnAI/status/2013582631124771104)  

##### **RL on LLM 的“算力规模定律”雏形**  
有团队给出了针对 LLM 强化学习阶段的“算力分配指导”，试图像预训练 scaling law 一样，说明在给定总算力下该分多少步、每步多少样本、如何平衡探索与稳定性。虽细节未完全公开，但对预算敏感的 RLFT 项目很实用。  
 > 相关链接：[作者推文](https://twitter.com/ChengZhoujun/status/2013686575499223474)  

##### **NanoGPT“极限速通”：hash embedding + 反 Chinchilla 配置**  
有人用 bigram hash embedding 加入每层 residual，实现 ~99.3 秒跑完 NanoGPT 基准，并故意偏离 Chinchilla 推荐的 token/参数比例。思路借鉴了 Hash Embeddings 和 DeepSeek Engram，说明在小模型+自回归上仍有不少低层优化空间。  
 > 相关链接：[作者推文](https://twitter.com/classiclarryd/status/2013520088297558274)  

##### **文本→优化问题：有人在系统性把自然语言转成约束求解**  
HuggingFace 讨论区有人分享套路：把一段描述拆成“关系解析→变量与约束→能量函数→子问题分解”，再用 ADMM / message passing 合并求解，本质是把语言任务转成显式的数学优化问题，方便搞可解释的推理流程。  
 > 相关链接：[讨论串](https://discord.com/channels/879548962464493619/879548962464493622/1462908479168843991)  

 

---  


#### **产品与应用落地**  
##### **Claude Code 在微软内部被叫停，改推 GitHub Copilot**  
爆料称 Satya 亲自叫停微软内部推广 Claude Code，要求员工优先用自家 GitHub Copilot，理由是“差距基本补上了”。只有少量高优先级研发项目可继续用 Anthropic API。外界普遍解读为：更多是战略和产品打磨需要，而非能力完全持平。  
 > 相关链接：[Reddit 讨论贴](https://www.reddit.com/r/ClaudeAI/comments/1qgx6br/microsoft_pauses_claude_code_rollout_after_satya/)  

##### **开发者用 Claude + XGBoost 训练“甲亢预警器”，准确率 98%**  
一位 Graves 病患者用 Claude 帮忙清洗 9.5 年 Apple Watch/Whoop 数据，再用 XGBoost 训练模型，声称 98% 验证准确率，可提前 3–4 周预测复发，并已做 iOS 监控 App 开源。评论提醒要警惕数据泄漏，并建议做真正的“未来时间段”测试。  
 > 相关链接：[项目长文](https://medium.com/data-science-collective/i-gave-claude-code-9-5-years-of-health-data-to-help-manage-my-thyroid-disease-85fcd8c0449f)｜[Reddit 讨论](https://www.reddit.com/r/MachineLearning/comments/1qi8twv/p_i_gave_claude_code_95_years_of_health_data_to/)  

##### **Gemini 深度集成 Chrome 与 Android，朝“操作系统级 Agent”走**  
Chrome 里的 Gemini 集成功能被夸“看视频顺手就能查背景”，无需手动搜索。Android 端 Gemini Live 则准备加入“AI 控手机 UI 完成任务”“多应用数据整合做深度研究”等实验特性，离真正的手机 Agent 又近了一步。  
 > 相关链接：[Chrome 集成体验贴](https://www.reddit.com/r/Bard/comments/1qhzifv/gemini_integration_into_chrome_browser_is_just/)｜[Gemini Live 新功能解析](https://www.reddit.com/r/Bard/comments/1qhf7zz/gemini_live_preps_big_upgrades_with_thinking_mode/)  

##### **Perplexity 接入三星 Bixby，成手机默认“网页回答引擎”**  
三星宣布在 One UI 8.5 中，把 Perplexity 集成进新版 Bixby，用户问问题时可直接在 Bixby 内拿实时网络答案，而不用再跳浏览器。对 Perplexity 来说，这是一次重量级 OEM 级分发渠道。  
 > 相关链接：[SamMobile 报道](https://www.sammobile.com/news/samsung-new-bixby-for-one-ui-8-5-official-coming-to-beta-soon)  

##### **Manus.im：AI 填简历/表单很香，重度用户开始要 CLI 级控制**  
Manus 被用户夸在自动填写求职表单方面明显强于其他系统，但长期重度使用者抱怨：平台频繁更新导致旧模块时不时失效，希望能有 CLI 接口自己调试和重配，哪怕是付费高级功能。这是典型“从玩具到生产”的控制权需求。  
 > 相关链接：[Manus Discord 反馈](https://discord.com/channels/1348819876348825620/1349440650495398020/1462917497123639488)｜[Manus 招聘页](https://manus.im/careers)  

##### **“Before You Buy”：给商品链接自动生“该问哪几个关键问题”**  
一个新小工具 buywiser.vercel.app，只要贴上商品链接，就会自动生成一组“买前要问的关键问题”，并尝试用真实来源回答。无需登录，作者还在积极要反馈，算是 AI 辅助消费决策的轻量化尝试。  
 > 相关链接：[Before You Buy](https://buywiser.vercel.app/)  

 

---  


#### **行业与公司动态**  
##### **DeepSeek-R1 发布一周年：被视为仅次于 LLaMA 的关键转折点**  
社区回顾 DeepSeek-R1 一周年：开源代码和模型、MIT 许可，可免费商用，被认为迫使西方大厂降价、开放推理过程。很多人认为这是仅次于 LLaMA 的第二个“拐点时刻”，也让“非西方阵营”在大模型话语权上真正入局。  
 > 相关链接：[周年纪念帖 1](https://www.reddit.com/r/LocalLLaMA/comments/1qhs2sd/its_been_one_year_since_the_release_of_deepseekr1/)｜[周年纪念帖 2](https://www.reddit.com/r/DeepSeek/comments/1qgy3lk/one_year_since_the_deepseek_moment_the_impact_is/)｜[DeepSeek 聊天站点](https://chat.deepseek.com)  

##### **“欧洲版 DeepSeek” 竞赛启动：主权 AI 成显性国家战略**  
Wired 报道称，受中国 DeepSeek 启发，欧洲多国政府和实验室在推“主权 AI”计划，希望减少对美国云和模型的依赖，法国 Mistral、英国 DeepMind 等被视为种子选手。评论一方面承认欧洲人才多，另一方面吐槽监管和高税负会拖慢落地。  
 > 相关链接：[Wired 报道](https://www.wired.com/story/europe-race-us-deepseek-sovereign-ai/)｜[Reddit 讨论](https://www.reddit.com/r/DeepSeek/comments/1qh15va/the_race_to_build_the_deepseek_of_europe_is_on/)  

##### **Runpod：从 Reddit 帖子起家到年化收入 1.2 亿美元的 AI 云**  
Runpod 四年前从一条 Reddit 帖子起步，如今年化经常性收入（ARR）已达 1.2 亿美元，典型模式是出租按小时的 A100/4090 等算力给训练/推理用户。社区有人表示可帮内推，说明这类“算力基础设施创业公司”已经十分赚钱且缺人。  
 > 相关链接：[TechCrunch 报道](https://techcrunch.com/2026/01/16/ai-cloud-startup-runpod-hits-120m-in-arr-and-it-started-with-a-reddit-post/)｜[Runpod 相关 Reddit 帖](https://www.reddit.com/r/LocalLLaMA/comments/1qib2ks/runpod_hits_120m_arr_four_years_after_launching/)  

##### **《The Thinking Game》AI 纪录片两月 3 亿播放，数据被质疑“水分太大”**  
DeepMind 的纪录片《The Thinking Game》在不到两个月拿到 3.05 亿 YouTube 播放，远超当年《AlphaGo》的 3700 万。不过视频仅 19 万赞、4 千多评论，点赞率远低于同体量视频，引发是否有强推/机器人流量的质疑。  
 > 相关链接：[Reddit 质疑贴](https://www.reddit.com/r/singularity/comments/1qhuuqf/the_thinking_game_documentary_is_sitting_at_305m/)｜[纪录片链接](https://www.youtube.com/watch?v=Z3D2UmAesN4)  

##### **“写代码的时代结束”？Node.js 之父等人看 AI 编程未来**  
Node.js 之父 Ryan Dahl 表示“写代码的时代快结束了”，与 Karpathy、Stroustrup 等人类似，认为软件工程将从“敲代码”转向“问题建模+约束设计”。评论区则提醒：大公司受安全/合规限制，内部对这类新工具的采纳往往比个人晚好几年。  
 > 相关链接：[原文分析](https://jpcaparas.medium.com/the-creator-of-node-js-says-the-era-of-writing-code-is-over-8320c868043b)｜[Reddit 讨论](https://www.reddit.com/r/ClaudeCode/comments/1qhiicv/the_creator_of_nodejs_says_the_era_of_writing/)  

 

---  


#### **政策、治理与安全**  
##### **OpenAI 上线 ChatGPT 年龄预测，给未成年人套“安全壳”**  
OpenAI 宣布在 ChatGPT 引入年龄预测系统，用于识别疑似未成年用户并自动套用更严格的内容与功能限制；被误判的成年人可在设置里自证年龄。全球先行上线，欧盟稍后跟进。外界既从儿童保护角度认可，也担心这为精细化画像甚至广告铺路。  
 > 相关链接：[OpenAI 官方博客](https://openai.com/index/our-approach-to-age-prediction/)｜[公告推文](https://twitter.com/OpenAI/status/2013688237772898532)｜[外界解读与质疑](https://twitter.com/scaling01/status/2013688152750215500)  

##### **Davos 叙事：科学家领导 vs“社交媒体老板”，谁更靠谱？**  
在达沃斯，Amodei、Hassabis 等被媒体包装成“科学家主导实验室”的代表，刻意对比“靠广告和流量赚钱的社交媒体企业家”。Hassabis 强调 DeepMind 的“全栈优势”和实体机器人前景，并表示若能全球协调，他支持暂缓继续提能力上限。  
 > 相关链接：[相关评论汇总 1](https://twitter.com/scaling01/status/2013651299519074729)｜[相关评论汇总 2](https://twitter.com/scaling01/status/2013718310194475379)｜[Hassabis 接受采访](https://twitter.com/emilychangtv/status/2013726877706313798)  

##### **Jan Leike：自动化对齐审计显示 2025 年各家“更少作妖”**  
前 OpenAI 对齐负责人 Jan Leike 发文称，对 Anthropic、GDM、OpenAI 模型的自动化审计算法显示，到 2025 年模型在迎合、欺骗等“失调行为”上总体是下降趋势。虽然具体指标和方法没在推文展开，但这是少见的跨厂对齐走向信号。  
 > 相关链接：[Jan Leike 推文](https://twitter.com/janleike/status/2013669924950970781)  

##### **BASI 社区：攻防两端都在玩，AntiJection / Zero‑Click 漏洞上榜**  
BASI Jailbreaking 服务器里，大家一边讨论 Grok/ChatGPT 等模型越狱技巧，一边分享 ZombieAgent、ShadowLeak、Zero‑Click AI 漏洞和 AntiJection 攻防挑战。整体氛围是：大模型应用越多，红队和安全工具也必须同步壮大。  
 > 相关链接：[AntiJection 挑战](https://challenge.antijection.com/challenge)｜[Zero‑Click 漏洞文章](https://thehackernews.com/2025/06/zero-click-ai-vulnerability-exposes.html)｜[ZombieAgent 介绍](https://www.radware.com/blog/threat-intelligence/zombieagent/)  

 

---  

  
