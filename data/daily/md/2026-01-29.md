#### **模型与能力**  
##### **Kimi K2.5：开放模型里的新顶流**  
Moonshot 的 Kimi K2.5 在 LMArena/Arena 文本榜拿到开放模型第1，STEM、编码表现突出。社区实测：编码能力接近 Claude Opus 4.5，价格却只有其约 10–20%，还能本地部署（1T MoE，经 Unsloth 量化后 240GB 级别 GGUF 可跑），但存在用词啰嗦、用 token 多、仍会幻觉等问题。  
 > 相关链接：[Text Arena 榜单](https://lmarena.ai/leaderboard/text)｜[Kimi 官方介绍推文](https://twitter.com/Kimi_Moonshot/status/2016521406906028533)｜[Kimi-K2.5 GGUF（Unsloth）](https://huggingface.co/unsloth/Kimi-K2.5-GGUF)｜[本地跑 Kimi K2.5 教程（Reddit）](https://www.reddit.com/r/LocalLLaMA/comments/1qpfse6/run_kimi_k25_locally/)  

##### **Kimi K2.5 系统提示词与工具链被泄露**  
有人公开了 Moonshot Kimi K2.5 的完整 system prompt 和工具配置（约 5K token），包括记忆 CRUD 协议、工具 schema、上下文注入和安全规则。这相当于一次官方“设计文档”泄露，对想复刻高质量助理人格、记忆机制和长对话稳定性的开源项目很有参考价值。  
 > 相关链接：[泄露内容仓库](https://github.com/dnnyngyen/kimi-k2.5-prompts-tools)｜[Kimi 分享链接](https://www.kimi.com/share/19c003f5-acb2-838b-8000-00006aa45d9b)｜[相关讨论（Reddit）](https://www.reddit.com/r/LocalLLaMA/comments/1qoml1n/leaked_kimi_k25s_full_system_prompt_tools/)  

##### **Trinity Large：400B 开源 MoE 登场**  
Arcee/Prime Intellect/Datology 发布 Trinity Large：400B 稀疏 MoE，推理时仅激活 13B 参数，256 experts、每 token 用 4 个（约 1.56% 路由）。开放权重+宽松协议，主打“前沿能力 + 部署成本可控”，已在 Cline、OpenRouter 等接入。  
 > 相关链接：[Arcee 技术报告](https://github.com/arcee-ai/trinity-large-tech-report/blob/main/Arcee%20Trinity%20Large.pdf)｜[OpenRouter Trinity-Large-Preview](https://openrouter.ai/arcee-ai/trinity-large-preview:free)｜[发布讨论（X）](https://x.com/primeintellect/status/2016280792037785624)  

##### **DeepSeek-OCR 2 发布：更像“人眼”的版面理解**  
DeepSeek 推出 DeepSeek-OCR 2，引入新 DeepEncoder V2，用“先整体理解再决定阅读顺序”的视觉因果流程，显著降低编辑距离。社区反馈 V1 在页眉页脚、浅色文本上会漏，现在期待 V2 修复；有人在找线上 API 以便直接集成。  
 > 相关链接：[DeepSeek-OCR 2 宣传贴](https://www.reddit.com/r/DeepSeek/comments/1qo6xb4/deepseekocr_2_is_out_now/)｜[在线 Demo](https://deepseek-ocr-v2-demo.vercel.app/)  

##### **Z-Image Base / Turbo：新一代开源文生图**  
阿里通义推出 Z-Image Base 与 Turbo 模型，主打高质量+高效率。Base 步数多、画质更精致；Turbo 步数少、约 7 秒出图，观感更“真实”。社区实测 12GB 显存也能跑，适合本地部署和二次微调，Stable Diffusion 圈评价是“有点像新一代 SDXL”。  
 > 相关链接：[Z-Image 模型页](https://huggingface.co/Tongyi-MAI/Z-Image)｜[发布贴（LocalLLaMA）](https://www.reddit.com/r/LocalLLaMA/comments/1qoiep6/the_zimage_base_is_here/)｜[Base vs Turbo 对比讨论](https://www.reddit.com/r/StableDiffusion/comments/1qojw11/zimage_base_vs_zimage_turbo/)  

##### **DeepMind AlphaGenome 开源权重**  
Google DeepMind 宣布开放 AlphaGenome 模型及权重，用于预测基因变异对分子层面的影响。官方称内部 API 已有超百万次日调用、3000 多用户，现放出 Hugging Face 集合，降低生物信息和药物研发团队的进入门槛。  
 > 相关链接：[DeepMind 官方宣布](https://twitter.com/GoogleDeepMind/status/2016542480955535475)｜[权重链接合集](https://twitter.com/GoogleDeepMind/status/2016542490115912108)｜[权重镜像讨论](https://twitter.com/osanseviero/status/2016628065422762113)  

##### **NVIDIA 推 NVFP4 版本 Nemotron 3 Nano**  
NVIDIA 发布 NVFP4 精度的 Nemotron 3 Nano，宣称在 Blackwell B200 上吞吐可达 BF16 的 4 倍，精度保持 99.4%，靠的是量化感知蒸馏（QAD）。vLLM 已快速支持这一格式，意味着后续 4bit 近似 FP 的主流化速度会加快。  
 > 相关链接：[NVIDIA AI Dev 推文](https://twitter.com/NVIDIAAIDev/status/2016556881712472570)｜[vLLM 支持 NVFP4](https://twitter.com/vllm_project/status/2016562169140433322)  

##### **MongoDB LEAF：把“大模型嵌入”蒸馏到 CPU 可跑**  
MongoDB Research 提出 LEAF：离线用大模型对文档算嵌入，线上查询改用小模型，对齐训练后可保留约 96% 质量，模型体积缩小 5–15 倍，查询吞吐最高快 24 倍，还能在 CPU / 边缘设备跑。这相当于把“嵌入推理”也做成蒸馏默认形态。  
 > 相关链接：[LEAF 概述](https://twitter.com/LiorOnAI/status/2016481603426414883)  

##### **Kimi / GPT / Claude：前沿模型“个性分工”**  
有分析把前沿大模型分成“探索型”和“执行型”：GPT‑5.2 更适合大范围搜索和深度推理（exploration），Claude Opus 4.5 则偏稳定可靠的 exploitation，用 token 少、结果稳。推论是：科研工作流更适合 GPT，生产级业务更偏向 Claude。  
 > 相关链接：[模型“性格”分析贴](https://twitter.com/scaling01/status/2016335491243676058)  

 

---  


#### **Agent 与工具链**  
##### **Agent 技能体系正在成型：从提示词到“技能文件”**  
DeepLearning.AI + Anthropic 推了“Agent Skills”课程，强调把流程逻辑从 prompt 抽成可复用的“技能文件”；LangChain 也在推 Skills 概念；Hugging Face 给出 upskill 案例：用强模型执行轨迹合成技能，再迁移到弱模型，某些 CUDA kernel 任务准确率可拉高 45%，也可能拉跨，提醒必须按模型评估。  
 > 相关链接：[Andrew Ng 课程介绍](https://twitter.com/AndrewYNg/status/2016564878098780245)｜[LangChain Skills 讨论](https://twitter.com/sydneyrunkle/status/2016585688389734654)｜[HF upskill 介绍](https://twitter.com/ben_burtenshaw/status/2016534389685940372)  

##### **Agent 评测：从单轮到多轮，必须“看轨迹”**  
社区共识在收敛：Agent 评估不能只看单轮输出，要基于完整调用轨迹做单步/整轮/多轮对比。SWE-fficiency 开源了自动化编码 agent 的评测 harness；CooperBench 专门测多 agent 协同；安全侧有 AgentDoG 尝试沿整个轨迹找出危险动作的根因。  
 > 相关链接：[SWE-fficiency 仓库](https://twitter.com/18jeffreyma/status/2016511583032061999)｜[CooperBench 介绍](https://twitter.com/gneubig/status/2016555800982937879)｜[AgentDoG 安全评估](https://twitter.com/HuggingPapers/status/2016366634475388968)  

##### **LM Studio 0.4：本地模型“变成服务”**  
LM Studio 0.4 发布，支持 headless 模式和有状态 REST API，可在无 GUI 服务器、CI/CD 上部署本地模型，并行处理请求，还内建 MCP 支持。Discord 用户还挖出运行时里隐藏的 ROCm 选项，意味着 AMD GPU 也能加速。  
 > 相关链接：[0.4.0 发布博客](https://lmstudio.ai/blog/0.4.0)｜[社区讨论（Discord 摘要）](https://discord.com/channels/1110598183144399058)  

##### **Cursor：自动模式限额 + CLI 反而更受欢迎**  
Cursor 调整收费后，Auto 模式不再无限，用量计入每月 $20 配额，超出按 token 收费，部分用户几天就“刷爆”。同时 IDE 中 revert 按钮偶现消失 bug。大项目用户开始用 Cursor CLI 搭配自家键盘/终端，图形界面只做展示。  
 > 相关链接：[定价变更讨论](https://xcancel.com/cursor_ai/status/2016202243499073768?s=46)｜[Cursor 社区反馈节选](https://discord.com/channels/1074847526655643750)  

##### **Clawdbot / Moltbot：把你所有 API Key 接管走的“总控 agent”**  
多个社区（OpenAI、Cursor 等）在警告 Clawdbot/Moltbot：它要求集中托管 OpenAI、Google、Anthropic 等 API key，由一个 agent 统一调用。问题是：一旦被入侵或被 prompt 注入，攻击者可直接批量调用所有 key，被形容为“现在存，未来(量子)解密”的风险池。  
 > 相关链接：[OpenAI Discord 警告](https://discord.com/channels/974519864045756446)｜[Cursor 社区讨论](https://discord.com/channels/1074847526655643750/1074847527708393565)  

##### **LeetCode MCP：把刷题直接接入 Claude**  
有开发者发布 LeetCode MCP server，让 Claude 能在终端里直接登录 LeetCode、拉题、要提示、提交答案，相当于“用 Claude 帮你刷每日一题”的官方 workflow。后续计划扩展到 Cursor / JetBrains 插件。  
 > 相关链接：[LeetCode MCP GitHub](https://github.com/SPerekrestova/interactive-leetcode-mcp)  

##### **Prompt 工程：紧张感和“微提示”确实会改变输出**  
Prompt 社区流行两种小技巧：1）加时间压力句式（“你只有30秒，说一个我忽略的点”）来逼模型给更直接的结论；2）“微提示”——用极短命令+动作词（audit/clarify/simplify）分步调用模型，替代一大段背景。有用户提醒：对深度推理模型，这可能牺牲思考深度换速度。  
 > 相关链接：[紧迫感 prompt 讨论](https://www.reddit.com/r/PromptEngineering/comments/1qp0kay/the_most_unhinged_prompt_that_actually_works/)｜[Micro‑prompting 讨论](https://www.reddit.com/r/PromptEngineering/comments/1qonyx9/microprompting_get_better_ai_results_with_shorter/)  

 

---  


#### **基础设施与硬件**  
##### **本地跑 Kimi K2.5：苹果双 M3 Ultra 也能扛**  
有人用两台 512GB 内存的 M3 Ultra Mac Studio + Thunderbolt 5 RDMA，跑 Kimi K2.5 量化版可到约 24 token/s。配合 Unsloth 1.8bit 动态量化，磁盘占用从 600GB 降到 240GB，本质是把“1T 等级”模型拉进高端个人机可玩的范围。  
 > 相关链接：[双 M3 Ultra 实测推文](https://twitter.com/alexocheema/status/2016404573917683754)｜[量化模型说明](https://unsloth.ai/docs/models/kimi-k2.5)  

##### **GPU MODE / Decart：H200、Trainium 3 上挤干 1TB 模型**  
Decart 招募内核工程师，主攻 Trainium 3 和实时视频模型 Lucy 2；同时有教程展示如何用 INT4 QAT+RL 在单张 H200 上滚动部署 1TB 级模型。社区也在讨论 DGX vs RTX 5090：前者 1.8TB/s 带宽碾压 5090 的 300GB/s，算力瓶颈更多在内存与 L2 设计。  
 > 相关链接：[Lucy 2 技术贴](https://x.com/DecartAI/status/2016134190509498740)｜[INT4 QAT RL 教程](https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/slime/int4/readme-en.md)  

##### **tinygrad / GPU MODE：调优工具链在补齐“可视化”短板**  
tinygrad 新增 AMD 模拟器，支持 DEBUG=3/6 打印编译与运行期指令，方便在无真卡环境下调 kernel；GPU MODE 里则有人吐槽搞量化的人还没做一套好用的交互式数值可视化工具，目前勉强用 captum 之类库“凑合看”，UI/UX 完全不够用。  
 > 相关链接：[tinygrad PR #14387](https://github.com/tinygrad/tinygrad/pull/14387)｜[GPU MODE 讨论串](https://discord.com/channels/1189498204333543425)  

 

---  


#### **研究与方法**  
##### **Goodfire：用可解释性“挖”出阿尔茨海默新生物标志物**  
Goodfire 报告称，在生物医学基础模型上做机械可解释性，成功从中挖出一类新的阿尔茨海默相关生物标志物，并经实验验证。这被他们视作一条可复用路线：先让模型在科研任务上“超人”，再用解释性去找可落地的科学假设。  
 > 相关链接：[Goodfire 线程](https://twitter.com/GoodfireAI/status/2016563911508840623)  

##### **LingBot‑VLA：机器人数据越多，通用操作模型确实在涨功**  
有长文总结 LingBot‑VLA 的结果：真实机器人抓取/操作数据从 3k 小时堆到 20k 小时，VLA 的成功率仍在稳步上升。架构上用 Qwen2.5‑VL 做视觉语言，再接一个 action expert 并共享注意力，在 GM‑100 基准上超越 π0.5 等先前方案。  
 > 相关链接：[LingBot‑VLA 解读](https://twitter.com/omarsar0/status/2016518141308993565)  

##### **MergeMix：用“模型合并”反推最优数据配比**  
Nous 社区关注的 MergeMix 论文提出：在训练中段把不同数据子集上训练的模型做可学习的合并，用合并效果来指导数据混合比例的优化。对预算有限的开源团队，意味着可以用较少实验尝试出更合理的训练数据配方。  
 > 相关链接：[MergeMix 论文](https://arxiv.org/pdf/2601.17858)  

##### **Flow Matching vs Diffusion vs 自回归：范式之争回到数学本身**  
Yannick Kilcher 社区在激烈讨论：1）Transformer 完全可以参数化 flow matching 的向量场，本质是训练目标不同；2）扩散和 flow matching 在数学上很接近，别被复杂推导吓住；3）“扩散一定优于自回归”并不成立，很多是现有 AR 架构设计上的折衷。  
 > 相关链接：[Flow matching 讨论](https://arxiv.org/abs/2305.03486)｜[自回归改进提案](https://arxiv.org/abs/2512.14982)  

 

---  


#### **产品与应用落地**  
##### **Google 把 Gemini 3 深度塞进 Chrome 和搜索**  
Gemini 3 现已驱动全球 AI Overviews。Chrome 同时上线侧边栏、应用深度集成、Nano Banana 图像编辑，以及“Auto Browse”多步网页代办功能（先在美国 Pro/Ultra 预览）。前端开发者评价：这是目前浏览器里最像“真 agent”的一版整合。  
 > 相关链接：[Google Chrome 更新线程](https://twitter.com/Google/status/2016575105346773297)｜[Gemini App 说明](https://twitter.com/GeminiApp/status/2016575257436647521)  

##### **Gemini 3 Flash Agentic Vision：会自己“拉近、裁剪、放大”的看图方式**  
Google 发布 Agentic Vision 能力，允许 Gemini 3 Flash 在推理过程中主动对图像进行裁剪、缩放、局部放大，再结合代码执行做逐步分析。部分前端工程师表示在 UI/视觉分析上已明显强于静态 vision 模型，期待尽快集成到 IDE/agent。  
 > 相关链接：[Agentic Vision 官方博客](https://blog.google/innovation-and-ai/technology/developers-tools/agentic-vision-gemini-3-flash/)  

##### **OpenAI Prism：面向科研的 GPT‑5.2 工作台，口碑“两极分化”**  
OpenAI 推出 Prism，面向科研人员的 GPT‑5.2 Web 工作区，目标是把论文阅读、图表理解、代码实验整合在一个界面。Bubeck 澄清不会“抽成科研成果”。但社区有人认为 Prism 会强化“黑盒科研”，甚至称其“损害科学研究”。  
 > 相关链接：[Bubeck 回应](https://twitter.com/SebastienBubeck/status/2016345977481777188)｜[Prism 报道存档](https://archive.md/d9Vsf)  

##### **Cline 3.55.0：支持 Trinity Large 和 Kimi K2.5 的本地编程代理**  
Cline 新版集成 Arcee Trinity Large（400B MoE，128K 上下文）和 Kimi K2.5（1T MoE，256K上下文、SWE‑bench 76.8%），支持从截图生成 UI 代码并自我修复。ChatGPT Plus/Pro 用户还能直接用 GPT‑5 系列，无需 API key。  
 > 相关链接：[Cline 3.55.0 更新说明](https://cline.bot/blog/cline-3-55-0-arcee-trinity-and-kimi-k2-5-now-in-cline)  

##### **DeepSeek-OCR 在实际文档场景中的痛点与期待**  
用户回顾 DeepSeek-OCR 1 的体验：版面理解强，但容易漏掉页眉页脚、反色文字等内容；同时有人在找 DeepSeek-OCR 2 的现成云 API，以便在流水线里替换传统 OCR。这类模型越来越被当作“结构化抽取”基础设施，而不仅是识别。  
 > 相关链接：[用户讨论串](https://www.reddit.com/r/DeepSeek/comments/1qo6xb4/deepseekocr_2_is_out_now/)  

 

---  


#### **行业与公司动态**  
##### **Moonshot Kimi K2.5：定价、牌照与出海的三重博弈**  
Kimi K2.5 在中国内外都大火：月订阅价约 $19，很多人觉得本地薪资水平下略贵；许可证要求大 DAU/高营收产品必须显著标注“Kimi K2.5”并受额外限制，被批评为阻碍大企业采用；同时社区强烈希望它尽快登陆 Perplexity、OpenRouter 等聚合平台。  
 > 相关链接：[许可与品牌要求讨论](https://www.reddit.com/r/LocalLLaMA/comments/1qos25i/kimi_k2_artificial_analysis_score/)｜[Perplexity 社区期待接入](https://discord.com/channels/1047197230748151888/1047649527299055688)  

##### **Arena（原 LMArena）改名+大改版，引发一轮“UI 骂战”**  
LMSYS 的 LMArena 更名为 Arena（arena.ai），UI 变得非常像 Claude 网页版，还上了 Google 登录和更强验证码。老用户吐槽：登录困难、验证码疯狂、缺少 STOP 按钮和老表情；好处是新增 Code Arena 等子榜，Kimi K2.5 Thinking 也在这里拿到开源第一。  
 > 相关链接：[改名博客](https://arena.ai/blog/lmarena-is-now-arena/)｜[Text Arena 榜单](https://lmarena.ai/leaderboard/text)  

##### **Trinity 训练成本曝光：约 35 万美金**  
Unsloth 社区分享 Arcee Trinity Large 训练成本，大约 35 万美元级别（400B MoE 但实际激活 13B）。这个数字一方面说明 MoE 确实能在“类前沿能力”上压成本，另一方面也给开源圈一个现实参照：真正大的模型依然烧钱。  
 > 相关链接：[Trinity Large Tech Report](https://github.com/arcee-ai/trinity-large-tech-report/blob/main/Arcee%20Trinity%20Large.pdf)  

##### **Perplexity 被骂“订阅骗局”：扣费混乱+限额改来改去**  
Perplexity Discord 里不少用户抱怨被自动续费后体验缩水：有的被扣费却用不了服务，有的 Pro 账户查询上限莫名降到每小时 1 条、又突然恢复。部分人准备找银行/监管投诉，给其它 AI SaaS 提了个清晰反例：别在计费规则上玩“黑箱”。  
 > 相关链接：[Perplexity 订阅争议](https://discord.com/channels/1047197230748151888/1047649527299055688)  

##### **OpenRouter：一边接 Trinity/Kimi，一边退款排长队**  
OpenRouter 一方面上线 Trinity-Large-Preview 等新模型，推“前沿开源网关”形象；另一方面有不少用户反映退款要等数周甚至一月以上，支持工单无人回应。说明多模型聚合平台在对接计费、退款流程上还远没到云厂商成熟度。  
 > 相关链接：[OpenRouter Trinity 发布](https://x.com/OpenRouterAI/status/2016280059527757995)｜[退款问题讨论](https://discord.com/channels/1091220969173028894/1094454198688546826)  

##### **Flapping Airplanes 实验室获 1.8 亿美元融资**  
一支新 AI 实验室 Flapping Airplanes 宣布融资 1.8 亿美元，投资方包括 GV、红杉、Index 等一线机构。Karpathy 评论说，新研究型创业公司仍有机会在局部做到比巨头好一个数量级。  
 > 相关链接：[融资宣布](https://twitter.com/flappyairplanes/status/2016564437499728259)｜[Karpathy 点评](https://twitter.com/karpathy/status/2016590919143952466)  

 

---  


#### **政策、治理与安全**  
##### **“魔法字符串”让 Claude 强制拒答，红队在研究把它当“断路器”**  
BASI Jailbreaking 社区找到一串特殊 token，插进对话就能几乎 100% 让 Claude 进入拒答模式，被形容为“安全断路器”。有人设想未来可以把这类机制标准化：一旦检测到高风险轨迹，就注入字符串硬刹车。  
 > 相关链接：[Discord 讨论节选](https://discord.com/channels/1105891499641684019)  

##### **Gemini / DeepSeek / Kimi：安全策略与审查的副作用**  
Gemini 被多次证明可以通过系统 prompt 绕过脏话/敏感内容过滤；DeepSeek 在被“越狱失败”后容易陷入无限重复拒答循环；中国模型的思维链里还能看到显式过滤语句。这些例子说明当下安全策略大多是“外贴一层规则”，容易被看穿、也容易损伤可用性。  
 > 相关链接：[Gemini 越狱经验](https://discord.com/channels/1179035537009545276)｜[DeepSeek 拒答循环讨论](https://discord.com/channels/1053877538025386074)  

##### **Clawdbot / Moltbot 再被点名：典型的“集中密钥风险”**  
多个社区把 Clawdbot/Moltbot 当负面案例：它不是传统恶意代码，但一旦 UI 面板暴露或遭到 prompt 注入，就可能批量调用用户上传的所有云商 API key。大家开始反思：agent 产品到底该不该“帮你统一管理所有 key”，还是应该默认本地、最小权限。  
 > 相关链接：[OpenAI 服务器讨论](https://discord.com/channels/974519864045756446/998381918976479273)｜[Cursor 社区安全提醒](https://discord.com/channels/1074847526655643750/1074847527708393565)  

 

---  

  
